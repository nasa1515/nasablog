---
emoji: ğŸ¤¦â€â™‚ï¸
title: "[DATA] - Azure VMì— Apache Spark v3.0 Standalone ì„¤ì¹˜ With Zeppelin"
date: "2021-08-14 00:39:25"
author: nasa1515
tags: DATA
categories: DATA
---



ë¨¸ë¦¬ë§  

ì €ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œ Apache Sparkê°€ ì–´ë–¤ ì‹ìœ¼ë¡œ ë™ì‘í•˜ëŠ”ì§€? ì–´ë–¤ í•¨ìˆ˜ê°€ ìˆëŠ”ì§€? ê°„ë‹¨í•˜ê²Œ ì´ë¡ ì ìœ¼ë¡œë§Œ ì•Œì•„ë´¤ìŠµë‹ˆë‹¤.  
ì•„ì§ Sparkì— ëŒ€í•œ ë‚´ìš©ì´ ì œëŒ€ë¡œ ì´í•´ê°€ ë˜ì§€ ì•Šì•„ ì¼ë‹¨ êµ¬ì„±ë¶€í„° í•´ë³´ê³  ì‹¤ìŠµì„ í•˜ë©´ì„œ ë‹¤ì‹œ ì´í•´ë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤.  






  


 
---

## âœ” Azure VMì— Spark StandAlone êµ¬ì„± 
* Spark StandAlone Clusterë¡œ êµ¬ì„±í•˜ëŠ” í¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 

<br/>

### í™˜ê²½êµ¬ì„±

  * OS : CentOS Linux release 8.2.2004 (Core)  
  * cpu : 4 core  
  * RAM : 14GB  
  * JDK : 1.8.0
  * python : 3.8.8
  * Spark 3.0.2
  * zeppelin : 0.9.0

<br/> 


---


### 1. Open JDK ì„¤ì¹˜ (root ê³„ì • ê¸°ë°˜)

SparkëŠ” JVM ê¸°ë°˜ì´ê¸° ë•Œë¬¸ì— JDKë¥¼ ë¯¸ë¦¬ ì„¤ì¹˜í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.  

```cs
[root@Spark-Standalone ~]# yum install -y java-1.8.0-openjdk-devel.x86_64
Last metadata expiration check: 0:28:13 ago on Thu 04 Mar 2021 07:30:20 AM UTC.
...
...
(ì¤‘ëµ)
Complete!
```

<br/>

java versionì„ í™•ì¸í•´ë³´ì£   

```cs
[root@Spark-Standalone ~]# java -version
openjdk version "1.8.0_275"
OpenJDK Runtime Environment (build 1.8.0_275-b01)
OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode)
```

<br/>

---

### 2. Apache Spark ì„¤ì¹˜ (root ê³„ì • ê¸°ë°˜)

<br/> 


Spark 3.0.2 ë‹¤ìš´ë¡œë“œ  

```cs
[root@Spark-Standalone ~]# wget https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz
```

<br/>


ì••ì¶•í•´ì œ ë° ê¶Œí•œ ì„¤ì •  

```cs
[root@Standalone home]# useradd spark
[root@Standalone home]# cd /home/spark/
[root@Standalone spark]# tar xvfz spark-3.0.2-bin-hadoop2.7.tgz
[root@Standalone spark]# mv spark-3.0.2-bin-hadoop2.7 spark
[root@Standalone spark]# chown -R spark:spark spark
[root@Standalone spark]# chmod -R 777  spark
```

<br/>

Spark í™˜ê²½ë³€ìˆ˜ ë“±ë¡ (spark ê³„ì •ìœ¼ë¡œ ì „í™˜ í›„ ì§„í–‰)  


```cs
[spark@Spark-Standalone ~]$ echo export PATH='$PATH':/home/spark/spark/bin > ~/.bashrc
[spark@Spark-Standalone ~]$ source ~/.bashrc
```


<br/>

Spark ì„¤ì¹˜ í™•ì¸ 

```cs
[spark@Spark-Standalone ~]$ spark-shell
21/03/04 08:37:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://spark-standalone.internal.cloudapp.net:4040
Spark context available as 'sc' (master = local[*], app id = local-1614847063399).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.0.2
      /_/

Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_275)
Type in expressions to have them evaluated.
Type :help for more information.

scala>
```


<br/>

Spark Config ì„¤ì • 

```cs
## Spark_HOMEì˜ conf ë””ë ‰í† ë¦¬ì—ì„œ ìˆ˜í–‰

[root@Standalone conf]# cp spark-env.sh.template spark-env.sh
[root@Standalone conf]# vim spark-env.sh


## nasa setting

export SPARK_WORKER_INSTANCES=3 [worker nodeì— ëŒ€í•œ ì„¤ì •]
```


Spark Master í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰

```cs
[root@Standalone sbin]# sh start-master.sh
starting org.apache.spark.deploy.master.Master, logging to /home/spark/spark/logs/spark-root-org.apache.spark.deploy.master.Master-1-Standalone.out
```

<br/>

MASTER WEB í™•ì¸ (Cloudë¼ë©´ Inbound ì„¤ì • í•„ìš”)

![ìº¡ì²˜3121](https://user-images.githubusercontent.com/69498804/110070522-86df3c80-7dbd-11eb-82cd-85a45eb4eeb2.JPG)

* Worker Node ì„¤ì •ì— í•„ìš”í•œ urlì„ ë¯¸ë¦¬ ë³µì‚¬  
    spark://Standalone.44p1qlnthrou1ezmysbcbmontc.syx.internal.cloudapp.net:7077


<br/>

Worker Node í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰

ì•„ê¹Œ env.sh ì„¤ì •ì— ë§ê²Œ 3ê°œì˜ Worker ê°€ ìƒì„±ë©ë‹ˆë‹¤. 

```cs
[root@Standalone sbin]# sh start-slave.sh spark://Standalone.44p1qlnthrou1ezmysbcbmontc.syx.internal.cloudapp.net:7077 -m 2g -c 1
starting org.apache.spark.deploy.worker.Worker, logging to /home/spark/spark/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-Standalone.out
starting org.apache.spark.deploy.worker.Worker, logging to /home/spark/spark/logs/spark-root-org.apache.spark.deploy.worker.Worker-2-Standalone.out
starting org.apache.spark.deploy.worker.Worker, logging to /home/spark/spark/logs/spark-root-org.apache.spark.deploy.worker.Worker-3-Standalone.out
```

<br/>

Master WEBì—ì„œ Worker ë“±ë¡ í™•ì¸

![44444](https://user-images.githubusercontent.com/69498804/110070820-23a1da00-7dbe-11eb-8014-304fd2583ef8.JPG)


<br/>

---


### 3. Zeppelin ì„¤ì¹˜ (root ê³„ì • ê¸°ë°˜)

<br/> 


Zeppelin ë‹¤ìš´ë¡œë“œ  

```cs
[root@Spark-Standalone zeppelin]# wget https://downloads.apache.org/zeppelin/zeppelin-0.9.0-preview2/zeppelin-0.9.0-preview2-bin-all.tgz
```

<br/>


ì••ì¶•í•´ì œ ë° ê¶Œí•œ ë³€ê²½

```cs
[root@Standalone home]# useradd zeppelin
[root@Standalone home]# cd /home/zeppelin/
[root@Standalone zeppelin]# tar xvfz zeppelin-0.9.0-preview2-bin-all.tgz
[root@Standalone zeppelin]# mv zeppelin-0.9.0-preview2-bin-all zeppelin
[root@Standalone zeppelin]# chown -R zeppelin:zeppelin /home/zeppelin
[root@Standalone zeppelin]# chmod -R 777 /home/zeppelin
```

<br/>

í™˜ê²½ ë³€ìˆ˜ ë“±ë¡ (zeppelin ê³„ì •ìœ¼ë¡œ ì „í™˜ í›„ ì§„í–‰)  

```cs
[zeppelin@Spark-Standalone ~]$ echo export PATH='$PATH':/home/zeppelin/zeppelin/bin > ~/.bashrc
[zeppelin@Spark-Standalone ~]$ source ~/.bashrc
```

<br/>

Zeppelin í™˜ê²½ ì„¤ì •  


```cs
### /home/zeppelin/zeppelin/conf ìœ„ì¹˜ì—ì„œ Conf íŒŒì¼ ì„¤ì •

[root@Spark-Standalone conf]# pwd
/home/zeppelin/zeppelin/conf
[root@Spark-Standalone conf]# cp zeppelin-env.sh.template zeppelin-env.sh

### ì„¤ì • ì¶”ê°€

[root@Spark-Standalone conf]# echo export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk > zeppelin-env.sh
[root@Spark-Standalone conf]# echo export SPARK_HOME=/home/spark/spark >> zeppelin-env.sh


### Web ì ‘ì†ì„ ìœ„í•œ ì„¤ì •

[root@Spark-Standalone conf]# cp zeppelin-site.xml.template zeppelin-site.xml
```

<br/>


#### Config ìˆ˜ì •


zeppelin-site.xml

```cs
...
...
<property>
  <name>zeppelin.server.addr</name>
  <value>127.0.0.1</value> -> Client IPë¡œ ë³€ê²½
  <description>Server binding address</description>
</property>

<property>
  <name>zeppelin.server.port</name>
  <value>7777</value>  -> 8080ì€ Sparkê°€ ì“°ê³ ìˆê¸°ì— 7777ë¡œ ì„¤ì •
  <description>Server port.</description>
</property>

...
...
```

<br/>


zeppelin-env.sh

ì•„ë˜ ì„¤ì • ì¶”ê°€  

```cs
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk
export SPARK_HOME=/home/spark/spark
export PYSPARK_PYTHON=/home/spark/spark/python
export PYTHONPATH=/home/spark/spark/python
export MASTER=spark://Standalone.44p1qlnthrou1ezmysbcbmontc.syx.internal.cloudapp.net:7077
```


<br/>

Zeppelin Daemon ê¸°ë™  

```cs
[root@Spark-Standalone conf]# /home/zeppelin/zeppelin/bin/zeppelin-daemon.sh start
Log dir doesn't exist, create /home/zeppelin/zeppelin/logs
Pid dir doesn't exist, create /home/zeppelin/zeppelin/run
Zeppelin start                                             [  OK  ]


### ì •ìƒ ê¸°ë™ í™•ì¸

[root@Standalone conf]# /home/zeppelin/zeppelin/bin/zeppelin-daemon.sh start
Zeppelin start                                             [  OK  ]
[root@Standalone conf]# jps
3779 ZeppelinServer
3575 Worker
3512 Worker
3449 Worker
3295 Master
3807 Jps
```

<br/>

Zeppelin Web page í™•ì¸ [Port 7777]

![ìº¡ì²˜3333](https://user-images.githubusercontent.com/69498804/109940335-47f5ac00-7d15-11eb-9c86-04ded7a40090.JPG)

<br/>


Notebookì„ í•˜ë‚˜ ë§Œë“¤ì–´ì„œ ì—°ë™ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. 

![ìº¡ì²˜4444](https://user-images.githubusercontent.com/69498804/110071856-24d40680-7dc0-11eb-9320-04d58c12ea12.JPG)

ì™„ë£Œì¸ì¤„ ì•Œì•˜ìœ¼ë‚˜...  

<br/>

----

#### ERROR ë°œìƒ

python, pysparkë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ”ë° python interpreterë¥¼ ëª»ì°¾ëŠ”ë‹¤..  

```cs
org.apache.zeppelin.interpreter.InterpreterException: org.apache.zeppelin.interpreter.InterpreterException: Fail to open PythonInterpreter
	at org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:76)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:760)
	at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:668)
	at org.apache.zeppelin.scheduler.Job.run(Job.java:172)
	at org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:130)
	at org.apache.zeppelin.scheduler.FIFOScheduler.lambda$runJobInScheduler$0(FIFOScheduler.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.zeppelin.interpreter.InterpreterException: Fail to open PythonInterpreter
	at org.apache.zeppelin.python.PythonInterpreter.open(PythonInterpreter.java:115)
	at org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)
	... 8 more
Caused by: java.io.IOException: Fail to launch python process.
org.apache.commons.exec.ExecuteException: Execution failed (Exit value: -559038737. Caused by java.io.IOException: Cannot run program "python" (in directory "."): error=2, No such file or directory)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:205)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Cannot run program "python" (in directory "."): error=2, No such file or directory
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
	at java.lang.Runtime.exec(Runtime.java:621)
	at org.apache.commons.exec.launcher.Java13CommandLauncher.exec(Java13CommandLauncher.java:61)
	at org.apache.commons.exec.DefaultExecutor.launch(DefaultExecutor.java:279)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:336)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	... 1 more
Caused by: java.io.IOException: error=2, No such file or directory
	at java.lang.UNIXProcess.forkAndExec(Native Method)
	at java.lang.UNIXProcess.<init>(UNIXProcess.java:247)
	at java.lang.ProcessImpl.start(ProcessImpl.java:134)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	... 7 more

	at org.apache.zeppelin.python.PythonInterpreter.createGatewayServerAndStartScript(PythonInterpreter.java:160)
	at org.apache.zeppelin.python.PythonInterpreter.open(PythonInterpreter.java:112)
	... 9 more
```

<br/>

í˜¹ì‹œ ëª°ë¼ python 3.8.8 ë²„ì „ìœ¼ë¡œ ìƒˆë¡œ ì„¤ì¹˜í•´ë´…ì‹œë‹¤.


ì‚¬ì „ íŒŒì¼ ì„¤ì¹˜
```cs
[root@Standalone conf]# yum -y install gcc openssl-devel bzip2-devel libffi-devel
```

<br/> 


íŒŒì´ì¬ ì„¤ì¹˜
```cs
[root@Standalone nasa1515]# wget https://www.python.org/ftp/python/3.8.8/Python-3.8.8.tgz

[root@Standalone nasa1515]# tar xvfz Python-3.8.8.tgz
[root@Standalone nasa1515]# chmod -R 777 Python-3.8.8
[root@Standalone nasa1515]#
[root@Standalone nasa1515]# cd Python-3.8.8
[root@Standalone Python-3.8.8]# ./configure --enable-optimizations
[root@Standalone Python-3.8.8]# make altinstall
[root@Standalone Python-3.8.8]# echo alias python="/usr/local/bin/python3.8" >> /root/.bashrc
[root@Standalone Python-3.8.8]# source /root/.bashrc
[root@Standalone Python-3.8.8]# python -V
Python 3.8.8
```

ê²°ë¡  : íŒŒì´ì¬ì„ ê¹”ê³  ë­ í•´ë´ë„ ì•ˆëœë‹¤...  

<br/>

ì•½ 4ì‹œê°„ë™ì•ˆ StackOverFlowë¥¼ ì°¾ì•„ë‹¤ë‹Œ ê²°ê³¼..ì•„ë˜ ê¸€ì„ ë°œê²¬í–ˆë‹¤..

* [STACK OverFlow](https://stackoverflow.com/questions/32959723/set-python-path-for-spark-worker)

<br/>


#### ë¬¸ì œ í•´ê²°  

spark - pysparkê°€ pythonì˜ ê²½ë¡œë¥¼ ëª»ì½ê³  ìˆë‹¤!!  
ê°•ì œë¡œ env íŒŒì¼ì— í™˜ê²½ë³€ìˆ˜ë¡œ pythonì˜ ê²½ë¡œë¥¼ ë„£ì–´ì£¼ì! 

```cs
### íŒŒì´ì¬ ê²½ë¡œ í™•ì¸

[root@Standalone ~]# which python3
/usr/bin/python3


### env.sh íŒŒì¼ì— í™˜ê²½ë³€ìˆ˜ ì„¤ì •

export PYSPARK_PYTHON="/usr/bin/python3"

```

<br/>

ì •ìƒì ìœ¼ë¡œ ì—°ê²°!!  

![ìº¡ì²˜331212](https://user-images.githubusercontent.com/69498804/110093218-cddd2a00-7ddd-11eb-8259-aa1bdfd93880.JPG)


<br/>

Zeppelinì—ì„œë„ ì •ìƒì ìœ¼ë¡œ êµ¬ë™ë˜ë„¤ìš”...

![123123](https://user-images.githubusercontent.com/69498804/110093881-8c994a00-7dde-11eb-8e41-81568de26954.JPG)

<br/>

---

#### Blob Storageì— csv íŒŒì¼ Upload

ê¸°ë³¸ì ìœ¼ë¡œ Azureì—ì„œ StorageëŠ” Storage Accountë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.  
ë•Œë¬¸ì— ìš°ì„ ì ìœ¼ë¡œ Storage Accountë¥¼ ìƒì„±í•˜ê³  blob containerë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.  

* Storage Account ë° blobì˜ ìƒì„±ì€ [ì´ì „í¬ìŠ¤íŠ¸](https://nasa1515.github.io/azure/2021/02/08/AZURE-Storageservice.html#a2)ë¥¼ í™•ì¸í•˜ì‹œë©´ ë©ë‹ˆë‹¤.  

<br/>

#### ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì´ TESTDATA.csv íŒŒì¼ì„ blobì— upload í–ˆìŠµë‹ˆë‹¤.  

![13123123](https://user-images.githubusercontent.com/69498804/110274941-64466100-8013-11eb-8357-ca245d5c6d2f.JPG)


<br/>

#### ERROR ë°œìƒ!


* #### ì›ë˜ì˜ ëª©í‘œ : hadoop(yarn) - Cluster Manager ì—†ì´ Standalone êµ¬ì„±ì— blob storage data read.


* í•´ë‹¹ êµ¬ì„±ì„ í…ŒìŠ¤íŠ¸ í•´ë³´ë ¤ê³  í–ˆìœ¼ë‚˜ ë‹¤ìŒê³¼ ê°™ì€ ERROR ë°œìƒ  

    ![1232313](https://user-images.githubusercontent.com/69498804/110295613-a8962900-8034-11eb-8639-d665dc057275.JPG)


    í•´ë‹¹ ì´ìŠˆëŠ” blob(data lake gen2)ì—ì„œ wasb[s] í˜•ì‹ìœ¼ë¡œ íŒŒì¼ì„ ë°›ì•„ì˜¤ë ¤ í–ˆìœ¼ë‚˜  
    Spark ê°€ ì„¤ì¹˜ë˜ì–´ìˆëŠ” VMì—ëŠ” Hadoopì´ ì„¤ì¹˜ ë° ì—°ë™ì´ ë˜ì–´ìˆì§€ ì•Šê¸°ì— DFì— ë„£ì„ ìˆ˜ ì—†ëŠ” ì´ìŠˆ ì˜€ìŠµë‹ˆë‹¤.  
    ì‚¬ì‹¤ pysparkë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•´ì„œ Azure blob apië¥¼ ì§ì ‘ ì„ ì–¸í•´ì„œ https ì—°ë™ì„ í•  ìˆ˜ëŠ” ìˆì§€ë§Œ  
    ê·¸ë ‡ê²Œ ì‚¬ìš©í•˜ëŠ” ë¡œì§ì€ ì‹¤ìŠµì´ë‚˜ ì‹¤ë¬´ì—ì„œë„ ì í•©í•˜ì§€ ì•Šë‹¤ê³  ìƒê°í•´ì„œ Hadoopì„ ê¹”ê¸°ë¡œ í–ˆìŠµë‹ˆë‹¤.  

<br/>

---

## ë§ˆì¹˜ë©°â€¦  

  
ë§ˆì§€ë§‰ pyspark ë¬¸ì œë¡œ ê±°ì˜ 4ì‹œê°„, hdhfs ë¬¸ì œë¡œ 4ì‹œê°„ ê±°ì˜ í•˜ë£¨ë¥¼ ë‚ ë ¸ìŠµë‹ˆë‹¤.  
ì‹œê°„ì´ ì¡°ê¸ˆ ì§€ë‚˜ë‹ˆ Sparkì— ëŒ€í•œ ë¡œì§ì„ ì œëŒ€ë¡œ ì´í•´ ëª»í•œ ë¶€ë¶„ì´ í° ê²ƒ ê°™ìŠµë‹ˆë‹¤.  
ê·¸ë˜ì„œ ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œ hadoopì„ ì„¤ì¹˜í•˜ê³  ì¬ë„ì „í•´ë´…ì‹œë‹¤..  


---

```toc
```


