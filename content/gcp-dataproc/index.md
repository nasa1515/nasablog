---
emoji: ğŸ¤¦â€â™‚ï¸
title: "[DATA, GCP] - GCP DataProc spark Clusterë¡œ ETL í›„ BigQueryì— ì ì¬"
date: "2021-09-08 00:34:25"
author: nasa1515
tags: CLOUD DATA
categories: CLOUD DATA
---

  


ë¨¸ë¦¬ë§  

ì´ë²ˆì—ëŠ” DataProc(Hadoop/Spark)ë¥¼ ì‚¬ìš©í•˜ì—¬ 
ëŒ€ìš©ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ë‹¤ë£¹ë‹ˆë‹¤. ë¬¼ë¡  íŒŒì´ì¬ì„ ì²¨ê°€í•´ì„œ  



--- 

## âœ” DataProcì— ëŒ€í•´ì„œ..

*Dataprocì€ ì¼ê´„ ì²˜ë¦¬, ì¿¼ë¦¬, ìŠ¤íŠ¸ë¦¬ë°, ë¨¸ì‹  ëŸ¬ë‹ì— ì˜¤í”ˆì†ŒìŠ¤ ë°ì´í„° ë„êµ¬ë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ” ê´€ë¦¬í˜• Spark ë° Hadoop ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.*  
ì¦‰ ì§€ê¸ˆê¹Œì§€ ê·€ì°®ê²Œ Spark, Hadoopì„ ì—°ë™í•˜ëŠ” ê³¼ì •ì„ ì—†ì• ê³  ì‚¬ìš©ë§Œí•˜ë©´ ë˜ëŠ” ì„œë¹„ìŠ¤ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

ì—¬ê¸°ì„œ DataFlowì™€ DataProcì˜ ì°¨ì´ì— ëŒ€í•´ì„œ ê¶ê¸ˆì¦ì´ ìƒê²¼ëŠ”ë°  
ë‘ íˆ´ ëª¨ë‘ ETLì„ í•˜ëŠ” íˆ´ì— ëŒ€í•´ì„œëŠ” ê³µí†µì ì„ ê°€ì§€ê³  ìˆì§€ë§Œ  
DataFlowëŠ” Serverless ì„œë¹„ìŠ¤ë¡œ Streaming, Batch Flowë¥¼ Codeë¡œ ê´€ë¦¬í•˜ê³  ì‹¶ìœ¼ë©´ ì‚¬ìš©í•˜ê³   
DataProcì€ ê¸°ì¡´ì— HDFS ê°™ì€ Hadoop EcoSystemì— ì¢…ì†ë˜ì–´ ìˆëŠ” ì‹œìŠ¤í…œì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ì‚¬ìš©í•˜ê¸° ì¢‹ë‹¤ê³  í•©ë‹ˆë‹¤.


<br/>

---

## âœŒ DataProc Cluster ìƒì„±

<br/>

* GCP íƒìƒ‰ ë©”ë‰´ > Dataproc > í´ëŸ¬ìŠ¤í„° ì„ íƒ > í´ëŸ¬ìŠ¤í„° ë§Œë“¤ê¸°

    ![ë‹¤ìš´ë¡œë“œ](https://user-images.githubusercontent.com/69498804/116354676-b8134080-a833-11eb-8b5a-249126ff2798.png)


<br/>

* í´ëŸ¬ìŠ¤í„° í•„ë“œ ì„¤ì • (ì´ë¦„ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ê¸°ë³¸ê°’)

    ![ìº¡ì²˜](https://user-images.githubusercontent.com/69498804/116355090-4f789380-a834-11eb-8880-311c70b982b2.JPG)

    <br/>

* í”„ë¡œë¹„ì €ë‹ ê³¼ì •ì„ 3ë¶„ì •ë„ ê±°ì¹˜ê³  ë‹¤ìŒê³¼ ê°™ì´ ìƒì„±ì´ ì™„ë£Œë©ë‹ˆë‹¤.

    ![2](https://user-images.githubusercontent.com/69498804/116356531-5b655500-a836-11eb-873e-f5701fbc4d9a.JPG)

<br/>

---

## ğŸ™Œ Data ì¤€ë¹„í•˜ê¸°

ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” BigQueryì—ì„œ ê³µê°œì ìœ¼ë¡œ ì œê³µí•˜ëŠ” DataSetì„ ì´ìš©í•©ë‹ˆë‹¤.  

Dataproc ClusterëŠ” GCS Connectorë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì œê³µí•˜ì—¬  
ë‹¤ë¥¸ ì„¤ì •ì—†ì´ GCSì— ìˆëŠ” ë°ì´í„°ì— ë°”ë¡œ ì•¡ì„¸ìŠ¤ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.  
ì €ëŠ” ì´ë¥¼ ì´ìš©í•´ì„œ BigQueryì˜ ê³µê°œ DataSetì˜ íŠ¹ì • í…Œì´ë¸”ì„ Cloud Storageë¡œ Exportí•˜ì—¬  
Exportí•œ ë°ì´í„°ì— ë°”ë¡œ ì ‘ê·¼í•˜ì—¬ ì‚¬ìš©, í¼í¬ë¨¼ìŠ¤ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤.  

<br/>


* ë°ì´í„° ì •ë³´  

    ![ìº¡ì²˜3](https://user-images.githubusercontent.com/69498804/116357157-24437380-a837-11eb-9047-048e8e5a018d.JPG)

    * Table ID : bigquery-public-data:covid19_weathersource_com.postal_code_day_history
    * Table í¬ê¸° : ì•½ 300 

    <br/>

* ë°ì´í„° í˜•ì‹ 

    ![ìº¡ì²˜4](https://user-images.githubusercontent.com/69498804/116357277-476e2300-a837-11eb-920c-682f3e9dfa19.JPG)

    ë°ì´í„°ì˜ ë‚´ìš©ì€ ë‚˜ë¼ ë³„ COVID-19ì˜ ê¸°ìƒìƒíƒœ ë°ì´í„°ì…ë‹ˆë‹¤.  

<br/>

* Cloude Storage ìƒì„± (GCS) - ì¿¼ë¦¬ ê²°ê³¼ ë°ì´ëŸ¬(CSV)í‹‘ ìŒ“ëŠ” ê³³  

    ![ìº¡ì²˜5](https://user-images.githubusercontent.com/69498804/116358291-720cab80-a838-11eb-8d31-a13169891652.JPG)

    * Regionì„ Bigqueryì™€ ë§ì¶°ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. 

<br/>

* BigQuery DataSet, Table ìƒì„± (ì¿¼ë¦¬ ê²°ê³¼ ë°ì´í„°ë¥¼ ìŒ“ëŠ” ê³³)

    ![ìº¡ì²˜6](https://user-images.githubusercontent.com/69498804/116358650-d7609c80-a838-11eb-8791-4acddef9cb46.JPG)

<br/>


* ì €ëŠ” Pythonìœ¼ë¡œ ê°„ë‹¨í•œ ì½”ë“œë¥¼ ì‘ì„±í•´ì„œ ë‹¤ìŒê³¼ ê°™ì´ ë°ì´í„°ë¥¼ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤.  

    ê³µê°œ DataSetì—ì„œ ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë‹¤ë¥¸ í…Œì´ë¸”ì— ì €ì¥í•˜ëŠ” ì½”ë“œ 

    ```python
    from google.cloud import bigquery

    # Construct a BigQuery client object.
    client = bigquery.Client()

    # TODO(developer): Set table_id to the ID of the destination table.
    table_id = "lws-cloocus.ustest.ustable"

    job_config = bigquery.QueryJobConfig(destination=table_id)

    sql = 'SELECT * FROM `bigquery-public-data.covid19_weathersource_com.postal_code_day_history` LIMIT 34230421'

    # Start the query, passing in the extra configuration.
    query_job = client.query(sql, job_config=job_config)  # Make an API request.
    query_job.result()  # Wait for the job to complete.

    print("Query results loaded to the table {}".format(table_id))
    ```
    * ì•„ì…”ì•¼ í•˜ëŠ” ê±´ Tableì„ ë³µì‚¬í•˜ëŠ” ê²ƒê³¼ ë°ì´í„°ë§Œ(ì¿¼ë¦¬ê²°ê³¼)ë³µì‚¬í•˜ëŠ” ê²ƒì€ ë‹¤ë¦…ë‹ˆë‹¤.  
    Tableì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ê²Œë˜ë©´ Tableì˜ ì •ë³´ê¹Œì§€ ì €ì¥ë©ë‹ˆë‹¤..


<br/>

* í•´ë‹¹ Codeë¥¼ ì‹¤í–‰ì‹œí‚¤ê²Œ ë˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ íŠ¹ì • Tableì— ì¿¼ë¦¬ê²°ê³¼ê°€ ì €ì¥ë©ë‹ˆë‹¤.  


    ![ìº¡ì²˜](https://user-images.githubusercontent.com/69498804/116361301-c9f8e180-a83b-11eb-90fb-a61cfbbd8fc9.JPG)

<br>

* ì¿¼ë¦¬ê²°ê³¼ê°€ ì €ì¥ë˜ì–´ìˆëŠ” Tableì˜ ë°ì´í„°ë¥¼ csvë¡œ ë³€í™˜í•´ì„œ GCSë¡œ ì €ì¥  

    ```python
    # Source option
    project = "lws-cloocus"
    dataset_id = "ustest"
    table_id = "ustable"


    # ìš©ëŸ‰ ë§ì€ Table (1Gì´ìƒ)ì€ * ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ Table ì½ì–´ì„œ csví™” ì‹œì¼œì•¼ í•¨.
    destination_uri = "gs://{}/{}".format(bucket_name, "result*.csv")
    dataset_ref = bigquery.DatasetReference(project, dataset_id)
    table_ref = dataset_ref.table(table_id)

    extract_job = client.extract_table(
        table_ref,
        destination_uri,
        # Location must match that of the source table.
        location="US",
    )  # API request
    extract_job.result()  # Waits for job to complete.

    print(
        "Exported {}:{}.{} to {}".format(project, dataset_id, table_id, destination_uri)
    )
    ```

    * BigQeuryì—ì„œ Dataë¥¼ export í•  ë•Œ í•œë²ˆì— 1GB ë‹¨ìœ„ê¹Œì§€ ë°–ì— ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
    ë•Œë¬¸ì— * ì™€ì¼ë“œì¹´ë“œë¥¼ ì‚¬ìš©í•´ì„œ CSV Fileì„ ë¶„ë¦¬í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤.  

    <br/>

* í•´ë‹¹ ì½”ë“œë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ GCSì— Dataê°€ ì €ì¥ë©ë‹ˆë‹¤.  


    ![ìº¡ì²˜3](https://user-images.githubusercontent.com/69498804/116361977-8783d480-a83c-11eb-8d1e-5d447ce71323.JPG)

    * ë‹¤ìŒê³¼ ê°™ì´ ìš©ëŸ‰ì´ ì¼ì •í•˜ê²Œ ë‚˜ëˆ ì„œ ì €ì¥ë©ë‹ˆë‹¤.  

<br/>

* ì €ì¥ëœ CSV Fileì„ Localë¡œ ë‹¤ìš´ë°›ì•„ì„œ NotePadë¡œ í™•ì¸í•´ë³´ì£   

    ![23](https://user-images.githubusercontent.com/69498804/116362297-ddf11300-a83c-11eb-8944-4694fb94bd4e.JPG)

    * ë‹¤ìŒê³¼ ê°™ì´ ë§¨ ìœ—ì¤„ì€ í—¤ë” ì •ë³´, ë‚˜ë¨¸ì§€ëŠ” ë°ì´í„° ê°’ë§Œ ì €ì¥ë©ë‹ˆë‹¤.  

<br/>

---

## ğŸ‘ Jupyter Notebook ì—°ê²°

ì´ì œ ê°„ë‹¨í•œ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ê¸° ìœ„í•´ Jupyter Notebookì„ ì—°ê²° í•˜ë ¤ê³  í–ˆëŠ”ë°...  
ë³´ë‹ˆê¹ Clusterë¥¼ ì˜ëª» ìƒì„±í–ˆë„¤ìš” ì•„ë˜ êµ¬ì„±ìš”ì†Œ GWë¥¼ ì‚¬ìš©í•˜ëŠ” ì˜µì…˜ì„ ì²´í¬í•´ì•¼í•©ë‹ˆë‹¤.  

* êµ¬ì„±ìš”ì†Œ ê²Œì´íŠ¸ì›¨ì´ 

    ![ìº¡ì²˜](https://user-images.githubusercontent.com/69498804/116366348-2a3e5200-a841-11eb-81c1-c83a9f629154.JPG)

    * ê²Œì´íŠ¸ì›¨ì´ ì˜µì…˜ ì²´í¬
    * êµ¬ì„±ìš”ì†Œì—ì„œ Jupyter Notebook ì²´í¬ 

<br/>

* í´ëŸ¬ìŠ¤í„°ê°€ ìƒˆë¡­ê²Œ ë§Œë“¤ì–´ì¡Œë‹¤ë©´ í´ëŸ¬ìŠ¤í„° ì •ë³´-> ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ ì ‘ì†í•©ë‹ˆë‹¤.  

    ![ìº¡ì²˜3](https://user-images.githubusercontent.com/69498804/116367440-527a8080-a842-11eb-9843-2fdb4cfdecfa.JPG)

    * ê·¸ëŸ¼ ë‹¤ìŒê³¼ ê°™ì´ JupyterLab GW linkê°€ ìƒê¸°ê³  ì ‘ì†í•©ë‹ˆë‹¤.  

    <br/>

* ê·¸ëŸ¼ ë‹¤ìŒê³¼ ê°™ì´ DataProc Clusterì™€ ì—°ê²°ëœ Jupyter Pageì— ì ‘ì†ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. 

    ![ìº¡ì²˜4](https://user-images.githubusercontent.com/69498804/116367646-85bd0f80-a842-11eb-8005-406031f0ca44.JPG)


<br/>

* ì´ í›„ì— GCSì— ì €ì¥ëœ csvë¥¼ ì½ëŠ” ê²ƒë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.  

    ![33333](https://user-images.githubusercontent.com/69498804/116504392-21a65400-a8f3-11eb-9e7e-8295718c17e2.JPG)

    <br/>

* ì €ëŠ” ì¿¼ë¦¬ ê²°ê³¼ ì‹œê°„ì´ë‚˜, table í˜•íƒœë¡œ ê²°ê³¼ë¥¼ ë³´ê³  ì‹¶ì–´ì„œ extensionì„ ì¶”ê°€ ì„¤ì¹˜ í–ˆìŠµë‹ˆë‹¤. 


    <br/>


    * Jupyterì—ì„œ Terminal ì°½ì„ ì—° ë’¤ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.

        ```cs
        # pip install jupyterlab_execute_time

        ```

    <br/>

    * ì„¤ì¹˜ê°€ ì™„ë£Œ ëœ ë’¤ ì—°ê²°ëœ WEBì„ ìƒˆë¡œê³ ì¹¨ í•˜ë©´ execure-time ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  

        ![ìº¡ì²˜444](https://user-images.githubusercontent.com/69498804/116510416-d5154580-a8ff-11eb-86ff-8ea55e585217.JPG)

    <br/>

    * ê·¸ í›„ Settings - Advanced Settings editor - Notebookì— ì•„ë˜ ì½”ë“œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.  

        ![22222222](https://user-images.githubusercontent.com/69498804/116514663-4b1cab00-a906-11eb-9071-34c3d15fc616.JPG)
 

    <br/>

    * ê·¸ëŸ¼ ë‹¤ìŒê³¼ ê°™ì´ ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ì´ ì¶œë ¥ë©ë‹ˆë‹¤.!

        ![3213121](https://user-images.githubusercontent.com/69498804/116514759-6be50080-a906-11eb-9860-534243a6388f.JPG)


<br/>


* ì €ëŠ” í•„ìš”í•´ë³´ì´ëŠ” ì¶”ê°€ Extentionì„ ë” ì„¤ì¹˜í•´ì¤¬ìŠµë‹ˆë‹¤.  

    <br/>

    * variableinspector

    ```cs
    # pip install lckr-jupyterlab-variableinspector

    ```

    <br/>

    * TOC

    ```cs
    # jupyter nbextension enable toc2/main
    ```

<br/>


---

## ğŸ‘ Pyspark Test

ìœ„ì—ì„œë„ Testë¥¼ í•´ë´¤ì§€ë§Œ ê·¸ë˜ë„ ëª‡ê°€ì§€ pyspark í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤.  

<br/>

* CSV File ì½ì–´ì˜¤ê¸° (GCSì— ìˆëŠ”)  

    ```python
    # df = spark.read.csv("gs://nasa_us/", header=True, inferSchema=True)
    ```
    * gs://nasa_us/ ê²½ë¡œì— ìˆëŠ” ëª¨ë“  íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤.  
    * read.csv ì˜µì…˜ì¸ header, inferSchemaë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.  

    ![2221313](https://user-images.githubusercontent.com/69498804/116836339-17d96500-ac01-11eb-9ab5-707e5ae65e2c.JPG)

    * ì•½ 45.96s ê°€ ì†Œìš” ë˜ì—ˆìŠµë‹ˆë‹¤.  


<br/>

* í•´ë‹¹ DataFrameì˜ Row ë°˜í™˜ 

    ```python
    # df.show(10)    -- Row 10ê°œ ë°˜í™˜
    # df.count()     -- Row ê°¯ìˆ˜ ë°˜í™˜
    ```

    ![11111](https://user-images.githubusercontent.com/69498804/116836737-ac909280-ac02-11eb-8dcc-dac053327581.JPG)

    * showì—ëŠ” 546ms ê°€ ì†Œìš” ë˜ì—ˆìŠµë‹ˆë‹¤.
    * countì—ëŠ” 13.81s ê°€ ì†Œìš” ë˜ì—ˆìŠµë‹ˆë‹¤.  

<br/>

* í•´ë‹¹ DataFrameì˜ Summary ê°’ ë°˜í™˜

    ```python
    # df.summary().show()
    ```

    ![222222](https://user-images.githubusercontent.com/69498804/116841196-68f25480-ac13-11eb-872b-1fc2019bdc29.JPG)

    * Summaryì—ëŠ” 4m 16.06s ê°€ ì†Œìš” ë˜ì—ˆìŠµë‹ˆë‹¤.


<br/>


---

## ë§ˆì¹˜ë©°â€¦  

  
DataProcì„ ì‚¬ìš©í•´ë³´ë©´ì„œ Sparkì— ëŒ€í•´ì„œë„ ë‹¤ì‹œ ì•Œì•„ ê°ˆ ìƒê°ì…ë‹ˆë‹¤.  
ê·¸ë˜ì„œ ë‹¤ìŒ í¬ìŠ¤íŠ¸ì—ì„œëŠ” Pysparkì˜ ë¬¸ë²•ì— ëŒ€í•´ì„œ í¬ìŠ¤íŒ… ì˜ˆì •ì…ë‹ˆë‹¤.  


---

```toc
```
