---
emoji: ğŸ¤¦â€â™‚ï¸
title: "[DATA, GCP] - GCP DataBricks ì‚¬ìš©ê¸°"
date: "2021-09-12 00:34:25"
author: nasa1515
tags: GCP DATA
categories: GCP DATA
---

  
<br/>

ë¨¸ë¦¬ë§  

ì €ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œ DataProcì— ëŒ€í•œ ì„¤ëª…ê³¼ ê°„ë‹¨í•œ ì‚¬ìš©ë²•ì„ ë‹¤ë¤„ë´¤ì—ˆìŠµë‹ˆë‹¤.  
ì´ë²ˆì—ëŠ” GCPì—ì„œ íŒŒíŠ¸ë„ˆ SaaSí˜•íƒœë¡œ ì œê³µí•´ì£¼ëŠ” DataBricksë¥¼ ì‚¬ìš©í•´ì„œ  
ì§€ë‚œë²ˆê³¼ ë™ì¼í•œ ë°ì´í„°, ìŠ¤íŠ¸ë¦½íŠ¸ë¥¼ ì´ìš©í•´ì„œ ì„±ëŠ¥ì´ë‚˜, ì‚¬ìš©ë²•ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë´¤ìŠµë‹ˆë‹¤.  
ë¬¼ë…¼ ì´ë²ˆì—ë„ íŒŒì´ì¬ì„ ì²¨ê°€í•´ì„œ  


--- 

## âœ” DataBricks?

![og-databricks](https://user-images.githubusercontent.com/69498804/117228331-cf65b580-ae53-11eb-9b9d-81bd0a524677.png)

Databricksë€?  
ê°„ë‹¨ ìš”ì•½í•´ì„œ Spark,Hadoop ë“± ë¹…ë°ì´í„° ê´€ë ¨ ì†”ë£¨ì…˜ ì‹¤í–‰í™˜ê²½ì„ ì œê³µí•˜ëŠ” í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.  
í†µí•© ë¶„ì„ í”Œë«í¼ìœ¼ë¡œ, í•œ WorkSpaceë‚´ì—ì„œ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.  
ì´ì „ì— Spark, Hadoopì„ ON-Premise í™˜ê²½ì— ì„¤ì¹˜í•œ í¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•´ë³´ì‹œë©´ ì•Œê² ì§€ë§Œ  
JDKë¶€í„° ì—°ë™í•´ì•¼ í•˜ëŠ” ë¶€ë¶„ì´ ë§¤ìš° ê·€ì°®ê³  ì˜¤ëœ ì‹œê°„ì´ ê±¸ë¦¬ê²Œ ë©ë‹ˆë‹¤.  
DataBricksë¥¼ ì‚¬ìš©í•˜ë©´ ì„¤ì¹˜, ì„¤ì • ë¶€ë¶„ ì—†ì´ ë°”ë¡œ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.  

DataBricksëŠ” ì•„ë˜ ì‘ì—…ë“¤ì„ í•œ WorkSpaceì—ì„œ ì§€ì›í•©ë‹ˆë‹¤.  

- reports
- dashboards
- ETL ì‘ì—… ì‹¤í–‰ (Extract, Transform, Load)
- ë¨¸ì‹ ëŸ¬ë‹, ìŠ¤íŠ¸ë¦¼ ì‘ì—…
- ì•„íŒŒì¹˜ Sparkë³´ë‹¤ ë” optimized.
- Databricks ì„œë²„ì™€ ì‹¤ì‹œê°„ìœ¼ë¡œ interaction

<br/>

---

## ğŸ‘Œ GCP DataBricks?

GCP, Azure, AWS ë“± 3ì‚¬ Public CloudëŠ” ì´ë¯¸ DataBricksë¥¼ SaaS, PaaS í˜•íƒœë¡œ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.  
GCPì˜ ê²½ìš° ì•„ì§ ë„ì…ëœì§€ 1ë…„ì´ ì±„ ì•ˆë˜ì„œ ë¶ˆì•ˆì •í•œ ë¶€ë¶„ë„ ìˆê³  Korea Regionë„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
ì•„ì§ GAì¼ì •ë„ ë‚˜ì˜¤ì§€ ì•Šì€ ìƒíƒœêµ¬ìš”...(AWS,AZUREëŠ” ë‹¤ ìˆëŠ”ë°...)   
ê·¸ë˜ì„œ ì´ë²ˆ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ì–´ì©” ìˆ˜ ì—†ì´ US Regionì—ì„œì˜ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.  


<br/>

* #### DataBricks ì‚¬ìš©í•˜ê¸°(êµ¬ë…)

    GCPì—ì„œ DataBricksë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ë…ì„ ë¨¼ì € ì§„í–‰í•´ì•¼ í•©ë‹ˆë‹¤.  

    ![da](https://user-images.githubusercontent.com/69498804/117228743-a0037880-ae54-11eb-9362-11dd61314007.JPG)

    * êµ¬ë… ì´í›„ì— DataBricksì˜ êµ¬ë§¤ ìŠ¤í™ì„ ì •í•˜ê³  DataBricks Dashboradë¡œ ì´ë™í•˜ë©´ ë©ë‹ˆë‹¤.  


    <br/>

* #### WorkSpace ìƒì„±  

    Dashboradì—ì„œ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš© í•  WorkSpaceë¥¼ ìƒì„±í•˜ë©´ ë©ë‹ˆë‹¤.


    ![ìº¡ì²˜2](https://user-images.githubusercontent.com/69498804/117228897-025c7900-ae55-11eb-941b-597f74ec3f45.JPG)


    <br/>

* #### WorkSpace ì ‘ì†  


    WorkSpaceë¥¼ ìƒì„± í›„ URLì— ì ‘ì†í•˜ë©´ ë“œë””ì–´ ë°ì´í„° ì‘ì—…ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

    ![123123123](https://user-images.githubusercontent.com/69498804/117229354-d42b6900-ae55-11eb-839c-bc1f7979ed4b.JPG)

<br/>


* #### DataBricks Cluster ìƒì„±  

    WorkSpaceì˜ Cluster Tabì—ì„œ Create Clusterë¥¼ í´ë¦­í•´ ìƒì„±í•©ë‹ˆë‹¤.  

    ![33333333333333](https://user-images.githubusercontent.com/69498804/117230334-d68ec280-ae57-11eb-939d-295ed700acea.JPG)


<br>

* #### ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ Specìœ¼ë¡œ Clusterë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.  

    ![2222](https://user-images.githubusercontent.com/69498804/117380571-f20bd300-af14-11eb-9cae-69720f7c2043.JPG)
    
    * Nmae : Cluster01 
    * Runtime Version : 8.1  
    * Worker Type : n2-standard-8 
    * Advanced Option Tabì„ ì—´ì–´ Google Service Account ì…ë ¥ 
        ì£¼ì˜ : Service AccountëŠ” GCSì— ê¶Œí•œì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

<br/>

* ì´ì œ Notebookì„ ìƒì„±í•˜ê³  GCSë¥¼ DBFSì— Mountí•´ì„œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.  


    ```python
    bucket_name = "nasagcp"
    mount_name = "gcpdata"
    dbutils.fs.mount("gs://%s" % bucket_name, "/mnt/%s" % mount_name)
    ```
    * ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

<br/>

* ì €ëŠ” ì´ì „ì— ì§œë†¨ì—ˆë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. 

    ```python
    bucket_name = "nasagcp"
    mount_name = "gcpdat11"
    dbutils.fs.mount("gs://%s" % bucket_name, "/mnt/%s" % mount_name)


    from pyspark.context import SparkContext
    from pyspark.sql.session import SparkSession


    # ------------------------------------------------------------------
    def renameCols(df1, old_columns, new_columns):
        for old_col,new_col in zip(old_columns,new_columns):
            d1f = df1.withColumnRenamed(old_col,new_col)
        return df1


    # Old_columns
    old_columns = ['avg(min_temperature_air_2m_f)',
                    'avg(max_temperature_air_2m_f)',
                    'avg(avg_temperature_air_2m_f)'
                    ]

    # New_columns
    new_columns = ['temperature_air_min_avg',
                    'temperature_air_max_avg',
                    'temperature_air_avg_avg'
                    ]
    # --------------------------------------------
    # ----------------------

    # Read CSV from GCS
    df_lee = spark.read.csv("/mnt/gcpdat11/", header=True, inferSchema=True)

    # data transform
    df_lee = df_lee.groupBy('country', 'date').agg({'min_temperature_air_2m_f' : 'avg', 'max_temperature_air_2m_f' : 'avg', 'avg_temperature_air_2m_f' : 'avg'}).sort(desc('country')).orderBy('date')

    df_result = renameCols(df_lee, old_columns, new_columns)

    country1 = df_result.select("country")
    country_dis10 = df_result.select("country").distinct()
    print("country_count =",country_dis10.count())


    # Write CSV to GCS
    df_result.coalesce(1).write.option("header", "true").mode("overwrite").csv("/mnt/gcpdat11/dbfsre/")
    ```

    * ì´ì „ì— ë°›ì•„ë†¨ë˜ Covid-19 ê¸°ìƒ ë°ì´í„°ë¥¼ ì •ë ¬í•˜ëŠ” Code ì…ë‹ˆë‹¤.  

<br/> 


---

## ë§ˆì¹˜ë©°â€¦  

  
ì‚¬ì‹¤ DataBricksëŠ” ì‚¬ìš©ë²•ì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ë‚¨ê¸°ê¸°ì—ëŠ” ë„ˆë¬´ ê°„í¸í•©ë‹ˆë‹¤..  
ê·¸ë˜ì„œ ê·¸ë‚˜ë§ˆ ì–´ë ¤ì›€ì´ ìˆì„ ê²ƒ ê°™ì€ DBFS Mount ë¶€ë¶„ë§Œ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤.  



---

```toc
```
