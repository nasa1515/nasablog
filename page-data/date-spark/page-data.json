{"componentChunkName":"component---src-templates-blog-template-js","path":"/date-spark/","result":{"data":{"cur":{"id":"2a5bcac3-907a-58f0-81da-8f92654bc3e6","html":"<p>머리말  </p>\n<p>이번에는 데이터의 가장 기초적인 오픈소스인 Apache Spark에 대한 내용 정리입니다.<br>\n아무것도 모르는 생짜 초보이기 때문에 틀린 부분이 많을 수 있습니다.  </p>\n<hr>\n<h2 id=\"-apache-spark-hadoop\" style=\"position:relative;\"><a href=\"#-apache-spark-hadoop\" aria-label=\" apache spark hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Apache Spark? Hadoop?</h2>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109732527-b3018e80-7c00-11eb-8fc9-53e9618bfac5.JPG\" alt=\"캡처1\"></p>\n<p>주워들은 말로는 데이터 시장은 오픈소스인 Hadoop과 Apache가 경쟁하며 성장하고 있다고 알고 있다<br>\n그런데 또 다른 글들을 보니 이미 업계에서는 두 오픈소스를 동시에 사용한다고도 한다.<br>\n경쟁하는 관계인데 또 상생을 하고 있다는게 무슨소리지?<br>\n다시 한번 찾아보니 각각의 툴의 용도에 대해서 알지 못했던 나의 오착이었다.  </p>\n<br/>\n<p>내가 이해한 두 앱의 용도를 간단하게 설명해보면<br>\n우선 두 툴은 빅데이터 처리 플랫폼, 프레임워크라는 공통점을 가지고 있지만 </p>\n<ul>\n<li>\n<h3 id=\"hadoop\" style=\"position:relative;\"><a href=\"#hadoop\" aria-label=\"hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop</h3>\n<p>분산 데이터 Infrastructure를 주로 하며,<br>\n대량의 데이터를 Server Cluster 내 복수 노드들에 분산시키는 역할을 한다.<br>\n이를 통해 데이터 처리를 위한 필요한 하드웨어의 비용부담을 줄여준다.   </p>\n</li>\n</ul>\n<p>반면에 Spark는 분산 데이터 컬렉션 상부에서 동작하는 <code class=\"language-text\">데이터 프로세싱 툴</code>로<br>\n분산형 스토리지의 역할은 수행하지 않는다고 한다.<br>\n대충 이 대목에서 왜 두 오픈소스를 상생하면서 쓰는지 감이오기 시작했다.  </p>\n<p>Hadoop은 HDFS(Hadoop Database filesystem)을 사용하며 맵리듀스를 핵심 구성 요소로 제공한다.  따라서 Spark가 없어도 된다.<br>\n반대로 Spark도 HDFS가 아닌 AWS,GCP,Azure 등과 융합될 수 있기에 Hadoop이 없어도 된다.<br>\n그러나 Hadoop과 Spark를 같이 사용할때가 가장 적합하다고 한다.  </p>\n<br/>\n<p>두 툴의 확실한 차이는 속도에서 확인이 가능하다. </p>\n<p>일반적인 상황에서 Hadoop보다 스파크의 속도가 월등히 빠르다고 한다.<br>\n이유는 데이터 프로세싱 절차의 차이 때문인데<br>\nHadoop은 MapReduce를 사용하기 때문이고, Spark는 DataSet 전체를 한번에 다루기 때문에…<br>\n또한 아래에서 다시 설명하겠지만 Hadoop은 HW에서, Spark는 메모리에서 동작하기 때문이다..  </p>\n<br/>\n<ul>\n<li>\n<p>Hadoop의 Mapreduce WorkFlow  </p>\n<p>Input -> Splitting -> Mapping -> Shuffling -> Reducing -> Final Result</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109735558-4ee1c900-7c06-11eb-85aa-5fd05dc011f1.jpg\" alt=\"99F6AA445B5975A320\"></p>\n<p><em>INPUT : 먼저 클러스터에서 데이터를 읽고</em><br>\n<em>클라이언트->네임노드->클라이언트->데이터 노드-> 마스터(Job Tracker)</em><br>\n<em>태스크 단위로 쪼개어 Tasketracker(worker)에 배정하고</em><br>\n<em>Map 단계를 수행한 후, 중간 결과물을 로컬 디스크에 저장을 한다.</em><br>\n<em>그리고 그 결과물을 다시 combine, partioning을 거쳐 나온 2차 중간 결과물을 디스크에 분할 저장한다.</em><br>\n<em>그리고 최종적으로 shuffling을 통해 reduce 작업에 할당된 후</em><br>\n<em>reduce 작업을 거쳐 최종적으로 나온 결과물이 HDFS에 저장된다”.</em></p>\n</li>\n</ul>\n<br/>\n<p>이에 반해, 스파크는 모든 데이터 운영을 메모리 내에서 실시간에 가깝게 처리할 수 있다(인메모리).<br>\n데이터를 읽고, 처리 분석을 거친 결과물을 클러스터에 입력하는 전 과정이 동시에 진행되는 것이다.<br>\n배치 프로세싱 경우에 스파크가 10배 빠르고, 인 메모리 Analytics의 경우, 100배 빠르다고 알려져있다.   </p>\n<br/>\n<p>나는 여기서 왜 Spark가 더 좋은데 Hadoop을 쓰지? 라는 의문이 들었다.<br>\n그러나 대부분의 Data 운영, 리포팅 요구의 대부분이 정적인 것들이고 시간의 여유가 있다면 Mapreduce의 방식을 채택한다고 한다.<br>\n다만 Spark가 필수적으로 필요할 때가 있는데 이는 비즈니스 공장의 센서 등 실시간으로 수집되는 스트리밍 데이터를 처리하거나, ML 알고리즘과 같이 APP의 복합적인 운영을 할때라고 한다.<br>\n그리고 애초에 Hadoop만 사용하다가 위와 같이 실시간 적인 데이터 처리를 위해서 도입한 것이<br>\nSpark라서 그냥 두 툴을 같이 쓰는게 최적이라고 한다.  </p>\n<br/>\n<hr>\n<h2 id=\"-apache-spark\" style=\"position:relative;\"><a href=\"#-apache-spark\" aria-label=\" apache spark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✌ Apache Spark</h2>\n<p>그럼 간단하게 데이터 플랫폼 2개의 툴에 대해서 설명했으니<br>\n오늘 포스트의 주제인 Spark에 대한 내용으로 돌아와보자 </p>\n<ul>\n<li>\n<h3 id=\"spark의-구성-요소\" style=\"position:relative;\"><a href=\"#spark%EC%9D%98-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\" aria-label=\"spark의 구성 요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark의 구성 요소</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109738566-61aacc80-7c0b-11eb-9c66-5f50dff0e63b.jpg\" alt=\"components_of_spark\"></p>\n<p>Spark는 다음 그림과 같은 구성 요소를 가지고 있습니다.</p>\n</li>\n</ul>\n<h3 id=\"apache-spark-core\" style=\"position:relative;\"><a href=\"#apache-spark-core\" aria-label=\"apache spark core permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Apache Spark Core</h3>\n<ul>\n<li>Spark job과 다른 Spark 컴포넌트에 필요한 기본 기능을 제공합니다.  </li>\n<li>주로 분산 데이터 컬렉션(DataSet)을 추상화한 객체 RDD로 다양한 연산, 변환 메소드를 제공합니다.</li>\n<li>HDFS, GlusterFS, S3등 여러 Filsystem에 접근이 가능합니다.  </li>\n<li>공유 변수, 누적 변수를 사용해 컴퓨팅 노드 간 정보를 공유합니다.  </li>\n<li>Spark core에는 네트워킹, 보안, 스케쥴링 및 데이터 셔플링 등 기본 기능을 제공합니다.  </li>\n</ul>\n<h3 id=\"spark-sql\" style=\"position:relative;\"><a href=\"#spark-sql\" aria-label=\"spark sql permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark SQL</h3>\n<ul>\n<li>Spark와 하이브 SQL이 지원하는 SQL을 사용해 대규모 분산 정형 데이터를 다룰 수 있습니다.  </li>\n<li>JSON File, Parquet 파일, RDB 테이블, 하이브 테이블 등 여러 정형 데이터를 읽고 쓸 수 있습니다.  </li>\n<li>DataFrame 과 DataSet의 연산을 RDD 연산으로 변환해 일반 Spark job으로 실행.  </li>\n</ul>\n<h3 id=\"spark-streaming\" style=\"position:relative;\"><a href=\"#spark-streaming\" aria-label=\"spark streaming permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Streaming</h3>\n<ul>\n<li>실시간 스트리밍 데이터를 처리하는 프레임 워크.  </li>\n<li>HDFS, Kafka, Flume, 트위터 등 커스텀 리소스도 사용 가능합니다.</li>\n<li>다른 Spark 컴포넌트 겸용, 실시간 데이터 처리를 ML, SQL, Graph와 통합 연산이 가능.  </li>\n</ul>\n<h3 id=\"spark-mllib\" style=\"position:relative;\"><a href=\"#spark-mllib\" aria-label=\"spark mllib permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark MLlib</h3>\n<ul>\n<li>머신 러닝 알고리즘 라이브러리.</li>\n<li>RDD, DataFrame의 DataSet을 변환하는 머신 러닝 모델을 구현 가능.  </li>\n</ul>\n<h3 id=\"spark-graphx\" style=\"position:relative;\"><a href=\"#spark-graphx\" aria-label=\"spark graphx permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark GraphX</h3>\n<ul>\n<li>그래프 RDD 형태의 그래프 구조를 만들 수 있는 기능을 제공.</li>\n</ul>\n<br/>\n<h3 id=\"spark-cluster의-구조와-실행과정\" style=\"position:relative;\"><a href=\"#spark-cluster%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%EC%8B%A4%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"spark cluster의 구조와 실행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Cluster의 구조와 실행과정</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109743000-5491db80-7c13-11eb-9d18-516463788a2a.png\" alt=\"다운로드\"></p>\n<ul>\n<li>Spark Application은 실제 작업을 수행하는 역할이고  </li>\n<li>Cluster Manager는 Application 사이에 자원을 중계해주는 역할을 담당합니다.  </li>\n</ul>\n<br/>\n<h3 id=\"spark-application\" style=\"position:relative;\"><a href=\"#spark-application\" aria-label=\"spark application permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Application</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109753108-ff5ec580-7c24-11eb-989a-fd120dee21ad.png\" alt=\"다운로드\"></p>\n<p>Spark Application은 Driver 프로세스와 Excutors 두개로 구성됩니다.  </p>\n<ul>\n<li>Spark Driver (Master) : 한개의 노드에서만 실행되고, Spark 전체의 main()함수를 실행합니다.<br>\nApplication 내 정보의 유지관리, Excutors의 실행 및 실행 분석, 배포 등 Master의 역할을 수행합니다.<br>\n즉 간단하게 사용자가 구성한 JOB을 TASK 단위로 변환해 Executor로 전달합니다.  </li>\n</ul>\n<br/>\n<ul>\n<li>Executer (Worker Node) : 다수의 Worker Node에서 실행되는 프로세스<br>\nMaster(Spark Driver)가 할당한 작업(TASK)를 수행한 결과를 반환.<br>\n추가로 블록매니저를 통해서 Cache하는 RDD를 저장합니다.  </li>\n</ul>\n<br/>\n<h3 id=\"cluster-manager\" style=\"position:relative;\"><a href=\"#cluster-manager\" aria-label=\"cluster manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cluster Manager</h3>\n<p>이름 그대로 Spark Application의 Resource를 효율적으로 분배하는 역할을 담당합니다.<br>\n바로 위에서 Driver에서 Executors로 task를 할당하고 관리한다고 설명했는데<br>\n그 작업을 진행하기 위해 Clouster Mananger에 의존하고 있습니다.(없어선안됨…)<br>\n즉 TASK의 할당 및 관리는 Driver -> Executors 구조가 아니라<br>\nDriver &#x3C;-> Cluster Manager &#x3C;-> Executors 구조 입니다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109754173-e820d780-7c26-11eb-99e7-05e46796c3d8.JPG\" alt=\"222\"></p>\n<p>현재 Spark 3.0 기준 대표적인 Cluster Manager의 종류는 위 3가지 +  Spark StandAlone 입니다.<br>\n근데 대부분 YARN,k8s 두 종류만 사용하는 듯…?  </p>\n<p>다른 Manager는 이해가 되는데 StandAlone은 무슨말일까..?  </p>\n<ul>\n<li>StandAlone\nSpark StandAlone은 Cluster로 구성하지 않고 단일 컴퓨터에서 동작시키는 거였다.<br>\n원래라면 나눠져야 할 Driver와 Executor는 각각 Thread로 동작한다고 한다.<br>\nCluster로 구성한다면 Worker Node에 여러개의 Executor를 실행 시킬 수 있지만 StandAlone의 경우 1개씩만 동작한다.  </li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"spark-apis\" style=\"position:relative;\"><a href=\"#spark-apis\" aria-label=\"spark apis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark APIs</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109767953-9c2c5d80-7c3b-11eb-914f-00aee9d23e95.png\" alt=\"3rF6p\"></p>\n<p>Spark Application은 v1 ~ v3를 거쳐 다음과 같이 3가지의 APIs를 사용합니다.  </p>\n<h4 id=\"rdd-resillient-distributed-dataset\" style=\"position:relative;\"><a href=\"#rdd-resillient-distributed-dataset\" aria-label=\"rdd resillient distributed dataset permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RDD (Resillient Distributed DataSet)</h4>\n<p>RDD는 이름을 그대로 풀어쓰면 이해하기가 쉽습니다.  </p>\n<ul>\n<li>Resillient : Mem 내 데이터 손실 시 다시 생성이 가능하다</li>\n<li>Distributed : Cluster를 통해 메모리에 분산되어서 저장된다 (분산) </li>\n<li>DataSet : 파일을 통해 가져 올 수 있다. 변경되지 않는다.  </li>\n</ul>\n<p>정리하면 여러 분산 노드에 걸쳐서 저장되는 변경이 불가능한 데이터의 집합입니다.   </p>\n<p>RDD의 생성은 2가지 방법으로서 생성됩니다.  </p>\n<ul>\n<li>외부로 부터 Data를 로딩할때 (Disk)</li>\n<li>코드에서 생성된 Data를 저장할 때</li>\n</ul>\n<p>추가적으로 RDD에서 제공하는 Operations(function) 역시 2가지만 존재합니다.  </p>\n<ul>\n<li>\n<h4 id=\"transformation-변환--존재하는-rdd에서-새로운-rdd를-생성하는-함수\" style=\"position:relative;\"><a href=\"#transformation-%EB%B3%80%ED%99%98--%EC%A1%B4%EC%9E%AC%ED%95%98%EB%8A%94-rdd%EC%97%90%EC%84%9C-%EC%83%88%EB%A1%9C%EC%9A%B4-rdd%EB%A5%BC-%EC%83%9D%EC%84%B1%ED%95%98%EB%8A%94-%ED%95%A8%EC%88%98\" aria-label=\"transformation 변환  존재하는 rdd에서 새로운 rdd를 생성하는 함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Transformation (변환) : 존재하는 RDD에서 새로운 RDD를 생성하는 함수</h4>\n<ul>\n<li>예를 들어 {1,2,3,3} 의 값을 가진 RDD에 Transformation을 사용하면  </li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109771135-d0a21880-7c3f-11eb-841a-287b875cb201.JPG\" alt=\"캡처222\"></p>\n<ul>\n<li>추가적으로 {1,2,3},{3,4,5} 두 값을 가진 RDD의 경우 </li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109771264-f4655e80-7c3f-11eb-80d5-0ee52f6f90dc.JPG\" alt=\"캡처333\"></p>\n<p>그림을 보면 이해가 쉬울 것이다. 대충 RDD의 데이터를 가지고 사용하는 작업이니… </p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"action-액션--실제로-job을-실행하는-함수-값을-받아오거나-저장한다\" style=\"position:relative;\"><a href=\"#action-%EC%95%A1%EC%85%98--%EC%8B%A4%EC%A0%9C%EB%A1%9C-job%EC%9D%84-%EC%8B%A4%ED%96%89%ED%95%98%EB%8A%94-%ED%95%A8%EC%88%98-%EA%B0%92%EC%9D%84-%EB%B0%9B%EC%95%84%EC%98%A4%EA%B1%B0%EB%82%98-%EC%A0%80%EC%9E%A5%ED%95%9C%EB%8B%A4\" aria-label=\"action 액션  실제로 job을 실행하는 함수 값을 받아오거나 저장한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Action (액션) : 실제로 JOB을 실행하는 함수, 값을 받아오거나 저장한다.</h4>\n<ul>\n<li>예를 들어 {1,2,3,3} RDD에서 Action 함수를 사용하면  </li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109771572-502fe780-7c40-11eb-8c9c-8cd33e05c808.JPG\" alt=\"캡처4444\"></p>\n<p>reduce 함수를 예로 들면 rdd.reduce(x,y: x+y) 이다.<br>\n그럼 RDD {1,2,3,3}의 값들이 각각 x,y가 되어 합한 1+2+3+3 = 9가 연산 후 반환된다.  </p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>간단하게 위의 Flow를 요악한 그림</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109773128-2d063780-7c42-11eb-9872-47784860e468.png\" alt=\"다운로드33333\"></p>\n</li>\n</ul>\n<p>추가적인 함수의 경우 다른 포스트에서 정리 할 예정입니다.!!</p>\n<br/>\n<h4 id=\"dataframe\" style=\"position:relative;\"><a href=\"#dataframe\" aria-label=\"dataframe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataFrame</h4>\n<p>Spark v1.3 이후 부터 RDD에서 발전한 개념?<br>\n기존의 RDD의 단점들 속도, 최적화 등을 보완하였다고 합니다.<br>\n여기저기서 찾아본 것으로는 scala에서 다음과 같이 사용이 가능하다고 한다.  </p>\n<p>val df = spark.sql(“실행 Query”)  </p>\n<p>대충 이해하자면 스키마의 최적화부분? 비정형 dataset으로 이해했던 RDD와 다르게 정형 데이터 (테이블)식으로 처리하는 듯 하다.(SQL 사용가능)<br>\n근데 DataSet이 있어서 DataFrame은 완벽히 이해하고 넘어가지 않아도 될 듯??  </p>\n<br/>\n<h4 id=\"dataset\" style=\"position:relative;\"><a href=\"#dataset\" aria-label=\"dataset permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataSet</h4>\n<p>Spark v1.6에서 추가되었다고 합니다.<br>\n데이터 타입체크, 직렬화를 위한 인코더, 카탈리스트 옵티마이저를 지원하고<br>\n데이터 처리 속도를 더욱 증가시켰다고 하는데;;; 잘모르겠다..<br>\nSpark v2.0에서 DataFrame + Dataset = Dataset으로 통합되었다고 하고 따로 DataFrame을 선언하는 느낌인듯 합니다.  </p>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>Spark의 기본 개념의 50%정도는 이해한 것 같습니다.<br>\n다음 포스트에서는 마저 정리 못한 APIs와 JOB, STAGE, TASK에 대해서 정리 예정입니다. </p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#-apache-spark-hadoop\">✔ Apache Spark? Hadoop?</a></li>\n<li>\n<p><a href=\"#-apache-spark\">✌ Apache Spark</a></p>\n<ul>\n<li><a href=\"#apache-spark-core\">Apache Spark Core</a></li>\n<li><a href=\"#spark-sql\">Spark SQL</a></li>\n<li><a href=\"#spark-streaming\">Spark Streaming</a></li>\n<li><a href=\"#spark-mllib\">Spark MLlib</a></li>\n<li><a href=\"#spark-graphx\">Spark GraphX</a></li>\n<li><a href=\"#spark-cluster%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%EC%8B%A4%ED%96%89%EA%B3%BC%EC%A0%95\">Spark Cluster의 구조와 실행과정</a></li>\n<li><a href=\"#spark-application\">Spark Application</a></li>\n<li><a href=\"#cluster-manager\">Cluster Manager</a></li>\n<li>\n<p><a href=\"#spark-apis\">Spark APIs</a></p>\n<ul>\n<li><a href=\"#rdd-resillient-distributed-dataset\">RDD (Resillient Distributed DataSet)</a></li>\n<li><a href=\"#dataframe\">DataFrame</a></li>\n<li><a href=\"#dataset\">DataSet</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","excerpt":"머리말   이번에는 데이터의 가장 기초적인 오픈소스인 Apache Spark에 대한 내용 정리입니다. 아무것도 모르는 생짜 초보이기 때문에 틀린 부분이 많을 수 있습니다.   ✔ Apache Spark? Hadoop? 캡처1 주워들은 말로는 데이터 시장은 오픈소스인 Hadoop과 Apache가 경쟁하며 성장하고 있다고 알고 있다 그런데 또 다른 글들을 보니 이미 업계에서는 두 오픈소스를 동시에 사용한다고도 한다. 경쟁하는 관계인데 또 상생을 하고 있다는게 무슨소리지? 다시 한번 찾아보니 각각의 툴의 용도에 대해서 알지 못했던 나의 오착이었다.   내가 이해한 두 앱의 용도를 간단하게 설명해보면 우선 두 툴은 빅데이터 …","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Apache Spark란??","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/date-spark/"}},"next":{"id":"0c0f7578-bb81-557a-8d80-32a4858eeb47","html":"<p>머리말  </p>\n<p>이번 포스트로 이제 파이프라인에서 동작하는 전체적인 보안툴에 대한 포스트는 끝났습니다.<br>\n최종적으로는   </p>\n<ol>\n<li>SonarQube로 Build 될 이미지의 소스코드에 대한 전략적 정적분석을   </li>\n<li>Anchore로 빌드된 이미지에 대한 분석을  </li>\n<li>OWASP ZAP으로 배포 된 서비스에 대한 동적분석  </li>\n</ol>\n<p>위 세가지 보안 항복을 Jenkins를 이용해 자동화 하였습니다.</p>\n<hr>\n<ul>\n<li>\n<p>사용 할 툴을 다음과 같습니다.  </p>\n<ul>\n<li>Jenkins</li>\n<li>Sonarqube</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"-sonarqube-\" style=\"position:relative;\"><a href=\"#-sonarqube-\" aria-label=\" sonarqube  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ SonarQube ??</h2>\n<p>위키백과 왈</p>\n<p><em>소나큐브(SonarQube, 이전 이름: 소나/Sonar)는 20개 이상의 프로그래밍 언어에서 버그, 코드 스멜, 보안 취약점을 발견할 목적으로 정적 코드 분석으로 자동 리뷰를 수행하기 위한 지속적인 코드 품질 검사용 오픈 소스 플랫폼이다.<br>\n소나큐브는 중복 코드, 코딩 표준, 유닛 테스트, 코드 커버리지, 코드 복잡도, 주석, 버그 및 보안 취약점의 보고서를 제공한다.</em></p>\n<p>음 읽어보니 개발자들에게 유용한 정적분석 툴입니다.</p>\n<br/>\n<hr>\n<h3 id=\"sonarqube-설치\" style=\"position:relative;\"><a href=\"#sonarqube-%EC%84%A4%EC%B9%98\" aria-label=\"sonarqube 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SonarQube 설치</h3>\n<ul>\n<li>이번 포스트에서 SonarQube의 설치과정은 다루지 않습니다.<br>\n즉 이미 SonarQube 서버와, Jenkins 서버가 설치되었다는 가정하에 진행하였습니다.</li>\n</ul>\n<br/>\n<ul>\n<li>설치에 관련된 포스트는 <a href=\"https://www.lesstif.com/software-architect/sonarqube-39126262.html\">여기</a>를 참고해주세요</li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"jenkins-설정-a-namea2a\" style=\"position:relative;\"><a href=\"#jenkins-%EC%84%A4%EC%A0%95-a-namea2a\" aria-label=\"jenkins 설정 a namea2a permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Jenkins 설정 <a name=\"a2\"></a></h3>\n<br/>\n<ul>\n<li>\n<p>Jenkins 내에서 SonarQube를 사용하기 위해서는 아래 플러그인 설치가 필요합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103322025-cf0d7600-4a7f-11eb-8081-02b118e9b30c.PNG\" alt=\"AAAAAA\"></p>\n<ul>\n<li>자세한 플러그인 정보는 <a href=\"https://plugins.jenkins.io/sonar/\">링크</a> 확인해주세요</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>플러그인 설치가 완료되었다면 Jenkins 환경설정에서 Sonarqube 서버의 설정이 필요합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103322080-09771300-4a80-11eb-8022-2f2b6e12fd14.PNG\" alt=\"222222\"></p>\n<ul>\n<li>설치한 SonarQube 서버의 정보를 기입해줍니다</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>Jenkins Global tool configuration 탭에서 Scanner에 대한 설정을 합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103322135-54912600-4a80-11eb-8b21-23d6f51e0fea.PNG\" alt=\"3332131\"></p>\n<ul>\n<li>별다르게 상이하는 부분은 없이 동일하게 설정하면 동작됩니다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>파이프라인 프로젝트에서 SonarQube의 변수들을 선언 해줍니다(스크립트의 편의성을 위함)  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103388784-54f7f280-4b4e-11eb-8547-d643c8756523.png\" alt=\"KakaoTalk_20201228_200226180\"></p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103388805-6fca6700-4b4e-11eb-8064-e7896067a891.png\" alt=\"KakaoTalk_20201228_200226346\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>이제 SonarQube 서버에서 Jenkins 서버에 대한 Webhook을 설정합니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103322208-97eb9480-4a80-11eb-8848-bd3142e2bb53.PNG\" alt=\"3333333333\"></p>\n<ul>\n<li>Jenkins 서버의 IP와 Port로 웹훅을 걸어주시면 됩니다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>정상적으로 설정이 되었다면 다음과 같이 웹훅이 생성됩니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103322240-b6ea2680-4a80-11eb-9bfe-eb624f8054b9.PNG\" alt=\"AAAAAAAAAAADDDDD\"></p>\n</li>\n</ul>\n<p>이제 Jenkins에서 SonarQube를 사용 할 수 있습니다!!</p>\n<br/>\n<hr>\n<h3 id=\"jenkins-pipeline-script-수정\" style=\"position:relative;\"><a href=\"#jenkins-pipeline-script-%EC%88%98%EC%A0%95\" aria-label=\"jenkins pipeline script 수정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Jenkins Pipeline Script 수정</h3>\n<p>그럼 파이프라인 스크립트 내에 SonarQube와 관련된 내용을 삽입해보겠습니다.</p>\n<ul>\n<li>\n<p>파이프라인 내용</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token function\">properties</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n<span class=\"token function\">parameters</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n    <span class=\"token keyword\">string</span><span class=\"token punctuation\">(</span><span class=\"token named-parameter punctuation\">name</span><span class=\"token punctuation\">:</span> 'sonar<span class=\"token punctuation\">.</span>projectKey'<span class=\"token punctuation\">,</span> <span class=\"token named-parameter punctuation\">defaultValue</span><span class=\"token punctuation\">:</span> 'com<span class=\"token punctuation\">.</span>appsecco<span class=\"token punctuation\">:</span>dvja'<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token keyword\">string</span><span class=\"token punctuation\">(</span><span class=\"token named-parameter punctuation\">name</span><span class=\"token punctuation\">:</span> 'sonar<span class=\"token punctuation\">.</span>host<span class=\"token punctuation\">.</span>url'<span class=\"token punctuation\">,</span> <span class=\"token named-parameter punctuation\">defaultValue</span><span class=\"token punctuation\">:</span> 'http<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span><span class=\"token number\">34.64</span><span class=\"token number\">.237</span><span class=\"token number\">.112</span><span class=\"token punctuation\">:</span><span class=\"token number\">9000</span>'<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token keyword\">string</span><span class=\"token punctuation\">(</span><span class=\"token named-parameter punctuation\">name</span><span class=\"token punctuation\">:</span> 'sonar<span class=\"token punctuation\">.</span>login'<span class=\"token punctuation\">,</span> <span class=\"token named-parameter punctuation\">defaultValue</span><span class=\"token punctuation\">:</span> '608cacd6bb83c50712ebb34c4cba377c841cdebb'<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> \n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span></code></pre></div>\n<p>우선 간단하게 파이프라인을 작성하기위해 변수 설정을 했습니다.</p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>그리고 SonarQube와 SonarQube 내에있는 Dependency-Check를 작성해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\">        stage <span class=\"token punctuation\">(</span>'Dependency<span class=\"token operator\">-</span>Check Analysis'<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            steps <span class=\"token punctuation\">{</span>\n                sh '<span class=\"token operator\">/</span><span class=\"token keyword\">var</span><span class=\"token operator\">/</span>lib<span class=\"token operator\">/</span>jenkins<span class=\"token operator\">/</span>dependency<span class=\"token operator\">-</span>check<span class=\"token operator\">/</span>bin<span class=\"token operator\">/</span>dependency<span class=\"token operator\">-</span>check<span class=\"token punctuation\">.</span>sh <span class=\"token operator\">--</span>scan `pwd` <span class=\"token operator\">--</span>format XML <span class=\"token operator\">--</span><span class=\"token keyword\">out</span> <span class=\"token operator\">/</span><span class=\"token keyword\">var</span><span class=\"token operator\">/</span>lib<span class=\"token operator\">/</span>jenkins<span class=\"token operator\">/</span>workspace<span class=\"token operator\">/</span>ci<span class=\"token operator\">-</span>build<span class=\"token operator\">-</span>pipeline<span class=\"token operator\">/</span>dependency<span class=\"token operator\">-</span>check<span class=\"token operator\">-</span>report <span class=\"token operator\">--</span>prettyPrint'\n                \n                <span class=\"token class-name\">dependencyCheckPublisher</span> pattern<span class=\"token punctuation\">:</span> 'dependency<span class=\"token operator\">-</span>check<span class=\"token operator\">-</span>report<span class=\"token operator\">/</span>dependency<span class=\"token operator\">-</span>check<span class=\"token operator\">-</span>report<span class=\"token punctuation\">.</span>xml'\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span>\n        <span class=\"token function\">stage</span><span class=\"token punctuation\">(</span>'Sonarqube <span class=\"token keyword\">and</span> Quality gate'<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n            options <span class=\"token punctuation\">{</span>\n                timeout<span class=\"token return-type class-name\"><span class=\"token punctuation\">(</span>time<span class=\"token punctuation\">:</span> 5<span class=\"token punctuation\">,</span> unit<span class=\"token punctuation\">:</span> 'MINUTES'<span class=\"token punctuation\">)</span></span>\n                <span class=\"token function\">retry</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">}</span>\n            steps <span class=\"token punctuation\">{</span>\n                <span class=\"token function\">withSonarQubeEnv</span><span class=\"token punctuation\">(</span>'SonarQube Server'<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                    sh <span class=\"token string\">\"mvn sonar:sonar\"</span>\n                <span class=\"token punctuation\">}</span>\n                script <span class=\"token punctuation\">{</span>\n                    qualitygate <span class=\"token operator\">=</span> <span class=\"token function\">waitForQualityGate</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>qualitygate<span class=\"token punctuation\">.</span>status <span class=\"token operator\">!=</span> <span class=\"token string\">\"OK\"</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n                        currentBuild<span class=\"token punctuation\">.</span>result <span class=\"token operator\">=</span> <span class=\"token string\">\"FAILURE\"</span>\n                    <span class=\"token punctuation\">}</span>\n                <span class=\"token punctuation\">}</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span></code></pre></div>\n<br/>\n</li>\n</ul>\n<p>여기까지만 하면 파이프라인 내에서는 SonarQube는 정상동작합니다.</p>\n<hr>\n<h3 id=\"파이프라인-실행-결과\" style=\"position:relative;\"><a href=\"#%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%8B%A4%ED%96%89-%EA%B2%B0%EA%B3%BC\" aria-label=\"파이프라인 실행 결과 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>파이프라인 실행 결과</h3>\n<ul>\n<li>\n<p>이제 모든 파이프라인 구성이 완료되었습니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103388929-262e4c00-4b4f-11eb-8ff4-ac9d873625eb.PNG\" alt=\"캡처\"></p>\n<ul>\n<li>파이프라인 스크립트의 STAGE별 순서 진행도를 위와같이 확인 할 수 있습니다.</li>\n<li>또한 SonarQube의 분석 결과 그래프도 위와 같이 확인 할 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>SonarQube의 Check-style 등의 경우 다른 리포트를 생성합니다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/103388989-91781e00-4b4f-11eb-8614-1ebeac419ec4.png\" alt=\"KakaoTalk_20201228_200227145\"></p>\n<ul>\n<li>PASSED의 경우 사용자가 ERROR Level을 임의로 설정 할 수 있습니다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>진행한 프로젝트의 보안툴은 모두 마무리 되었습니다.<br>\n미리 미리 정리해놓았던 문서들을 다시 보면서 정리하려고 힘들을 느끼고 있습니다.<br>\n사실 문서화가 가장 중요하다고 생각하지만 업무를 진행하면서 실시간으로 문서화하기는 정말 쉽지 않습니다.<br>\n그래도 블로그 글을 꾸준히 포스트하고 공부하려면 필요 한 일들이니 노력해보겠습니다.  </p>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#-sonarqube-\">✔ SonarQube ??</a></p>\n<ul>\n<li><a href=\"#sonarqube-%EC%84%A4%EC%B9%98\">SonarQube 설치</a></li>\n<li><a href=\"#jenkins-%EC%84%A4%EC%A0%95-a-namea2a\">Jenkins 설정 <a name=\"a2\"></a></a></li>\n<li><a href=\"#jenkins-pipeline-script-%EC%88%98%EC%A0%95\">Jenkins Pipeline Script 수정</a></li>\n<li><a href=\"#%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%8B%A4%ED%96%89-%EA%B2%B0%EA%B3%BC\">파이프라인 실행 결과</a></li>\n</ul>\n</li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","frontmatter":{"date":"August 12, 2021","title":"[DEVOPS] - SonarQube With Jenkins","categories":"DevOps","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/devops-sonarqube/"}},"prev":{"id":"e82d4a67-91b1-5218-9fc2-35c7377e5ffc","html":"<p>머리말  </p>\n<p>이번 내용은 이전에 Spark의 이론적인 설명을 이어서 더 대표적인 Hadoop에 대해서 이론적인 내용들을 정리해보는 포스트입니다.<br>\n저는 여러 포스트로 실제 Cluster를 구축하긴 했지만 HDFS가 데이터를 어떻게 저장하는지, ecosystem이 뭐지? 라는<br>\n의문이 많이 남았기에 궁금한 내용들을 정리할 필요를 느꼈습니다.  </p>\n<hr>\n<h2 id=\"-apache-hadoop\" style=\"position:relative;\"><a href=\"#-apache-hadoop\" aria-label=\" apache hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Apache Hadoop?</h2>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110746690-8395f600-8280-11eb-867b-616f6c82b8fb.JPG\" alt=\"1111123123\"></p>\n<p>Hadoop : <em>하둡 소프트웨어 라이브러리는 간단한 프로그래밍 모델을 사용하여<br>\n여러대의 컴퓨터 클러스터에서 대규모 데이터 세트를 분산 처리 할 수있게 해주는 프레임워크 이다.</em></p>\n<p>라고 모든 글에서 설명을 하는데 나는 그냥 데이터를 분산 저장하는 파일시스템이라고 이해했다.<br>\n솔직히 아직 많이 다뤄보지 못해서 정확한 의미는 잘 모르겠고<br>\n가장 주력으로 두고 있는 HDFS와 MapReduce 방식을 이해하면 프레임 워크라는게 어떤 말인지 대충 이해는 가고<br>\n나아가서는 EcoSystem에 대해 이해를 한다면 어떤 느낌인지 감이 올 것같다.  </p>\n<p>하둡의 초기에 HDFS, MapReduce 프레임워크로 시작되었으나<br>\n현재에는 여러 데이터저장, 실행엔진, 프로그래밍 및 데이터처리 같이<br>\n하둡 생태계 (Hadoop Ecosystem)을 포함하는 의미로 확장 발전 되었다고 한다.</p>\n<br/>\n<ul>\n<li>\n<h3 id=\"hadoop-ecosystem\" style=\"position:relative;\"><a href=\"#hadoop-ecosystem\" aria-label=\"hadoop ecosystem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop Ecosystem</h3>\n<p>위에서 Hadoop을 분산 FrameWork이라고 설명했었는데<br>\nHadoop Ecosystem이 그 FrameWork을 이루는 프로젝트의 모임이라고 생각하면 된다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110749647-be9a2880-8284-11eb-81ba-ab6f7a2e6dc1.png\" alt=\"123123123\"></p>\n<br/>\n<p>이 많은 Service 들을 정리하면 다음과 같다. </p>\n<ul>\n<li>Hadoop Core Project : HDFS(분산 데이터 저장), MapReduce(분산 처리)</li>\n<li>Hadoop Sub Project : 나머지 프로젝트 -> 데이터 마이닝, 수집, 분석 등을 수행한다.</li>\n</ul>\n<p>너무 많은 서비스에 저도 이해가 잘 안되서 간단하게 정리를 해봤습니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110750345-ad055080-8285-11eb-88f1-822e3be5c029.JPG\" alt=\"11111123233\"></p>\n<br/>\n<p>다른 분들이 각 프로젝트 들에 대해서 잘 정리해놓은 것도 있네요</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110750466-db832b80-8285-11eb-8361-c32461fc97b8.JPG\" alt=\"33333333\"></p>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"-hadoop-ecosystem-core-구성-요소\" style=\"position:relative;\"><a href=\"#-hadoop-ecosystem-core-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\" aria-label=\" hadoop ecosystem core 구성 요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✌ Hadoop EcoSystem Core 구성 요소</h2>\n<br/>\n<ul>\n<li>\n<h3 id=\"hdfs-hadoop-distributed-file-system\" style=\"position:relative;\"><a href=\"#hdfs-hadoop-distributed-file-system\" aria-label=\"hdfs hadoop distributed file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS (Hadoop Distributed File System)</h3>\n<p>Hadoop Ecosystem의 환경에서 데이터를 저장하는 분산형 파일 시스템<br>\nHDFS는 Hadoop Framework을 위해 JAVA로 작성된 분산 확장 파일 시스템입니다.<br>\nHDFS는 대용량 파일을 여러 서버에 나누고, 중복 저장함으로써 안정성을 높힙니다. </p>\n<br/>\n</li>\n<li>\n<h4 id=\"특징\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95\" aria-label=\"특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h4>\n<ol>\n<li>HDFS는 다수의 노드에 복제 데이터도 함께 저장해 데이터 유실을 방지한다.  </li>\n<li>HDFS에 저장된 파일을 조회하려면 스트리밍 방식으로 데이터에 접근해야한다  </li>\n<li>한번 저장한 데이터는 수정할 수 없고, 읽기만 가능해서 데이터 무결성을 유지한다.<br>\n4.데이터 수정은 불가능하지만 파일 이동, 삭제, 복사할 수 있는 인터페이스를 제공한다.</li>\n</ol>\n<br/>\n</li>\n<li>\n<h4 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110756535-aed31200-828d-11eb-8d1e-e2bd0843713f.JPG\" alt=\"222211312\"></p>\n<p>HDFS는 마스터/슬레이브(master/slave)구조를 가집니다. </p>\n<br/>\n</li>\n<li>\n<h4 id=\"hdfs의-특징\" style=\"position:relative;\"><a href=\"#hdfs%EC%9D%98-%ED%8A%B9%EC%A7%95\" aria-label=\"hdfs의 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS의 특징</h4>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> Block 구조의 FileSystem<span class=\"token punctuation\">,</span> 저장파일은 특정 사이즈의 Block으로 나눠져 분산된 서버에 저장된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> 하나의 Block은 <span class=\"token number\">3</span>개<span class=\"token punctuation\">(</span>수정 가능<span class=\"token punctuation\">)</span>로 복제되며<span class=\"token punctuation\">,</span> 각각 다른 HDFS의 DataNode에 분산저장된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> HDFS에는 NameNode 서버 한 대<span class=\"token punctuation\">,</span> Slave 역할을 하는 DataNode 서버가 여러 대로 구성된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> NameNode는 HDFS의 모든 <span class=\"token function\">Metadata</span><span class=\"token punctuation\">(</span>블록들이 저장되는 디렉토리의 이름<span class=\"token punctuation\">,</span> 파일명등<span class=\"token range operator\">..</span><span class=\"token punctuation\">)</span>를 관리하고  \n   Client가 이를 이용하여 HDFS에 저장된 파일에 접근할 수 있다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> 하둡 어플리케이션은 HDFS에 파일을 저장하거나<span class=\"token punctuation\">,</span> 저장된 파일을 읽기 위해 HDFS Client를 사용하며 API형태로 사용자에게 제공된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> DataNode는 주기적으로  HeartBeat 전송한다 \n   <span class=\"token punctuation\">(</span>NameNode에서 <span class=\"token class-name\">Block</span> Report <span class=\"token punctuation\">:</span> 노드에 저장되어 있는 블록의 정보 <span class=\"token operator\">=</span> Metadata<span class=\"token punctuation\">)</span>\n   이를 통해 NameNode는 DataNode가 정상 동작하는지 확인한다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">7</span><span class=\"token punctuation\">.</span> Clients는 NameNode에 접속해서 원하는 파일이 저장된 블록의 위치를 확인하고<span class=\"token punctuation\">,</span>  \n   해당 Block이 저장된 DataNode에서 직접 데이터를 조회한다<span class=\"token punctuation\">.</span>  </code></pre></div>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"hdfs-file-저장-flow\" style=\"position:relative;\"><a href=\"#hdfs-file-%EC%A0%80%EC%9E%A5-flow\" aria-label=\"hdfs file 저장 flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS File 저장 Flow</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110758607-0bcfc780-8290-11eb-91ad-1b1e234128d2.png\" alt=\"다운로드11\"></p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> APP이 Client에게 파일 저장을 요청  \n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> Client는 NameNode에게 Block이 저장될 경로 생성을 요청한다<span class=\"token punctuation\">.</span> \n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> NameNode는 해당 경로가 존재하지 않으면 생성한 뒤  \n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> NameNode는 그 경로에 수정하지 못하게 LOCKING을 걸어둡니다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> 그 후 Client에게 Block을 저장할 DataNode 목록을 반환하고  \n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> Client는 첫번째 DataNode에 Data Block을 전송 \n\n<span class=\"token number\">7</span><span class=\"token punctuation\">.</span> 첫번째 DataNode는 Local에 저장한 뒤 두번째 DataNode로 전송 \n\n<span class=\"token number\">8</span><span class=\"token punctuation\">.</span> 두번째 DataNode는 동일하게 저장한 뒤 세번째로 전송 \n\n<span class=\"token number\">9</span><span class=\"token punctuation\">.</span> 세번째 DataNode부터 Local에 저장완료 후 넘겨준 DataNode에게 완료 Return을 준다 \n\n<span class=\"token number\">10</span><span class=\"token punctuation\">.</span> 최종적으로는 첫번째 DataNode가 Client에게 저장완료를 Return</code></pre></div>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"hdfs-file-읽기-flow\" style=\"position:relative;\"><a href=\"#hdfs-file-%EC%9D%BD%EA%B8%B0-flow\" aria-label=\"hdfs file 읽기 flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS File 읽기 Flow</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110759735-471ec600-8291-11eb-9e63-5e5164a004d1.png\" alt=\"64982211\"></p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> APP이 Client에게 파일 읽기를 요청\n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> Client는 NameNode에게 파일이 어느 DataNode의 어떤 블록에 저장되어 있는지 정보를 요청\n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> MetaData를 통해 파일이 저장된 블록 리스트를 Client에게 반환\n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> Client는 해당 DataNode에 접근해 Block 조회 요청\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> DataNode는 Client에게 요청된 Block을 전송\n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> Client는 App에 데이터를 전달</code></pre></div>\n<br/>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<h3 id=\"mapreduce-a-namea4a\" style=\"position:relative;\"><a href=\"#mapreduce-a-namea4a\" aria-label=\"mapreduce a namea4a permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce <a name=\"a4\"></a></h3>\n<p>대용량의 데이터 처리를 위한 분산 프로그래밍 Model, 소프트웨어 FrameWork라고 불린다.<br>\n대규모 분산 컴퓨팅 환경에서 MapReduce를 이용해 대량의 데이터를 병렬로 분석이 가능하고<br>\n직접 작성하는 Map과 Reduce 라는 두 개의 메소드로 구성된다.<br>\n요새는 HIVE등 SQL과 유사한 구문으로 MapReduce Code를 만들어 사용한다.</p>\n<p>MapReduce는 Hadoop 클러스터의 데이터를 처리하기 위한 시스템으로,<br>\n총 2개 Map , Reduce의 phase로 구성되어 있다.</p>\n<p>Map과 Reduce사이에는 Shuffle과 Sort라는 스테이지가 존재한다.<br>\n각 Map Task는 전체 데이터 세트에 대한 별개의 부분에 대한 작업을 수행하게 되는데<br>\n기본적으로 하나의 HDFS Block을 대상으로 수행하게 된다.<br>\n모든 Map Task가 종료되면 MapReduce 시스템은 intermediate<br>\n데이터를 Reduce phase를 수행할 노드로 분산하여 전송한다.</p>\n<br/>\n</li>\n<li>\n<h4 id=\"map--reduce\" style=\"position:relative;\"><a href=\"#map--reduce\" aria-label=\"map  reduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MAP &#x26; REDUCE</h4>\n<p>똑똑한 1명이 다량의 일을 처리하는 것<br>\n평범한 100명이 다량의 일을 처리하는 것<br>\n상식적으로 둘 중에 100명 진행하는 것이 훨씬 더 빠를 것이다.<br>\n위의 예가 분산처리의 핵심이지만 100명 각각의 결과를 취합하고 정리하는 시간의 소모도 크다.<br>\n또한 탐색할 데이터가 비정형이라서 갯수가 101개라거나, 길이가 서로 다르다거나 하면<br>\n이를 동일한 업무크기로 나누는 일도 쉽지가 않다.</p>\n<h3 id=\"mapreduce는-이러한-처리를-도와주는-역할을-한다\" style=\"position:relative;\"><a href=\"#mapreduce%EB%8A%94-%EC%9D%B4%EB%9F%AC%ED%95%9C-%EC%B2%98%EB%A6%AC%EB%A5%BC-%EB%8F%84%EC%99%80%EC%A3%BC%EB%8A%94-%EC%97%AD%ED%95%A0%EC%9D%84-%ED%95%9C%EB%8B%A4\" aria-label=\"mapreduce는 이러한 처리를 도와주는 역할을 한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce는 이러한 처리를 도와주는 역할을 한다.</h3>\n<br>\n</li>\n<li>\n<h4 id=\"분산형-파일시스템에서는\" style=\"position:relative;\"><a href=\"#%EB%B6%84%EC%82%B0%ED%98%95-%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C%EB%8A%94\" aria-label=\"분산형 파일시스템에서는 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>분산형 파일시스템에서는?</h4>\n<p>① MapReduce 작업이 끝나면 HDFS에 파일이 써지고(write)<br>\n② MapReduce 작업이 시작될 때는 HDFS로 부터 파일을 가져오는(Read) 작업이 수행된다.</p>\n<p>MapReduce는 명칭 그대로 Map단계 &#x26; Reduce단계로 이루어진다.</p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h3 id=\"map\" style=\"position:relative;\"><a href=\"#map\" aria-label=\"map permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MAP</h3>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110880244-aa583900-8321-11eb-8a05-de07fbfd261d.png\" alt=\"111111\"></p>\n<ul>\n<li>위의 그림처럼 흩어져 있는 분산 클러스터에서 각각의 데이터를 <code class=\"language-text\">(key, value의 형태)</code>로 분류합니다.  </li>\n<li>MapReduce의 Job의 입력 크기를 <code class=\"language-text\">스플릿</code>이라고 합니다<br>\n-> 각 스플릿마다 하나의 Map Task를 생성하게되고<br>\n-> 만들어진 Map Task는 스플릿의 레코드를 Map 함수로 처리<br>\n-> (key, value) 구조를 가지는 중간 산출물이 생성!</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h3 id=\"reduce\" style=\"position:relative;\"><a href=\"#reduce\" aria-label=\"reduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reduce</h3>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110882149-d88b4800-8324-11eb-9370-ba6df69a549d.png\" alt=\"11123323\"></p>\n<p>위의 그림은 문자열 데이터를 포함된 단어의 빈도 별로 나눠 출력해주는 Reduce 과정입니다.<br>\nMapReduce는 다음과 같은 과정으로 데이터를 다룹니다.</p>\n<ul>\n<li>Splitting : 문자열 데이터를 라인별로 나누는 과정</li>\n<li>Mapping : 라인별로 문자열을 입력 -> (key, value) 형태로 출력</li>\n<li>Shuffling : 같은 key를 가지는 데이터끼리 분류</li>\n<li>Reducing : 각 key 별로 빈도수를 합산해서 출력</li>\n<li>Final Result : 리듀스 메소드의 출력 데이터를 합쳐서 하둡 파일시스템에 저장</li>\n</ul>\n<br/>\n</li>\n<li>\n<p>간단하게 Map, Reduce 영역을 분리한 그림 </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110893271-fa8ec580-8338-11eb-883a-a4b715313a3d.png\" alt=\"33333\"></p>\n</li>\n</ul>\n<br>\n<ul>\n<li>\n<h3 id=\"mapreduce-jop\" style=\"position:relative;\"><a href=\"#mapreduce-jop\" aria-label=\"mapreduce jop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce Jop</h3>\n<p>Job은 ‘Full Program’ 즉, 전체 프로그램을 의미합니다.<br>\n데이터 집합을 통해 Mapper와 Reducer를 전체 실행하고<br>\nTask는 데이터 Block을 통해 하나의 Mapper 또는 Reducer를 실행하게 됩니다.</p>\n<ul>\n<li>Client가 수행하려는 작업단위<br>\n입력데이터, 맵리듀스 프로그램, 설정 정보로 구성.</li>\n<li>Hadoop은 Job을 Map Task와 Reduce Task로 작업을 나누어서 실행</li>\n<li>Job이 실행되는 과정을 제어 해주는 노드</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"mapreduce-시스템-구성\" style=\"position:relative;\"><a href=\"#mapreduce-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B5%AC%EC%84%B1\" aria-label=\"mapreduce 시스템 구성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce 시스템 구성</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110894214-cfa57100-833a-11eb-9a91-388e8d72ce48.png\" alt=\"image44444\"></p>\n<p>MapReduce System은 Client, JobTracker, TaskTracker로 구성된다.</p>\n<ul>\n<li>JobTracker 는 NameNode(Master)에 위치</li>\n<li>TaskTracker 는 DataNode(Slave)에 위치</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"client\" style=\"position:relative;\"><a href=\"#client\" aria-label=\"client permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Client</h3>\n<p>분석하고자 하는 데이터를 Job의 형태로 JobTracker에게 전달한다.</p>\n<br/>\n</li>\n<li>\n<h3 id=\"jobtracker\" style=\"position:relative;\"><a href=\"#jobtracker\" aria-label=\"jobtracker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>JobTracker</h3>\n<ul>\n<li>NameNode에 위치  </li>\n<li>Hadoop Cluster의 전체 Job들을 스케줄링하고 모니터링</li>\n</ul>\n<p>맵 리듀스 Job들은 JobTracker라는 소프트웨어 데몬에 의해 제어된다.<br>\nJobTracker들은 다음과 같은 역할을 수행한다.</p>\n<ul>\n<li>\n<ol>\n<li>Client는 MapReduce의 Job을 JobTracker에게 보낸다  </li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li>JobTracker는 Clsuter의 다른 노드들에게 맵과 리듀스 Task를 할당한다.  </li>\n</ol>\n</li>\n<li>\n<ol start=\"3\">\n<li>해당 노드들은 TaskTracker라는 데몬에 의해 각각 실행되고  </li>\n</ol>\n</li>\n<li>\n<ol start=\"4\">\n<li>TaskTracker는 Map,Reduce Task를 인스턴스화 한 뒤 진행 상황을 JobTracker에게 보고한다.</li>\n</ol>\n</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"tasktracker\" style=\"position:relative;\"><a href=\"#tasktracker\" aria-label=\"tasktracker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TaskTracker</h3>\n<ul>\n<li>DataNode에서 실행되는 데몬 (DataNode에 위치)</li>\n<li>사용자가 설정한 맵리듀스 프로그램을 실행해 JobTracker로부터 작업을 요청받은뒤  </li>\n<li>Map과 Reduce 요청 개수만큼 Map,Reduce Task를 생성한 뒤 JobTracker에게 보고한다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>이번 포스트에서는 Hadoop에 대한 간단한 설명들과 EcoSyetem의 Core Preeject 부분을 자세히 살펴봤습니다.<br>\n원래 Sub까지 한 포스트에서 다루려고 했지만 포스트가 너무 길어져서 다음포스트에서 이어서 설명하겠습니다.    </p>\n<br/>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#-apache-hadoop\">✔ Apache Hadoop?</a></li>\n<li><a href=\"#-hadoop-ecosystem-core-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\">✌ Hadoop EcoSystem Core 구성 요소</a></li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Apache Hadoop, HDFS, MapReduce","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/data-hadoop/"}},"site":{"siteMetadata":{"siteUrl":"https://nasa1515.com","comments":{"utterances":{"repo":"nasa1515/nasablog"}}}}},"pageContext":{"slug":"/date-spark/","nextSlug":"/devops-sonarqube/","prevSlug":"/data-hadoop/"}},"staticQueryHashes":["1073350324","2938748437"]}