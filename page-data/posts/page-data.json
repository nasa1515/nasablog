{"componentChunkName":"component---src-templates-category-template-js","path":"/posts","result":{"pageContext":{"currentCategory":"All","categories":["All","CLOUD","DevOps","LINUX","DATA","Error-Report","NETWORK"],"edges":[{"node":{"id":"501a1b19-d923-56be-afa0-39e4052fe194","excerpt":"머리말   안녕하세요 NASA1515입니다. 굉장히 오랜만에 글을 씁니다. (회사 일, 개인사정 등등 바쁜일이 참 많았습니다..) 아무튼…2022년 4월부터 그래도 주당 하나의 포스트는 작성해보자의 마인드로 블로그를 운영해보려고 합니다. 사실 추가 글을 작성하지 않아도, adsence 수익을 쌓이니깐 나태해진 이유가 크긴합니다..    ✔ ORACLE Install 서론 없이 바로 Oracle을 설치해보도록 하죠 Oracle은 기본 Linux에 깔게되면 파라메터 등등 귀찮아 지는 작업들이 많기 때문데 Azure에서 제공해주는 DataBase Image를 사용하도록 하겠습니다.   Disk 증설!  Azure VM의 S…","fields":{"slug":"/azure-oracle19/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Oracle 19c 설치, LogMiner, CDC 설정하기 From Azure VM","date":"April 01, 2022"}},"next":{"fields":{"slug":"/azure-chatbot/"}},"previous":null},{"node":{"id":"ae20c5ad-ffd3-5801-9cbf-a67512c9d035","excerpt":"머리말   이번 포스트도 역시 파이썬을 첨가했습니다. MicroSoft에서 제공하는 BotFramework을 사용해서 간단한 질답을 하는 ChatBot을 생성한 뒤 Azure Web에 배포하고 Teams App에 연동 해보겠습니다.   ✔ BotFrameWork MicroSoft에서 제공하고 있는 Chatbot SDK OpenSource 입니다. C#, JS, Python, Java 등 여러 언어를 사용해서 SDK를 사용 할 수 있고 제작한 템플릿을 쉽게 Azure의 Service와 연동 할 수 있습니다.   GITHUB   ✌ 1. Bot 생성 바로 Bot 생성에 앞서 진행 전 선행조건을 만족해야합니다.  👍 Fra…","fields":{"slug":"/azure-chatbot/"},"frontmatter":{"categories":"CLOUD DATA","title":"[DATA, AZURE] - MicroSoft BotFrameWork with Python to Azure","date":"October 24, 2021"}},"next":{"fields":{"slug":"/data-databricks/"}},"previous":{"fields":{"slug":"/azure-oracle19/"}}},{"node":{"id":"14668db0-2f50-511a-abf9-9d92fcdc88bd","excerpt":"머리말   저번 포스트에서 DataProc에 대한 설명과 간단한 사용법을 다뤄봤었습니다. 이번에는 GCP에서 파트너 SaaS형태로 제공해주는 DataBricks를 사용해서 지난번과 동일한 데이터, 스트립트를 이용해서 성능이나, 사용법에 대한 테스트를 해봤습니다. 물논 이번에도 파이썬을 첨가해서   ✔ DataBricks? og-databricks Databricks란? 간단 요약해서 Spark,Hadoop 등 빅데이터 관련 솔루션 실행환경을 제공하는 클라우드 서비스입니다. 통합 분석 플랫폼으로, 한 WorkSpace내에서 여러 서비스를 사용해 모든 분석이 가능합니다. 이전에 Spark, Hadoop을 ON-Premis…","fields":{"slug":"/data-databricks/"},"frontmatter":{"categories":"CLOUD DATA","title":"[DATA, GCP] - GCP DataBricks 사용기","date":"September 12, 2021"}},"next":{"fields":{"slug":"/gcp-dataproc2/"}},"previous":{"fields":{"slug":"/azure-chatbot/"}}},{"node":{"id":"c0b1f1d9-1ce1-51df-9998-f2fdcca0e5a7","excerpt":"머리말   저번 포스트에서 DataProc에 대한 설명과 간단한 사용법을 다뤄봤었습니다. 이번에는 DataProc Cluster에 Pyspark Script를 사용해서 \n자동화 JOB을 만들어 보겠습니다. 파이썬을 첨가해서   ✔ Data Data의 경우에는 이전 포스트에서 다뤘었던 Covid-19의 기상 데이터를 기반으로 진행합니다.   12312312 용량 : 약 51GB 행 : 542,304,210 2222 데이터 형식 요약 👍 Python Script 위의 데이터에서 특정 그룹(나라, 날짜) 별로 MAX,MIN,AVG 값들의 평균 값을 구하는 스크립트  간단 설명 : GCS에서 CSV Format의 Data를 …","fields":{"slug":"/gcp-dataproc2/"},"frontmatter":{"categories":"CLOUD DATA","title":"[DATA, GCP] - GCP DataProc 2탄 Pyspark JOB Access","date":"September 10, 2021"}},"next":{"fields":{"slug":"/gcp-dataproc/"}},"previous":{"fields":{"slug":"/data-databricks/"}}},{"node":{"id":"f1eefdc3-7c74-544e-b4c9-728dcf1c72c7","excerpt":"머리말   이번에는 DataProc(Hadoop/Spark)를 사용하여 \n대용량의 데이터를 처리하는 방법에 대해서 다룹니다. 물론 파이썬을 첨가해서   ✔ DataProc에 대해서.. Dataproc은 일괄 처리, 쿼리, 스트리밍, 머신 러닝에 오픈소스 데이터 도구를 활용할 수 있는 관리형 Spark 및 Hadoop 서비스입니다. 즉 지금까지 귀찮게 Spark, Hadoop을 연동하는 과정을 없애고 사용만하면 되는 서비스라고 볼 수 있습니다.   여기서 DataFlow와 DataProc의 차이에 대해서 궁금증이 생겼는데 두 툴 모두 ETL을 하는 툴에 대해서는 공통점을 가지고 있지만 DataFlow는 Serverles…","fields":{"slug":"/gcp-dataproc/"},"frontmatter":{"categories":"CLOUD DATA","title":"[DATA, GCP] - GCP DataProc spark Cluster로 ETL 후 BigQuery에 적재","date":"September 08, 2021"}},"next":{"fields":{"slug":"/azure-datafactory/"}},"previous":{"fields":{"slug":"/gcp-dataproc2/"}}},{"node":{"id":"899a2ae9-4b12-5939-9578-b5831fff8cb9","excerpt":"머리말   요 근래 블로그 Rebuild, 업무 등등등…너무 바쁜 하루였습니다. (🤦‍♂️ 아직도 바쁘긴 하지만;;) 그래도 주말, 퇴근 이후에 기술공부 하는 시간 중에 쪼끔이나마 짬을내 블로그 업데이트를 하려고 노력중입니다!! 이번 포스트에서는 Azure의 DataFactory의 이론적인 내용과 실제 Oracle DB의 데이터를 수집하는 내용입니다. ✔ Azure DataFactory? image\n데이터 이동을 오케스트레이션하고 데이터를 변환하는 데이터 워크플로를 만들 수 있는 클라우드 기반 ETL 및 데이터 통합 서비스 서로 다른 데이터 저장소의 데이터를 수집할 수 있는 데이터 기반 워크플로(파이프라인이라고 함)를 만들…","fields":{"slug":"/azure-datafactory/"},"frontmatter":{"categories":"CLOUD DATA","title":"[DATA, AZURE] Azure DataFactory로 Oracle Data 수집하기","date":"September 05, 2021"}},"next":{"fields":{"slug":"/data-gcpdataflow/"}},"previous":{"fields":{"slug":"/gcp-dataproc/"}}},{"node":{"id":"d7e3e240-ef5e-5891-af05-6c06162c25f1","excerpt":"머리말   요즘 포스트를 작성 할 시간이 부족했습니다…(일…) 그래서 오랜만에 포스트를 올린 기념으로 이번 내용을 더욱 알차게 준비했습니다. 이번 포스트에서는 GCP의 DataFlow를 사용해 GCS에 있는 CSV 파일을 간단한 Parsing 작업을 한 뒤 BigQuery Table에 적재하는 부분을 다뤘습니다. 물론 파이썬을 첨가해서   ✔ DataFlow에 대해서.. DataFlow는 GCP에서 DataPipeline(ETL, MR 등)을 Apache Beam 기반으로 동작하도록 만든 Runtime Service 입니다. 음 간단하게 말하면 Spark Streming이나 Batch 처리를 Cloud를 사용해 Paa…","fields":{"slug":"/data-gcpdataflow/"},"frontmatter":{"categories":"DATA CLOUD","title":"[DATA] - GCP DataFlow, csv from GCS to BigQuery With Python","date":"September 02, 2021"}},"next":{"fields":{"slug":"/azure-coludshellerror/"}},"previous":{"fields":{"slug":"/azure-datafactory/"}}},{"node":{"id":"44a1ef15-7454-5c7f-9869-55e001e067ce","excerpt":"머리말   이번에 새롭게 Azure PASS를 전달받아서 해당 구독으로 Cloud Shell을 사용하려고 했으나 Cloudshell error = Error creating Azure Storage Account - code : 409 error 발생으로 Storage가 생성되지 않아 관련 포스트를 작성합니다.   ✔ Error! Cloud Shell에 연결을 위한 Storage를 생성하려는데 다음과 같은 Error 발생 11111 해당 Error Code : 409가 발생전에 403 Error도 발생했으나 해결했습니다.   403 ERROR 해결 : StackOverFlow에서 구독의 Resource provider…","fields":{"slug":"/azure-coludshellerror/"},"frontmatter":{"categories":"CLOUD Error-Report","title":"[AZURE] Cloudshell error = Error creating Azure Storage Account - code : 409","date":"August 20, 2021"}},"next":{"fields":{"slug":"/azure-aksconnect/"}},"previous":{"fields":{"slug":"/data-gcpdataflow/"}}},{"node":{"id":"f5c486fe-8405-5843-a44d-eb7bf2fda959","excerpt":"머리말   추후에 Kafka를 k8s Cluster 환경에서 설치 및 구동을 해보려고 합니다. 그래서 일단 YAM을 더 효율적이게 생성하기 위해 VSCODE와 AKS를 연결해봅시다.   ✔ Preview : VSCODE로 k8s를 관리한다면? nasagif 위처럼 pod, service 등의 yaml 형식을 자동으로 정의해 편리하게 사용 가능   굳이 명령어를 치지 않고도 배포 및 상태 확인이 가능   yaml manifest 모아서 관리 한 뒤 helm Chart를 만들기 간편하다.   추가적으로 AKS은 대체로 Cloud Shell을 이용하는데 - Cloud Shell은 docker 명령을 지원하지 않는다.   실…","fields":{"slug":"/azure-aksconnect/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] VSCODE로 Cloud PaaS k8s (AKS) 관리하기","date":"August 19, 2021"}},"next":{"fields":{"slug":"/data-sparkonyarn/"}},"previous":{"fields":{"slug":"/azure-coludshellerror/"}}},{"node":{"id":"2113ff4f-0a02-5bae-b5c9-faf24641bc18","excerpt":"머리말   이전에 한번 Standalone Cluster로 Spark를 설치하는 방법을 알아봤습니다. 그러나 Azure와 연동하는 과정에서 여러가지 문제가 발생했고 결국 이전 포스트인 Hadoop Cluster를 구성해서 Spark를 구동시키기로 했습니다. 이번 포스트에서는 설치한 Hadoop Cluster의 yarn에 Spark를 구동시키는 과정입니다.   ✔ Spark 설치 JDK 등의 기본적인 환경설정은 이전포스트를 확인해주세요. 이번 포스트에서는 Spark의 설치보다는 yarn과의 연동부분을 중점으로 둡니다.   Python 설치 (pyspark를 위함) Spark 계정 설정 Spark 다운로드 및 설치 Spa…","fields":{"slug":"/data-sparkonyarn/"},"frontmatter":{"categories":"DATA","title":"[DATA] - Apache Spark v3.0 on yarn 설치 With Zeppelin","date":"August 16, 2021"}},"next":{"fields":{"slug":"/data-hadoopinstall/"}},"previous":{"fields":{"slug":"/azure-aksconnect/"}}},{"node":{"id":"cc3f2da4-d9dd-5454-a99e-eba728ad8ea2","excerpt":"머리말   앞이 막막합니다. 저번 포스트에서 이미 인프라 구성을 끝냈어야 했는데… 이번 포스트에서라도 마무리 지어보죠   ✔ 설치 환경 Hadoop 3.3.0 (Full-Distribute Mode) Server Master Worker1 Worker2 OS CentOS 8.2 CentOS 8.2 CentOS 8.2 Disk 30G 30G 30G MEM 14G 14G 14G CPU 4.Core 4.Core 4.Core VM (Azure) Hadoop Master IP : 10.0.0.5  Hadoop Worker1 IP : 10.0.0.6  Hadoop Worker2 IP : 10.0.0.7  ✌ Hadoop 설치 전…","fields":{"slug":"/data-hadoopinstall/"},"frontmatter":{"categories":"DATA","title":"[DATA] - Hadoop 3.3.0 Full Distribute mode infra 구축","date":"August 15, 2021"}},"next":{"fields":{"slug":"/data-sparkinstall/"}},"previous":{"fields":{"slug":"/data-sparkonyarn/"}}},{"node":{"id":"55f2967c-b271-5121-9dc5-8bebc2e1c7a9","excerpt":"머리말   저번 포스트에서 Apache Spark가 어떤 식으로 동작하는지? 어떤 함수가 있는지? 간단하게 이론적으로만 알아봤습니다. 아직 Spark에 대한 내용이 제대로 이해가 되지 않아 일단 구성부터 해보고 실습을 하면서 다시 이해를 해보겠습니다.   ✔ Azure VM에 Spark StandAlone 구성 Spark StandAlone Cluster로 구성하는 포스트입니다.  환경구성 OS : CentOS Linux release 8.2.2004 (Core)   cpu : 4 core   RAM : 14GB   JDK : 1.8.0 python : 3.8.8 Spark 3.0.2 zeppelin : 0.9.0 1…","fields":{"slug":"/data-sparkinstall/"},"frontmatter":{"categories":"DATA","title":"[DATA] - Azure VM에 Apache Spark v3.0 Standalone 설치 With Zeppelin","date":"August 14, 2021"}},"next":{"fields":{"slug":"/data-hadoopeco/"}},"previous":{"fields":{"slug":"/data-hadoopinstall/"}}},{"node":{"id":"3b573dbf-a917-56a5-9a76-6736d98f7ec3","excerpt":"머리말   이전 포스트에서 Hadoop EcoSystem 중 Core Project에 대해서 다뤘었습니다. 이번 포스트에서는 데이터를 수집하거나 DB화 하는 오픈소스들의 모음인 SUB Project들에 대해서 다룹니다. 모든 프로젝트를 다루지는 않고 앞으로 사용하게 될 것 같은 프로젝트 위주로 정리했습니다.     ✔ Hadoop EcoSystem Sub Project 123123123 이전포스트에서는 Hadoop EcoSystem의 Core Project 부분에 대해서 다뤘습니다. Core Project는 다 설명했고 이제 Hadoop Sub Project의 차례 입니다.  Hadoop Core Project : H…","fields":{"slug":"/data-hadoopeco/"},"frontmatter":{"categories":"DATA","title":"[DATA] - Hadoop EcoSystem Sub Project","date":"August 13, 2021"}},"next":{"fields":{"slug":"/data-hadoop/"}},"previous":{"fields":{"slug":"/data-sparkinstall/"}}},{"node":{"id":"e82d4a67-91b1-5218-9fc2-35c7377e5ffc","excerpt":"머리말   이번 내용은 이전에 Spark의 이론적인 설명을 이어서 더 대표적인 Hadoop에 대해서 이론적인 내용들을 정리해보는 포스트입니다. 저는 여러 포스트로 실제 Cluster를 구축하긴 했지만 HDFS가 데이터를 어떻게 저장하는지, ecosystem이 뭐지? 라는 의문이 많이 남았기에 궁금한 내용들을 정리할 필요를 느꼈습니다.   ✔ Apache Hadoop? 1111123123 Hadoop : 하둡 소프트웨어 라이브러리는 간단한 프로그래밍 모델을 사용하여 여러대의 컴퓨터 클러스터에서 대규모 데이터 세트를 분산 처리 할 수있게 해주는 프레임워크 이다. 라고 모든 글에서 설명을 하는데 나는 그냥 데이터를 분산 저…","fields":{"slug":"/data-hadoop/"},"frontmatter":{"categories":"DATA","title":"[DATA] - Apache Hadoop, HDFS, MapReduce","date":"August 13, 2021"}},"next":{"fields":{"slug":"/date-spark/"}},"previous":{"fields":{"slug":"/data-hadoopeco/"}}},{"node":{"id":"2a5bcac3-907a-58f0-81da-8f92654bc3e6","excerpt":"머리말   이번에는 데이터의 가장 기초적인 오픈소스인 Apache Spark에 대한 내용 정리입니다. 아무것도 모르는 생짜 초보이기 때문에 틀린 부분이 많을 수 있습니다.   ✔ Apache Spark? Hadoop? 캡처1 주워들은 말로는 데이터 시장은 오픈소스인 Hadoop과 Apache가 경쟁하며 성장하고 있다고 알고 있다 그런데 또 다른 글들을 보니 이미 업계에서는 두 오픈소스를 동시에 사용한다고도 한다. 경쟁하는 관계인데 또 상생을 하고 있다는게 무슨소리지? 다시 한번 찾아보니 각각의 툴의 용도에 대해서 알지 못했던 나의 오착이었다.   내가 이해한 두 앱의 용도를 간단하게 설명해보면 우선 두 툴은 빅데이터 …","fields":{"slug":"/date-spark/"},"frontmatter":{"categories":"DATA","title":"[DATA] - Apache Spark란??","date":"August 13, 2021"}},"next":{"fields":{"slug":"/devops-sonarqube/"}},"previous":{"fields":{"slug":"/data-hadoop/"}}},{"node":{"id":"0c0f7578-bb81-557a-8d80-32a4858eeb47","excerpt":"머리말   이번 포스트로 이제 파이프라인에서 동작하는 전체적인 보안툴에 대한 포스트는 끝났습니다. 최종적으로는    SonarQube로 Build 될 이미지의 소스코드에 대한 전략적 정적분석을    Anchore로 빌드된 이미지에 대한 분석을   OWASP ZAP으로 배포 된 서비스에 대한 동적분석   위 세가지 보안 항복을 Jenkins를 이용해 자동화 하였습니다. 사용 할 툴을 다음과 같습니다.   Jenkins Sonarqube ✔ SonarQube ?? 위키백과 왈 소나큐브(SonarQube, 이전 이름: 소나/Sonar)는 20개 이상의 프로그래밍 언어에서 버그, 코드 스멜, 보안 취약점을 발견할 목적으로 정…","fields":{"slug":"/devops-sonarqube/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - SonarQube With Jenkins","date":"August 12, 2021"}},"next":{"fields":{"slug":"/devops-anchor/"}},"previous":{"fields":{"slug":"/date-spark/"}}},{"node":{"id":"db35f671-1882-5449-b83f-40eecad72930","excerpt":"머리말   지난 포스트에서 간단하게 전체적인 파이프라인에 대해서 포스트를 했습니다. 이번 포스트는 Harbor에 배포 될 Container Image 분석 오픈소스 Anchore를 도입했던 포스트를 작성했습니다. 사용 할 툴을 다음과 같습니다.   Jenkins Anchore ✔ Anchore ?? 정말 간단히 설명해서 Docker Image의 취약점을 스캔하는 스캐너라고 생각하면 됩니다. Anchore 오픈 소스 버전은 다음에서 참고할 수 있습니다. https://anchore.com/opensource/ 이미지 분석 컨테이너 이미지의 심층 검사를 수행하여 모든 OS의 패키지, 파일 및 소프트웨어 아티팩트 (Ruby…","fields":{"slug":"/devops-anchor/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - 이미지 분석 툴 Anchore With Jenkins","date":"August 11, 2021"}},"next":{"fields":{"slug":"/devops-harbor/"}},"previous":{"fields":{"slug":"/devops-sonarqube/"}}},{"node":{"id":"f1f3cd19-e979-5f14-987a-47d3f564c240","excerpt":"머리말   그동안 빌드된 이미지를 관리하거나 정적분석 할 때 Docker hub를 기반으로 구성했으나 이번 프로젝트에서는 어떻게 하면 보안에 조금 더 중점을 둘 수 있을까를 생각하다 Harbor를 사용하여 독립적인 저장소로 이미지를 관리하기로 결정하였습니다. 사용 할 툴을 다음과 같습니다.   Jenkins OWASP ZAP ✔ Harbor 설치 (Docker) Harbor 설치의 경우 이미 많은 분들이 더 쉽게 설명해놓으셔서 간단히 넘어가겠습니다.   img 우선 Harbor는 특정 OS에 맞는 docker, docker-compose가 요구됩니다 Centos 7을 기반으로 진행하였습니다. docker-compose…","fields":{"slug":"/devops-harbor/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - Private 이미지 저장소 Harbor 도입","date":"August 10, 2021"}},"next":{"fields":{"slug":"/devops-owaspzap/"}},"previous":{"fields":{"slug":"/devops-anchor/"}}},{"node":{"id":"08b7b481-d22d-5769-b198-a051e19e0c19","excerpt":"머리말   이번 포스트에서는 구축된 DevSecOps 파이프라인에서 보안쪽을 강화하기 위해서 OWASP ZAP을 도입한 도입기 포스트입니다. 보통 외부 서버로 두고 서비스의 Port나 IP등을 스캔하지만 저희는 k8s 클러스터에 직접 올려 pod들을 스캐닝 하려고 했습니다. 사용 할 툴을 다음과 같습니다.   Jenkins OWASP ZAP ✔ GCP의 LB IP를 고정 저는 gcloud-sdk를 이용하여 Cloud Shell에서 작업을 진행했습니다 아래와 같이 CLoud Shell에 원격 접속 후 GKE 클러스터에 대한 권한을 받아옵니다 그 후 아래 명령어로 외부 고정 IP를 생성해줍니다 이후에 배포 할 서비스의 메…","fields":{"slug":"/devops-owaspzap/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - Jenkins Pipeline에 OWASP ZAP 도입기","date":"August 09, 2021"}},"next":{"fields":{"slug":"/devops-jenkinspush/"}},"previous":{"fields":{"slug":"/devops-harbor/"}}},{"node":{"id":"b022c64e-b03d-5890-807a-f79d479433c2","excerpt":"머리말   이전 포스트에서 간단하게 이미지를 빌드한 뒤 ArgoCD와 SYNC를 맞춰 배포를 자동화한 파이프 라인을 완성했습니다. 이번 포스트에서는 Jenkins에서 해당 이미지를 빌드하는 부분에 대해서 포스트 했습니다. 사용 할 툴을 다음과 같습니다.   Jenkins maven github ArgoCD ✔ 전체 Jenkins 파이프라인 파이프라인 스크립트 파이프라인의 프로세스 소스코드를 Clone 해온 뒤 Build 테스트   Dependency-Check Analysis 로 코드 정적분석   Sonarqube and Quality gate 정적분석   위의 검사에서 에러가 없으면 Docker image build…","fields":{"slug":"/devops-jenkinspush/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - Jenkins로 Dvmn 앱 이미지 자동 빌드 및 푸시하기","date":"August 08, 2021"}},"next":{"fields":{"slug":"/devops-gcpfilestore/"}},"previous":{"fields":{"slug":"/devops-owaspzap/"}}},{"node":{"id":"801845e2-ac0a-5de8-bf0a-12fd8d8036e2","excerpt":"머리말   이번 포스트에서는 앱 구동을 위한 MYSQL 이중화입니다 이전 포스트에서 앱 배포를 완료했지만 MYSQL pod의 경우 볼륨의 문제로 하나밖에 뜨지 않아 DB 데이터를 어떻게 저장할지에 대한 고민이 있었습니다. 고민해본 결과 NFS를 만들어서 그쪽에 데이터를 저장해놓고 POD가 실행될때마다 NFS를 읽어오자! 라는 결론이 나왔습니다 그래서 NFS 서버를 구축하려고 하려는 찰나 GCP에서 API 서비스로 제공한다는 소식을 듣고 바로 사용해 보았습니다 사용 할 툴을 다음과 같습니다.   GCP FileStore k8s PV,PVC ArgoCD ✔ 발생 이슈 MYSQL Pod를 두개 이상 띄우려고 할때 아래와 같…","fields":{"slug":"/devops-gcpfilestore/"},"frontmatter":{"categories":"DevOps CLOUD","title":"[DEVOPS] - GCP의 FileStore (NFS) 를 PV로 사용해보자","date":"August 07, 2021"}},"next":{"fields":{"slug":"/devops-cicd2/"}},"previous":{"fields":{"slug":"/devops-jenkinspush/"}}},{"node":{"id":"bdbab45f-6ba1-56d5-9b14-88db8da9d77d","excerpt":"머리말   이전에 구성한 파이프라인의 전체적인 자동화는 아직 구성이 안됐지만 CI, CD 각각의 자동화는 마쳤습니다. 그렇기에 이번에는 실제 보안 취약점 검사를 위한 오픈소스 툴을 Rancher 클러스터 환경에 배포해봤습니다.!! 사용할 툴은 DVMN인데 기본적으로 PHP 배포판이 대부분이지만 저는 Jenkins에서 Junit등의 취약점 분석을 조금 더 쉽게 하기 위해서 JAVA 기반의 배포판으로 MSA를 만들어 배포했습니다. 사용 할 툴을 다음과 같습니다.   GITHUB ArgoCD Helm kompose ✔ DVWA MSA 생성 DVMN JAVA 링크 해당 주소에서 JAVA기반의 DVWA앱을 확인했습니다!! 그러…","fields":{"slug":"/devops-cicd2/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - 보안 취약점 검사를 위한 Dvmn 앱 자동 배포하기","date":"August 07, 2021"}},"next":{"fields":{"slug":"/gcp-cloudshell/"}},"previous":{"fields":{"slug":"/devops-gcpfilestore/"}}},{"node":{"id":"4c31f4f6-beeb-5136-85e5-ea2c0b6b62e5","excerpt":"머리말   가급적이면 모든 업무를 코드화 하고 싶었습니다. 그러기위해서 가장 기초가 되어야 하는 부분은 원격접속이라고 생각해서 포스팅합니다. ✔ Google Cloud SDK를 설치 공식 DOC Google Cloud SDK 설치 : 이 포스트는  환경에서 진행하였습니다 패키지 소스로 Cloud SDK 배포 URI를 추가합니다. 설치 전 apt-transport-https 의 설치 유무를 확인합니다. Google Cloud 공개 키를 가져옵니다. Cloud SDK를 업데이트하고 설치합니다.   gcloud init 명령을 통해 사용합니다! 그럼 특정 계정 접속을 선택할 수 있는데 알맞게 선택합니다   계정 선택!   …","fields":{"slug":"/gcp-cloudshell/"},"frontmatter":{"categories":"CLOUD","title":"[GCP] - GCP Cloud shell 원격 접속 하기","date":"August 07, 2021"}},"next":{"fields":{"slug":"/devops-argocd/"}},"previous":{"fields":{"slug":"/devops-cicd2/"}}},{"node":{"id":"85410047-efe9-5c0d-aa1f-e10ed1571e2d","excerpt":"머리말   안녕하세요 NASA입니다!!. 이번 포스트에서는 Open Source인 Gitops기반의 Argo-CD 를 이용한 배포에 대해서 포스트했습니다 앞서 다룬 포스트에서 기본적인 환경구성은 모두 완료되었고 이제부터 진정한 파이프라인 구성입니다!! 사용 할 툴을 다음과 같습니다.   Rancher (GKE) Argo-cd ✔ 환경구성 환경구성의 경우 이전 포스트에서 모두 완료했습니다!! 다만 클러스터 내부에 직접 들어가 Argo-CD를 설치하는게 아닌 Rancher의 카탈로그를 사용해서 자동 Helm 배포를 진행합니다 ✔ Rancher Argo-CD Plugin을 설치 구축중인 파이프라인의 전제적인 Service …","fields":{"slug":"/devops-argocd/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - Argo-CD를 이용한 배포 자동화","date":"August 07, 2021"}},"next":{"fields":{"slug":"/devops-rancher-gke/"}},"previous":{"fields":{"slug":"/gcp-cloudshell/"}}},{"node":{"id":"3530a618-aa45-5512-8771-62a86a0ea7dc","excerpt":"머리말   안녕하세요 NASA입니다!!. 이번 포스트에서는 Open Source인 Rancher를 이용한 k8s 클러스터 구축에 대한 포스트입니다 이전 포스트와 다른점은 이전에는 이미 구성되어있는 클러스터를 사용했다면 이번 포스트에서는 GKE를 사용했다는 점입니다!! 사용 할 툴을 다음과 같습니다.   docker, Rancher (GKE) k8s ✔ 환경구성 환경구성은 다음과 같습니다. 스크린샷, 2020-10-13 17-18-15 Rancher : Rancher master가 띄워져있는 Cluster 관리 서버 Jenkins : 이전 포스트에서 설정한 CI 작동 서버 gke : GKE 클러스터 노드 GKE SERV…","fields":{"slug":"/devops-rancher-gke/"},"frontmatter":{"categories":"DevOps CLOUD","title":"[DEVOPS] - GKE Cluster를 Rancher에 연동하기","date":"August 06, 2021"}},"next":{"fields":{"slug":"/devops-rancher/"}},"previous":{"fields":{"slug":"/devops-argocd/"}}},{"node":{"id":"369278cb-c762-599f-ba00-0a2a53a49b54","excerpt":"머리말   안녕하세요 NASA입니다!!. 이번 포스트에서는 Open Source인 Rancher를 이용한 k8s 클러스터 구축에 대한 포스트입니다   사용 할 툴을 다음과 같습니다.   Rancher (GCP INSTANCE) k8s (GKE), ON-PRE로 구성된 클러스터 ARgoCD ✔ RANCHE 환경으로 서비스 구축을 해봅시다. Rancher는 Rancher Labs에서 개발한 오픈 소스컨테이너 오케스트레이션 플랫폼 Rancher 2.0(현재 버전)은 Kubernetes 기반으로 개발되었으며 기존 온프레미스 환경을 비롯한 멀티 클라우드 환경을 통합 관제할 수 있도록 지원합니다.  스크린샷, 2020-10-22…","fields":{"slug":"/devops-rancher/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - Rancher를 사용한 Kubernetes Cluster 구축","date":"August 05, 2021"}},"next":{"fields":{"slug":"/devops-cicd1/"}},"previous":{"fields":{"slug":"/devops-rancher-gke/"}}},{"node":{"id":"057af5e7-bd29-5bbc-86f2-61487fe7337f","excerpt":"머리말   안녕하세요 NASA입니다!!. 이번 포스트에서는 Open Source를 이용한 DevSecOps CI/CD PIPELINE 구축에 대한 포스트입니다. 다만 포스트의 양이 매우 많아 질 것 같아. CI, CD 별 그리고 툴 별로 포스트를 나눌 예정입니다. 이번 포스트에서는 Jenkins를 이용한 CI 구성 부분을 포스트 했습니다!.. 사용 할 툴을 다음과 같습니다.   gitlab Jenkins Docker, dockerhub ✔ 환경구성 우선 환경 구성은 아래와 같습니다\n캡처 jenkins : 젠킨스 서버의 역할을 하는 서버 (Docker in Docker) Rancher-master : Rancher 기반…","fields":{"slug":"/devops-cicd1/"},"frontmatter":{"categories":"DevOps","title":"[DEVOPS] - Jenkins를 이용한 CI 자동화 구축","date":"August 04, 2021"}},"next":{"fields":{"slug":"/azure-synapse/"}},"previous":{"fields":{"slug":"/devops-rancher/"}}},{"node":{"id":"887be352-bf3c-5019-b2eb-f2dcb2cfba4d","excerpt":"머리말   블로그에도 매번 인프라나 Devops 관련 글들만 올라와서 최근에 공부하고 있는 Data쪽도 포스트를 늘리려고 합니다. 아직 초급자 수준이라서 틀린 내용이 많을 것 같지만, 복습하는 느낌으로… 본 포스트에서 내용들은 모드 MS Doc를 기준으로 정리해 작성했습니다. ✔ Azure Synapse Analytics Synapse Analytics는 엔터프라이즈 데이터 웨어하우징과 빅 데이터 분석을 결합한 SaaS 입니다. Synapse의 용어 중의 SQL Pool (SQL DW)이란?? Synapse Analytics에서 사용할 수 있는 을 나타냅니다.  Enter Prise Data WareHousing 엔터…","fields":{"slug":"/azure-synapse/"},"frontmatter":{"categories":"CLOUD DATA","title":"[AZURE] [DATA] Azure Synapse Analytics","date":"August 02, 2021"}},"next":{"fields":{"slug":"/azure-web/"}},"previous":{"fields":{"slug":"/devops-cicd1/"}}},{"node":{"id":"0bf6fb78-69ee-5e69-9e9f-a47b40709147","excerpt":"머리말   이전에 GCP에서 진행한 것 처럼, 간단하게 AZURE VM을 사용해 LAMP (Linux, Apache, Mariadb, PHP)를 구성해봤습니다. 이번 포스트에서는 방법에 대해 자세히 설명하지 않고 구성중에 일어난 이슈(Error)를 주로 다뤘습니다.   ✔ Azure LAPM Architecture 저는 LAPM의 구성에 목적을 두고 있기에 따로 WEB/WAS를 분리해서 구성하지 않았습니다. 구성끼리 성능차이는 별로 없겠지만, 고가용성을 높이기 위해서는 WEB/WAS를 분리하는 것이 맞습니다. Architecture 123123 L4 LoadBalancer (Basic) 1대 WEB/WAS VM : 2…","fields":{"slug":"/azure-web/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] LAPM 서비스 구축하기","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-vscodeerror/"}},"previous":{"fields":{"slug":"/azure-synapse/"}}},{"node":{"id":"39c9c344-904a-5250-9709-466120805c8f","excerpt":"머리말   이전 포스트인 Azure Cloud Shell from VSCODE 포스트에서 디렉토리를 연동하는 과정에서 발생했던 에러의 리뷰입니다.   ✔ AZURE Cloud Shell “Select Directory…” Error From VSCODE vscode에서 Sing-in을 마치고 Cloud Shell에 연결하려고 할때 다음과 같은 Error가 발생합니다. 캡처 해당 Error가 발생하는 이유는 크게 두가지입니다. 특정 Tanant에 사용자가 많거나, 여러가지 Tanant가 존재 할 경우 Azure Account extension의 버전이 너무 높거나 몇가지 테스트를 실행해봐서 해결방법을 발견해 포스트합니다…","fields":{"slug":"/azure-vscodeerror/"},"frontmatter":{"categories":"CLOUD Error-Report","title":"[AZURE] AZURE Cloud Shell 'Select Directory...' Error From VSCODE","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-vscode/"}},"previous":{"fields":{"slug":"/azure-web/"}}},{"node":{"id":"e909cd79-b60a-5a67-bb66-7ec30ec07158","excerpt":"머리말   지금까지는 Azure Portal에서만 PowerShell을 이용 했었습니다. 그러나 일일히 VM에 들어가고 인증하고 하는 과정들이 너무 불필요하게 느껴졌고 앞으로 IAC등을 사용할 예정이기에 VSCODE의 연동이 필요하다고 느꼈습니다. 그래서 이번 포스트는 VSCODE의 연동입니다.   본 포스트는  기반에서 시행되었습니다. ✔ 1. Visual Studio(VS) Code 설치 VSCODE 페이지로 이동하여 VS 코드를 설치합니다. 캡처33 👍 2. Node.js 설치 Nodejs 페이지로 이동하여 Node.js를 설치합니다. 캡처 ✌ 3. VSCODE Azure Account extension 설치 V…","fields":{"slug":"/azure-vscode/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Azure Cloud Shell From vscode","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-vpn/"}},"previous":{"fields":{"slug":"/azure-vscodeerror/"}}},{"node":{"id":"8423ce2e-c37b-515c-b8d2-8edf65d06e70","excerpt":"머리말   앞서서 Azure의 많은 기능들을 설명했지만 주관적으로 인프라 엔지니어에게 제일 중요한 부분은 이번 포스트에서 진행할 Gateway 부분인 것 같습니다.!   ✔ Virtual Network Gateway - VPN Azure에서 VPN(Virtual Private Network)를 사용하는 경우는 다음과 같습니다. S2S (Site-to-Site) : 가상네트워크와 On-Premise 네트워크를 연결하는 VPN, VPNgw와 LocalGW가 필요   P2S (Point-to-Site) : 가상네트워크와 개별 디바이스를 연결하는 VPN, VPNgw와 ClientVpn 필요. Vnet-Vnet : 서로 다른 …","fields":{"slug":"/azure-vpn/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Virtual Network Gateway - VPN","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-vmss/"}},"previous":{"fields":{"slug":"/azure-vscode/"}}},{"node":{"id":"8b1ce3f4-20d2-5327-bc8f-2521eb281304","excerpt":"머리말   VMSS는 제가 기존에 하던 IDC 업무를 그만두고 Cloud를 하게 만든 기술입니다. VMSS는 앞 포스트에서 진행했던 scale-Up & Down 처럼 미리 프로비전할 필요없이 자동적으로 프로비전되어 고가용성을 제공합니다.   ✔ 가상 머신 확장 집합 (VMSS) VMSS를 사용하는 이유? 예를 들어 같은 역할을 하는 VM이 적게는 수십에서 많게는 수백대가 필요한 상황이 있을 수 있습니다. 규모가 큰 인프라를 운영하거나, 평소에는 적은 수의 VM 이었다, 갑자기 많은 수의 VM으로 확장해 사용해야 하는 애플리케이션도 있구요. (명절의 KTX, 블랙 프라이데이의 Amazon 등등) 이렇게 VM 갯수가 많아…","fields":{"slug":"/azure-vmss/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] 가상 머신 확장 집합 (VMSS)","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-scale/"}},"previous":{"fields":{"slug":"/azure-vpn/"}}},{"node":{"id":"1e4b185e-3a61-592b-a0a9-bffd601deb83","excerpt":"머리말   지금까지 단일로 만든 VM은 장애가 일어나면 워크로드 대응이 쉽지 않습니다. 이번 포스트에서는 Azure에서 생성한 VM에 대한 크기 조정과 가용성 구현에 대해서 알아보겠습니다. 가용성을 구현하는 방법은 여러가지가 있는데 이번 포스트는 Scail-up,down과 가용성에 대해 다룹니다. 이미 이전 Region & availability zones 포스트에서 가용성에 대한 설명은 했었지만 부족한 부분이 많아서 다시 설명합니다.   ✔ VM Scail-Up & Scail-Down Scail-Up & Down 은 이미 배포된 VM의 CPU,MEM,DISK 등을 높거나, 낮게 변경하는 작업입니다. 가장 간단한 방법…","fields":{"slug":"/azure-scale/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Availability (가용성) VMSS, SCALE","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-lb/"}},"previous":{"fields":{"slug":"/azure-vmss/"}}},{"node":{"id":"89037838-0ae9-5f0b-980b-071e6772142f","excerpt":"머리말   아마 클라우드나 IDC나 어떠한 서비스를 운영하는데 가장 중요한건 부하분산이라고 생각합니다. 어떤 서비스든 전체적인 서비스에 대한 안정성이 가져야 하는 가장 중요한 것이기 때문이죠 그래서 이번 포스트에서는 AZURE에서 제공하는 L7 LB Application GateWay에 대해서 포스트 했습니다.   ✔ Application GateWay Application GateWay는 웹 트래픽 부하 분산 장치, 즉 L7 LB 입니다. 요청 URL이나 호스트 헤더등의 HTTP 특성을 기반으로 트래픽을 웹 서버 풀로 보내 부하 분산합니다.   구성요소 APPlication GateWay의 구성요소는 다음과 같습니다…","fields":{"slug":"/azure-lb/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Application GateWay, LoadBalancer","date":"August 01, 2021"}},"next":{"fields":{"slug":"/azure-blob/"}},"previous":{"fields":{"slug":"/azure-scale/"}}},{"node":{"id":"8a05a396-fc68-5762-a348-1f0fb07f765d","excerpt":"머리말   스토리지에 대한 내용은 앞에서 간단하게 다뤘지만\n세부적인 내용들이 많이 부족합니다, 더 구체화 한 포스트를 이번에 작성했습니다.  ✔ 스토리지(STORAGE) 모든 데이터는 비정형데이터, 반정형데이터, 정형 데이터라는 3가지 유형으로 나눌 수 있습니다. 데이터 유형 유형 설명 예 비정형 데이터 데이터가 개체로 존재, 구조화 되지 않아 연산이 불가능 문서, 동영상, 이미지 등 이진 파일 반정형 데이터 스키마에 해당하는 메타데이터가 데이터 내부에 있으며 연산 불가능 HTML, XML, JSON, YAML 형식 데이터 정형 데이터 고정된 칼럼에 저장되거나 행과 열에 의해 데이터 속성이 구분 되는 데이터, 연산가능…","fields":{"slug":"/azure-blob/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Storage Account, Azure BLOG!","date":"July 30, 2021"}},"next":{"fields":{"slug":"/azure-resource2/"}},"previous":{"fields":{"slug":"/azure-lb/"}}},{"node":{"id":"fce848a7-253c-55d6-b796-830043777662","excerpt":"머리말   사실 이론적인 내용을 모두 다루고 난 다음에 실습으로 넘어가려고 했지만 빠른 이해를 위해서는 실습과 이론이 병행되어야 할 것 같아서 Azure Potal 실습과 병행하여 포스트 하겠습니다. 이번 포스트는 리소스 태그, 리소스 이동하기 등 리소스에 관련된 실습 내용입니다.   ✔ Azure Resoureces Group 생성 Azure의 모든 리소스를 생성한거나 사용하기 위해서는 리소스를 관리하는 RG가 먼저 필요합니다. 이론적인 내용은 Azure 시리즈의 Resource, Resource Manager 포스트를 확인해주세요   Azure Portal에서 아래 보이는 Resources Group 메뉴로 접속합…","fields":{"slug":"/azure-resource2/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] RG 생성, Resource 생성, TAGING, Resoureces 이동하기","date":"July 30, 2021"}},"next":{"fields":{"slug":"/azure-storage/"}},"previous":{"fields":{"slug":"/azure-blob/"}}},{"node":{"id":"90b7fcb8-0979-5415-a040-a4b8a5bcdc6e","excerpt":"머리말   이번 포스트에서는 Azure 스토리지 서비스에 대한 내용을 다뤘습니다. GCP를 사용했었던 경험으론 스토리지를 가장 많이 썼던 것 같은데 AZURE도 그럴지 봐야할 것 같습니다. ✔ Azure Storage ON-PREMISE에 있는 모든 파일을 클라우드로 마이그레이션 하는 경우에 가장 많이 사용하는 서비스가 아닐까 싶습니다. Azure Storage는 IaaS 가상 머신 및 Paas 클라우드에도 사용됩니다.   Azure Storage에서 사용 가능 한 Storage의 종류는 아래와 같습니다. Azure Blob Storage Azure Disk Storage Azure Files Storage Azure…","fields":{"slug":"/azure-storage/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] STORAGE","date":"July 30, 2021"}},"next":{"fields":{"slug":"/azure-region/"}},"previous":{"fields":{"slug":"/azure-resource2/"}}},{"node":{"id":"900c1da1-4baf-564c-b5e6-5a06d7a0858b","excerpt":"머리말   이전 포스트에서 AZURE의 기초 이론 내용들을 설명했습니다. 퍼블릭 클라우드를 한번이라도 경험해본 분이라면 region, availability의 개념은 어느정도 알고 있겠죠?… ✔ Azure Region Azure만이 아니라 모든 Public Cloud는 데이터 센터를 포함하는 전 세계 여러 위치인 Region에 리소스가 생성됩니다.   간단하게 요약해 서비스를 사용 할 때 전세계 중 특정한 나라의 물리적 장비를 사용한다는 말입니다. 즉 Region이란 리소스를 생성 할 수 있는 지리적 영역을 의미합니다. 2020년 6월 기준 AZURE의 Region 배포 상황\nregions-small Special A…","fields":{"slug":"/azure-region/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Region, availability zone","date":"July 30, 2021"}},"next":{"fields":{"slug":"/azure-subscriptions/"}},"previous":{"fields":{"slug":"/azure-storage/"}}},{"node":{"id":"32299667-18a3-5daf-9ea5-ce8b27263add","excerpt":"머리말   AZURE를 차근차근 알아가고 있습니다. 아직 AZURE의 기초단계라 그런지 가장 생소한 것은 구독(Subscriptions)입니다. AWS,GCP의 경우 크레딧이라고하는 것들의 리소스단위가 AZURE에서는 구독(Subscriptions)으로 표현된다고 합니다. ✔ AZURE의 리소스 관리 구독이라는 개념을 완벽히 이해해야 앞으로의 지식을 받아 드리기 편할 것 같습니다. Overview : Subscriptions, Management group, resources, region image   hierarchy 각 기능들은 위 그림과 같이 하향식 계층 구조를 띄고 있습니다. 관리 그룹, 구독, 리소스 그룹,…","fields":{"slug":"/azure-subscriptions/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] Subscriptions, management Group, Resoucre Group","date":"July 29, 2021"}},"next":{"fields":{"slug":"/azure-400/"}},"previous":{"fields":{"slug":"/azure-region/"}}},{"node":{"id":"b14c365a-752f-5f30-8912-eb263635e8f2","excerpt":"머리말   첫 AZURE 자격증인 AZ-104를 이어 AZ-400 자격증을 취득하여 AZURE DevOps Engineer Expert certified를 가지게 되었습니다. 이번 포스트에서는 AZ-400 시험의 후기를 작성했습니다. 자격증 자격증 기본적으로 AZURE 자격증의 Certi 획득 방식은 참 마음에 들지 않습니다. 이번에 취득한 Certi가 그 중 하나인데요 GCP 나 AWS의 경우 associate, Pro 등으로 나눠져 있는 반면 AZURE는 아래 이미지와 같이 자격증 하나 하나가 세분화하게 나눠져 있습니다.   자격증 음 간단하게 설명하자면 DevOps Engineer certi를 얻기 위해서는 10…","fields":{"slug":"/azure-400/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] AZ-400 [DevOps Engineer Expert] 자격증 합격 후기","date":"July 28, 2021"}},"next":{"fields":{"slug":"/azure-service/"}},"previous":{"fields":{"slug":"/azure-subscriptions/"}}},{"node":{"id":"bebe6258-49ea-5e52-bd2c-140c3091ca2f","excerpt":"머리말   이번 포스트부터 본격적인 이론 내용에 대해서 알아보겠습니다. 개인적으로 AZURE 사용하면서 많이 사용하게 될 서비스들에 대해서 정리해보았습니다. ✔ Azure Service 인스턴스, 네트워크 등 3사 퍼블릭 클라우드가 제공하는 기능은 거의 동일 합니다.   AZURE 전체 서비스 azure-services 가장 일반적으로 사용량이 많은 것들만 정리 해봤습니다. 컴퓨팅 네트워킹 스토리지 데이터베이스 웹 DevOps ✌ 컴퓨팅(Computing) 컴퓨팅 서비스는 회사가 Azure 플랫폼으로 이전하는 주된 이유 중 하나입니다. Azure에서는 애플리케이션 및 서비스를 호스팅하는 다양한 옵션을 제공합니다. 다음…","fields":{"slug":"/azure-service/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] SERVICE, COMPUTING, NETWORK","date":"July 27, 2021"}},"next":{"fields":{"slug":"/lpic-success/"}},"previous":{"fields":{"slug":"/azure-400/"}}},{"node":{"id":"62babada-c355-5a7f-8379-5b41e98f7dec","excerpt":"머리말   개인적으로 IT 업계의 엔지니어는 자격증으로 실력을 판가름 할 수 없다고 생각합니다. 그럼에도 이직이나 기본 스택을 표현하기에 가장 좋은 것은 자격증이라고 생각하기 때문에 저는 이번년도 목표를 파이썬 공부와 자격증 7개로 잡았습니다   AZ-104 (완료) AZ-400 (완료) AZ-303 (완료) AZ-304 (완료) AZ-200  LPIC-1 (완료) CKA 오늘은 리눅스 LPIC-1 자격증을 취득해서 후기를 작성해봅니다.   LPIC-101 합격증 lpic1 LPIC-102 합격증 lpic2 공부방법 사실 LPIC-1 (101,102)의 경우 리눅스를 실무에서 다뤄본 사람이라면 아주 쉬운 자격증입니다.…","fields":{"slug":"/lpic-success/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - LPIC-1 (101,102) 합격 후기","date":"July 27, 2021"}},"next":{"fields":{"slug":"/azure-104/"}},"previous":{"fields":{"slug":"/azure-service/"}}},{"node":{"id":"051d0e6a-30d8-5788-b7f5-73e9cb7bc4e1","excerpt":"2021년을 맞이하는 주말이 끝나고 지난 월요일에 마이크로소프트의 Azure 자격증을   취득했습니다. 이전에 GCP, AWS로 개인, 팀 프로젝트를 진행했던 경험 덕분에 Cloud 개념들에 대해서 조금 더 쉽게 이해 할 수 있었던 것 같습니다. 그러나 AWS, GCP와는 구독(Subcription) 이라는 개념은 약간 생소했습니다. 공부방법 Microsoft Learn 사실 마이크로소프트 자체에서 만든 공식자료가 완벽합니다. AWS와는 다르게 객관적으로 이해하지 쉽게 적혀있고 그림으로 설명도 첨부하여서 대부분을 공식 doc, learn으로 공부했던 것 같습니다. 그리고 case study도 읽으시는걸 추천합니다. 이…","fields":{"slug":"/azure-104/"},"frontmatter":{"categories":"CLOUD","title":"[AZURE] AZ-104 [Microsoft Azure Administrator] 자격증 합격 후기","date":"July 26, 2021"}},"next":{"fields":{"slug":"/kubernetes-error01/"}},"previous":{"fields":{"slug":"/lpic-success/"}}},{"node":{"id":"fd1c3f20-62ff-5ee2-a922-ceae1bfe395d","excerpt":"이번 포스트는 이전 K8S 설치 및 구성 포스트에서 정상적으로 설치 뒤에 발견된 이슈에 대한 리포트 입니다. github, 영문 리포트 사이트에서 여러가지 글이 있지만 정확한 원인과 해결방법에 대한 댓글이 없어 리포트 합니다. ✔ 해결방법  이후에서만 발생하는 이슈입니다. 버전을 낮춰 설치를 진행, 혹은 버그가 릴리즈 될 때까지 기다리는 수 밖에 없을 것 같습니다.   저는 1.16 버전으로 설치 후 정상 구동을 확인 했습니다. 추가적으로 GCP같은 퍼블릭 클라우드의 환경에서만 발생하는건지 기존의 레거시 설치 환경에서도 발생하는 건지는 테스트가 필요합니다. ✌ 이슈 내용 에서 헬스체크 이슈 \n으로 기본 설치 이후 아래…","fields":{"slug":"/kubernetes-error01/"},"frontmatter":{"categories":"DevOps Error-Report","title":"[Kubernetes] - 1.17버전 이상 헬스 체크 에러 리포트","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-volume/"}},"previous":{"fields":{"slug":"/azure-104/"}}},{"node":{"id":"624b3182-5fe2-5d6a-9dad-741527689b4e","excerpt":"머리말    이번 포스트에서는 쿠버네틱스의 볼륨에 대해서 알아보자. ✔ 쿠버네티스의 볼륨 파드의 컨테이너는 이미지로부터 파일시스템을 제공받는다. 그러나 파드가 종료되면 파드 내의 은 더 이상 사용 할 수 없게 된다.   컨트롤러에 의해 새로운 파드가 생성이 되면 이미지로 부터 새로운 파일 시스템을 제공받는다. 즉 컨테이너는 기본적으로 데이터를 유지하지 않으며, 이런 형태를  라고 한다. 파드는 새로 생성된 데이터를 보존하기 위해 을 생성하고 이런 볼륨을 컨테이너에 해서 사용한다. 볼륨은 여러 파드에서 에 접근이 가능하다. 기본적인 볼륨의 은 파드의 과 같다. 파드가 생성되고 삭제됨에 따라 볼륨도 같이 생성되고 삭제된다…","fields":{"slug":"/kubernetes-volume/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 Volume","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-service/"}},"previous":{"fields":{"slug":"/kubernetes-error01/"}}},{"node":{"id":"6c1b0b6c-a003-5855-a2b1-30c61c4e5df0","excerpt":"머리말   이번 포스트에서는 쿠버네티스의 네트워크 및 내부 서비스들에 대해서 알아보겠습니다. ✔ Service 이전 포스트들에서 쿠버네티스 클러스터안에 컨트롤러들을 이용해서 POD를 정의했습니다.      POD 특성상 생성 및 정의 될때 지정되는 IP가 랜덤하고  또한 리스타트 때마다 IP가 변동됩니다.   위 두개의 이유로 POD는 로 호출이 어렵습니다. 또한 여러 POD에 같은 애플리케이션을 운용할 경우 이 POD 간의 로드밸런싱을 지원해줘야 하는데 이러한 기능들을 수행하는게  입니다.   간략한 서비스들의 기능을 요약해보면 아래 4가지 정도입니다. 서비스를 사용하게 되면 고정된 주소를 이용해서 접근이 가능해 집…","fields":{"slug":"/kubernetes-service/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 Service","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-controller/"}},"previous":{"fields":{"slug":"/kubernetes-volume/"}}},{"node":{"id":"059e8eef-76f8-5d37-9aac-1ad3fc2d4868","excerpt":"머리말   이번 포스트에서는 자동적으로 POD 및 시스템을 관리 할 수 있는 컨트롤러에 대해서 알아보겠습니다 ✔ 라이브니스 프로브 라이브니스 프로브 개념 사용자가 모든 오브젝트를 일일이 관리할 수는 없다. 관리하고자 하더라도 사용자의 사각지대에 있는 오브젝트를 실제 프로덕션 환경에서 관리하기 위해서는 수동 작업은 권장되지 않는다. 실제 환경에서는 자동적으로 정상적이고 안정적인 상태가 유지되어야 한다. 쿠버네티스가 이러한 요구를 충족시키기 위해서 사용하는 것이 이다. 라이브니스 프로브는 파드에 의해 컨테이너를 동작시키고 동작중인 컨테이너의 상태를 주기적으로 모니터링한다. 파드에서 오류가 발생하면 해당 컨테이너를 재시작시…","fields":{"slug":"/kubernetes-controller/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 컨트롤러","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-label/"}},"previous":{"fields":{"slug":"/kubernetes-service/"}}},{"node":{"id":"3e819d0c-cf4a-5cab-84f4-1a08c1b7532d","excerpt":"머리말   이전 포스트에서는 기본적인 POD의 정의 및 생성에 대해서 알아봤다 이번 포스트에서는 POD를 더 효율적으로 관리하기 위한 레이블과 셀렉터에 대해서 알아보자 ✔ 레이블 레이블 은 파드와 같은 오브젝트에 첨부된 키와 값의 쌍이다. 레이블은 오브젝트의 특성을 식별하는 데 사용되어 사용자에게 중요하지만, 코어 시스템에 직접적인 의미는 없다. 레이블로 오브젝트의 하위 집합을 선택하고, 구성하는데 사용할 수 있다. 레이블은 오브젝트를 생성할 때에 붙이거나 생성 이후에 붙이거나 언제든지 수정이 가능하다. 오브젝트마다 키와 값으로 레이블을 정의할 수 있다. 오브젝트의 키는 고유한 값이어야 한다. 레이블은 UI와 CLI에…","fields":{"slug":"/kubernetes-label/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 레이블 및 셀렉터","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-pod/"}},"previous":{"fields":{"slug":"/kubernetes-controller/"}}},{"node":{"id":"64fbddd3-aaf7-50d0-a98f-5a7dff2bb244","excerpt":"머리말   이제 기본적인 개념과 kubectl 명령어까지 모두 알아봤다!! 이번 포스트부터는 진짜 실습을 들어가보자!! 우선 컨포넌트 포스트에서 설명했던 것들부터 시작하겠습니다!! ✔ POD?! 은 쿠버네티스 APP의 기본 실행 단위인데 쉽게 말해 쿠버네티스 워크로드에서 관리할 수 있는 가장 작은 단위가 파드입니다. 또한 배포 시 배포의 단위가 되기도 합니다. 파드는 하나 이상의 ‘동작중인’ 컨테이너를 포함하고 있는 오브젝트이고 하나의 파드에는 하나의 컨테이너를 배치하는 것이 기본입니다. 쿠버네티스 클러스터 내에서 파드는 주로 두 가지 방법으로 사용되죠. 스크린샷, 2020-09-16 15-29-48 Pod 모델 종류…","fields":{"slug":"/kubernetes-pod/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 POD?","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-command/"}},"previous":{"fields":{"slug":"/kubernetes-label/"}}},{"node":{"id":"b1a77332-6f87-5631-8103-2ad76c5e959f","excerpt":"머리말   이제 실습전 알아야 할 이론적인 부분들은 모두 포스팅 했습니다. 이번 포스트 부터 이후 포스트까지는 실습에 대한 내용들을 다룰 것입니다.     ✔ kubectl 명령어 쿠버네티스는  이라는 CLI 명령어를 통해서 쿠버네티스 및 클러스터 관리, 디버그 및 트러블 슈팅들을 할 수 있습니다. 자세한 내용을 알고 싶으면 kubectl 치트 시트를 참고하세요 는 기본적으로 아래와 같은 형태로 커맨드 라인에 입력하여 사용할 수 있습니다.  : 자원에 실행하려는 동작 create : 생성 ge` : 정보 가져오기 describe : 자세한 상태 정보 delete : 삭제    : 자원 타입 pod : Pod servi…","fields":{"slug":"/kubernetes-command/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 명령어 정리","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-architecture/"}},"previous":{"fields":{"slug":"/kubernetes-pod/"}}},{"node":{"id":"85b868eb-f8db-5212-ac16-bf9c82a6dddc","excerpt":"머리말  이전 포스트에서 쿠버네티스의 기본적인 컴포넌트 개념에 대해서 정리 해보았습니다. 이번에는 실습에 들어가기 앞서 아키텍쳐의 개념을 잡고 들어가기위해서 조대협님의 블로그 글을 참고하여 제 식대로 다시 정리 해보았습니다.   참고  :  조대협님 블로그 ✔ 아키텍쳐 개념정리 이전 포스트에서 쿠버네티스에 대한 개념 이해가 끝났으면 이제 쿠버네티스가 실제로 어떤 구조로 구현이 되어 있는지 아키텍쳐를 살펴보도록 하자. 아키텍쳐를 이용하면 동작 원리를 이해할 수 있기 때문에 쿠버네티스의 사용법을 이해하는데 도움이 된다. (kubernetes의 아키텍쳐) 스크린샷, 2020-09-16 11-45-17 ✌ 마스터와 노드 쿠버…","fields":{"slug":"/kubernetes-architecture/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 아키텍쳐","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-componant/"}},"previous":{"fields":{"slug":"/kubernetes-command/"}}},{"node":{"id":"f7b5524d-5df4-5975-baf4-be92f59dc22a","excerpt":"머리말   이전 포스트에서 드디어 GCP 인스턴스 기반의 k8s 클러스터 환경을 구축했습니다. 이번 포스트에서는 이번에 간단하게 포스트해서 정리했지만 실제 실습을 들어가기전 전체적인 개념에 대해서 다시 한번 정리하고 실습에 들어가야 할 것 같아서 조대협님의 블로그 글을 참고하여 내 식대로 다시 정리해보았다.   참고  :  조대협님 블로그 ✔ 개념정리 오브젝트 쿠버네티스를 이해하기 위해 가장 중요한 부분이 이다. 가장 가 되는  를 하고 하는 추가적인 기능을 가진  이러한 오브젝트의 이외에 추가정보인 들로 구성이 된다고 보면 된다.  오브젝트 스펙 (Object Spec) 오브젝트들은 모두 오브젝트의 특성 (설정정보)…","fields":{"slug":"/kubernetes-componant/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스의 컴포넌트","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-error1/"}},"previous":{"fields":{"slug":"/kubernetes-architecture/"}}},{"node":{"id":"b10caab8-cb55-5a70-84d6-bbb3cda063ef","excerpt":"✔ 발생 에러 상황 : kubespray로  명령어 구동 중 “assertion: groups.etcd | length is not divisibleby 2” 에러 발생” kubespray로  명령어 진행 시  에러가 발생할 수 있습니다. 스크린샷, 2020-08-21 10-10-28 캡쳐 이미지를 보면 특정노드는 성공했는데 특정노드는 실패했습니다 ✌ 원인 해당 에러는 아래 이미지와 같이  파일에 지정한 가 인 경우에 발생합니다. 스크린샷, 2020-08-21 10-12-18 kubespray/roles/kubernetes/preinstall/tasks/0020-verify-settings.yml 코드 확인 스크린샷,…","fields":{"slug":"/kubernetes-error1/"},"frontmatter":{"categories":"DevOps Error-Report","title":"[Error Report] - length is not divisibleby 2","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes-kubeadm/"}},"previous":{"fields":{"slug":"/kubernetes-componant/"}}},{"node":{"id":"02ef2350-d7b7-5949-8669-9c9f4ed8580e","excerpt":"머리말   이전 포스트에서는 kubespay 자동화 툴을 사용해서 K8S 클러스터를 구축 했었습니다. 이번 포스트에서는 kubeadm을 이용해서 K8S 클러스터를 구축하는 방법에 대해서 포스트했습니다.   ✔ 사전준비 사전 준비의 경우 kubespray와 동일하게 GCP VM Instance에서 구성했기 때문에 방법이 동일합니다. 사전 준비는 이전 포스트인 kubespray를 확인해주세요. ✌ 쿠버네티스  설치하기 kubeadm 본격적인 설치 과정입니다.\n은  과  을  때문에 직접 설치해야 합니다.   전체 Server에 아래 를 추가합니다.   CENSOS yum update 도커 설치 전 사전 세팅  도커 저장소…","fields":{"slug":"/kubernetes-kubeadm/"},"frontmatter":{"categories":"DevOps CLOUD","title":"[Kubernetes] - Kubernetes 환경구성 on GCP Using kubeadm","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubetnetes-kubespary/"}},"previous":{"fields":{"slug":"/kubernetes-error1/"}}},{"node":{"id":"22b18939-b966-58ca-8408-1ddb10464062","excerpt":"머리말   쿠버네티스 환경을 구성하는 방법은 여러가지가 존재합니다 서버를 준비하는 방법은 또한 여러 가지가 있겠지만 가장 쉽게 생각해볼 수 있는 건  와  를 이용한 로 구성하는 것 입니다. 하지만 이번 포스트에서는 GCP STUDY + Kubernetes STUDY 겸 GCP로 진행했습니다. 사실 GCP 무료 크레딧이 아까운 마음이 더 크긴 했습니다. ✔ 사전준비 쿠버네티스는 3개월 마다 새로운 버전이 릴리즈 되고 해당 버전은 9개월 동안 버그와 보안 이슈를 수정하는 패치가 이루어 집니다.   이번 포스트에 구성할 노드는 와 로 총 의 서버가 필요합니다. 노드의 최소 요구 사양은 다음과 같습니다. 항목 사양 CPU …","fields":{"slug":"/kubetnetes-kubespary/"},"frontmatter":{"categories":"DevOps CLOUD","title":"[Kubernetes] - Kubernetes 환경구성 on GCP Using KubeSpary","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes01/"}},"previous":{"fields":{"slug":"/kubernetes-kubeadm/"}}},{"node":{"id":"5355c631-7fe6-5aa1-b88f-9fb739c067bf","excerpt":"머리말    쿠버네티스… 이름만 많이 들어보고 많이 사용하는 기술이라고만 들었다.  하지만 온프레미스 경험만 가지고 있는 나는 아무것도 알지 못한다.  아마도 포스트를 작성하면서 조금씩 익숙해질 것이라고 생각한다.  마지막 포스트를 쓸 때 쯤에는 초급정도의 스킬은 가지고 있었으면 싶다.    참고 블로그 : https://subicura.com/2019/05/19/kubernetes-basic-1.html ✔ 쿠버네티스란??  쿠버네티스는 컨테이너를 쉽고 빠르게 해주는 오픈소스 플랫폼입니다.   보통 k8s 또는 큐브 (kube) 라고 줄여서 부릅니다. 현재는 단순한 컨테이너 플랫폼이 아닌 , 을 지향하고 컨테이너로 …","fields":{"slug":"/kubernetes01/"},"frontmatter":{"categories":"DevOps","title":"[Kubernetes] - 쿠버네티스란?","date":"June 29, 2021"}},"next":{"fields":{"slug":"/linux-shellscript/"}},"previous":{"fields":{"slug":"/kubetnetes-kubespary/"}}},{"node":{"id":"bb2ad5b9-0ebe-541d-90f7-19beb2914965","excerpt":"머리말   이전 포스트에서는 정규표현식에 대한 내용을 포스팅 했었습니다. 이번 포스트에서부터는 이제 실제 스크립트를 작성하는데 많은 도움이 되는 매개변수등에 대해서 설명 할 예정입니다. ✔ 특수 매개변수 특수매개변수 (Special Parameters)    매개변수를 설명하기 전 알고가야 할 사항은 인지, 인지  사실 별로 중요하지 않습니다. 그저 미리 내장된 특수한 변수들이 있고, 해당 코드들이 무슨 의미인지만 알면 됩니다. 매개변수들의 상관관계 스크린샷, 2020-08-19 15-35-50 특수 매개 변수 사용 예 간단하게 스크립트를 하나 짜봤습니다. 코드에 보이는 과 와 같이 달러 표시로 시작되는 것들이 내부적…","fields":{"slug":"/linux-shellscript/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Shell Script - 특수,위치,아규먼트 매개 변수","date":"June 28, 2021"}},"next":{"fields":{"slug":"/linux-shellscript-intervalRegula/"}},"previous":{"fields":{"slug":"/kubernetes01/"}}},{"node":{"id":"5de3edf0-d3d2-54d0-8c0a-ff6001426eaa","excerpt":"머리말   이전 포스트에서는 sed,awk등 텍스트를 편집하는 명령어들에 대해서 알아보았습니다. 이번에는 쉘스크립트를 작성할때 가장 기초가 되는 정규표현식에 대해서 포스트했습니다.   ✔ 정규표현식 정규 표현식은 , 을 도와주는 특별한 문자입니다   정규표현식(regular expression)은 줄여서  또는  라고도 합니다.   정규 표현식은 리눅스 뿐만 아니라  등 에서도 사용할 수 있습니다.   스크린샷, 2020-08-19 14-23-56 ✌ 정규표현식 표현방법 정규표현식은 표준인 과 POSIX 정규표현식에서 확장된 가 대표적입니다   이외에도 수많은 정규표현식이 존재하지만 약간의 차이점이 있을뿐 대부분 비슷…","fields":{"slug":"/linux-shellscript-intervalRegula/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Shell Script - 정규표현식","date":"June 28, 2021"}},"next":{"fields":{"slug":"/linux-awk/"}},"previous":{"fields":{"slug":"/linux-shellscript/"}}},{"node":{"id":"2672455e-760f-5f0e-9c81-1c0d256f9b99","excerpt":"머리말  이전 포스트에서는 스크립트나 리눅스를 운영하면서 자주 사용하게 되는 sed 명령어에 대해서 포스트 했습니다. 이번 포스트에서는 동일하게 자주 사용되는 awk 에 대해서 설명해보았습니다.   ✔ awk ? 란?   awk는 텍스트 파일을 처리하는 라인 지향 프로그램 입니다. 아래 이미지와 같이 필드와 레코드로 구분하여 데이터를 처리하게 되는데 구분자를 사용하여 표와 같은 모양이 됩니다.  : 엔터(개행)  : 탭, 스페이스  데이터를 조작하고 리포트를 생성하기 위해 사용하는 언어입니다. 간단한 연산자를 명령라인에서 사용할 수 있으며, 큰 프로그램을 위해 사용될 수 있습니다. 는 데이터를 조작할 수 있기 때문에 …","fields":{"slug":"/linux-awk/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Shell Script - awk","date":"June 28, 2021"}},"next":{"fields":{"slug":"/linux-sed/"}},"previous":{"fields":{"slug":"/linux-shellscript-intervalRegula/"}}},{"node":{"id":"18adfc92-7a37-5216-a788-0d0c92aaa9d9","excerpt":"머리말   이미 2년정도 실무를 경험하면서 스크립트는 지겹도록 작성해서 이미 익숙한 명령어이지만 이 명령어도 쓰는 옵션만 쓰고 쓰지 않았던 옵션에 대해서는 상세하게 알지 못했습니다. 이번 포스트를 쓰면서 머리속에 지식을 박아넣습니다.. ✔ Sed(streamlined editor) ? 는 대화형 기능이 없는 편집기입니다.   명령행에서 직접 편집 명령어와 파일을 지정하여 작업한 후 결과를 화면으로 확인합니다.   sed 편집기는 원본을 손상하지 않는다.   리다이렉션을 이용하여 편집 결과를 파일로 저장하여 확인할 수 있다.   sed 명령어는 를 의미합니다. streamlined = ‘능률적인’을 의미하듯 정말 편한 …","fields":{"slug":"/linux-sed/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Shell Script - sed","date":"June 28, 2021"}},"next":{"fields":{"slug":"/docker-file/"}},"previous":{"fields":{"slug":"/linux-awk/"}}},{"node":{"id":"91aeb602-995f-5d6f-bf10-8331113bcafe","excerpt":"머리말    이번 포스트에서는 Docker에서 조금도 간편화된 방법으로 이미지를 제작할 수 있는 Dockerfile에 대해서 포스팅합니다. ✔ DOCKERFILE 은 컨테이너를 만들고 해야하는 일련의 작업들을 미리 선언함으로써 매번 해당 작업을 하지않고도, 컨테이너 생성시 자동으로 등록된 작업이 실행된 후 컨테이너를 생성할 수 있는 파일입니다. Dockerfile은 어플리케이션 개발 외에도 도커 허브에 배포할때,이미지가 아닌, Dockerfile을 이용하여 배포할 수도 있습니다. Dockerfile은 COMMAND-VALUE 쌍으로 구성된 지시어로 이루어진 도커 이미지 설정 파일입니다. 베이스 이미지를 지정, 컨테이너…","fields":{"slug":"/docker-file/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - Dockerfile","date":"June 27, 2021"}},"next":{"fields":{"slug":"/docker-volume/"}},"previous":{"fields":{"slug":"/linux-sed/"}}},{"node":{"id":"bb26cdb7-0ad3-53cc-9c61-d071c65fbd2b","excerpt":"머리말    이전 포스트에서는 도커 컨테이너의 전반적인 운영법에 대해서 포스팅 했었습니다.  이번 포스트에서는 볼륨을 이용해서 실제 도커의 데이터 관리 방법과 그와 관련된 명령어들을 포스트 했습니다. ✔ 도커 볼륨 기본적으로 컨테이너에 생성되는 모든 파일은 컨테이너 레이어에 저장됩니다. 이 데이터들은 컨테이너와 함께 삭제되는 런타임 데이터인데  이 데이터를 영구적으로 저장하려면 반드시 을 사용해야 합니다. 도커의 볼륨-마운트 구조    도커 볼륨을 사용 방법  초기 도커부터 사용했던 방식입니다. 호스트의 특정 디렉토리와 컨테이너의 디렉토리를 연결하는 방식입니다. bind mount는 쉽게 사용할 수 있지만 도커에 의해…","fields":{"slug":"/docker-volume/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - VOLUMES","date":"June 26, 2021"}},"next":{"fields":{"slug":"/docker-net2/"}},"previous":{"fields":{"slug":"/docker-file/"}}},{"node":{"id":"19140e2a-39e6-528d-83b0-b371a0d9a02d","excerpt":"머리말    이전 포스트에서는 도커의 네트워크에 대해서 포스팅했습니다.  이번 포스트에서는 이전 포스트에서 포스팅한 네트워크의 종류가 아니라  실제 컨테이너에 사용자가 네트워크 대역대를 직접 설정할 수 있는 MACVLAN과 LINK에 대해서 포스팅합니다. ✔ MACVLAN MacVLan은 브릿지가 없습니다. 대신 서브 인터페이스라는 개념이 등장해서 사용합니다.   물리적인 NIC eth0은 존재하며 에서 여러 하위 인터페이스를 만듬으로써 여러개의 mac 주소를 가질 수 있도록 합니다. 그렇게 되면 생성된 하위 인터페이스들에 여러개의 컨테이너들이 연결되면서 VLAN을 구성할 수 있습니다.   즉 하나의 NIC를 가상화함…","fields":{"slug":"/docker-net2/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - MACVLAN, LINK","date":"June 26, 2021"}},"next":{"fields":{"slug":"/docker-network/"}},"previous":{"fields":{"slug":"/docker-volume/"}}},{"node":{"id":"a5cac2cd-ed18-5dc7-8042-ae4cd3358d7b","excerpt":"머리말    이번 포스트에서는 컨테이너들의 서비스와 중요하게 연관되어있는 도커의 네트워크에 대해서 포스트 했습니다.   ✔ DOCKER - 네트워크 유형 도커에는 다양한 네트워크가 존재해 용도에 맞게 네트워크를 선택 할 수 있습니다.    기본으로 사용하는 네트워크는 ,,이 존재하고  명령어로 네트워크 목록을 확인 할 수 있습니다. ✌ BRIDGE NETWORK Bridge는 컨테이너가 사용하는 프라이빗 네트워크입니다. 같은 Bridge로 연결되어 있으면 컨테이너의 IP 주소로 통신할 수 있습니다. 외부로 통신 할 때에는  통신을 사용하며 외부에서 Bridge로 통신을 위해선 을 사용해야 합니다.   도커를 설치하면 …","fields":{"slug":"/docker-network/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - Network","date":"June 26, 2021"}},"next":{"fields":{"slug":"/docker-image/"}},"previous":{"fields":{"slug":"/docker-net2/"}}},{"node":{"id":"59e72fe7-ba09-5687-9fb1-d0c5b71d1bba","excerpt":"머리말    이전 포스트에서는 도커의 설치방법에 대해서 간단하게 포스팅 했었습니다.  이번 포스트에서는 실제 도커의 컨테이너의 생성 관리 방법 및 명령어들을 포스트 했다. ✔ 도커 이미지 도커는 기본적으로 라고 하는 중앙 이미지 저장소에서 이미지를 내려받습니다. 도커 허브는 도커가 공식적으로 제공하고 있는 이미지 저장소로 쉽게 올리고 내려받을 수 있습니다.  Docker Hub 도커 허브는 도커에서 제공하는 기본 이미지 저장소로 ubuntu, centos, debian등의 베이스 이미지와 ruby, golang, java, python 등의 공식 이미지가 저장되어 있습니다. 일반 사용자들이 만든 이미지도 50만 개가 …","fields":{"slug":"/docker-image/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - IMAGE","date":"June 26, 2021"}},"next":{"fields":{"slug":"/docker-container/"}},"previous":{"fields":{"slug":"/docker-network/"}}},{"node":{"id":"17ac3a0c-cbd6-554f-a341-f5738ed79af3","excerpt":"머리말   이전 포스트에서는 도커의 이론적이 내용에 대해서 간단하게 정리한 포스팅을 했었습니다. 이번 포스트에서는 이미지를 이용해서 실제 도커의 컨테이너 생성 관리 방법과 그와 관련된 명령어들을 포스트 했습니다. ✔ 도커 컨테이너 드디어 컨테이너를 실행해 보려고 합니다. 컨테이너의 위대함을 보기위해 여러개의 프로그램을 마구잡이로 띄워보겠습니다. 컨테이너를 실행하는 명령어는 다음과 같습니다. 다음은 자주 사용하는 옵션들입니다. Ubuntu OS 기반의 컨테이너를 생성해보겠습니다. 명령어를 사용하면 사용할 이미지가 저장되어 있는지 확인하고 없다면 다운로드를 한 후 컨테이너를 하고  합니다. 위 예제는  이미지를 다운받은 …","fields":{"slug":"/docker-container/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - CONTAINER","date":"June 26, 2021"}},"next":{"fields":{"slug":"/docker/"}},"previous":{"fields":{"slug":"/docker-image/"}}},{"node":{"id":"86ebeb5f-f270-5f35-ac2b-da9d5887dfe4","excerpt":"머리말    데브옵스나, 인프라엔지니어들에겐 필수적으로 익혀야 하는 기술이지만 나는 이제야 처음 접하기 시작해서 남들보다 쪼금 늦은 것 같다.  약간의 실습만 해봤는데도 이렇게 편하게 할 수 있는 작업들을 나는 그동안 make && install 명령어를 낭비했던 것 같다.  이번 포스트에서는 도커란 무엇인지에 대해 설명한다.   ✔ 도커란 무엇인가?  도커는 의 (오픈소스) 가상화 플랫폼입니다. 라 하면 배에 실는 네모난 화물 수송용 박스를 생각할 수 있는데 각각의 컨테이너 안에는 옷, 신발, 전자제품, 술, 과일등 다양한 화물을 넣을 수 있고 규격화되어 컨테이너선이나 트레일러등 다양한 운송수단으로 쉽게 옮길 수 있…","fields":{"slug":"/docker/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - DOCKER란?","date":"June 26, 2021"}},"next":{"fields":{"slug":"/docker-install/"}},"previous":{"fields":{"slug":"/docker-container/"}}},{"node":{"id":"42ce3601-f03b-5fec-b93c-308b868bf3a5","excerpt":"머리말    이전 포스트에서는 도커에 대해서, 도커와 VM과의 차이 에서 포스팅 했었다.  이번 포스트에서는 실제 도커의 설치방법 및 확인 방법등에 대해 간단하게 포스트 했다. ✔ 도커 설치 도커는 리눅스 컨테이너 기술이므로 macOS나 windows에 설치할 경우 가상머신에 설치가 됩니다. 리눅스 컨테이너 말고 윈도우즈 컨테이너라는 것도 존재하지만 이 포스트는 리눅스를 전제로 합니다.   Linux 리눅스에 도커를 설치하는 방법은 자동 설치 스크립트를 이용하는 것이 가장 쉽습니다. 다음 명령어를 입력하면 root 권한을 요구하고 잠시 기다리면 설치가 완료됩니다. 스크립트를 사용하는 방법 외에도 패키지 저장소에 연결하…","fields":{"slug":"/docker-install/"},"frontmatter":{"categories":"DevOps","title":"[DOCKER] - Install","date":"June 26, 2021"}},"next":{"fields":{"slug":"/gcp-semi/"}},"previous":{"fields":{"slug":"/docker/"}}},{"node":{"id":"2c6aaf2e-afa2-5601-8840-df15a9f171b6","excerpt":"머리말    GCP를 공부하기 위해 모인 사람들로 구성해서 간단한 토이 프로젝트를 진행해보았다.  리눅스를 처음 공부하듯 GCP에서도 웹페이지를 띄우는 프로젝트를 우선 진행해보았다.   ✔ GCP를 사용한 웹 사이트 구축 토이 프로젝트 사용기술 GCP 인스턴스 SQL (VPC) 로드밸런싱 오토스케일링 HTTP/APACHE/MYSQL/Wordpress DNS  개요   오토스케일링은 클라우드 환경의 가장 기본적 요소들 중에 하나입니다.   트래픽 집중에 따라 서버, 스토리지 등의 자원이 자동으로 확장하면서  안정적인 서비스를 유지 할 수 있습니다.   서버의 개수가 늘어나는 것을   줄어드는 것을 이라고 한다.   오토…","fields":{"slug":"/gcp-semi/"},"frontmatter":{"categories":"CLOUD","title":"[GCP] - wordpress 생성해보기","date":"June 25, 2021"}},"next":{"fields":{"slug":"/gcp-02/"}},"previous":{"fields":{"slug":"/docker-install/"}}},{"node":{"id":"b2d897ea-0b3a-513b-94ba-e1357a3a976b","excerpt":"머리말   GCP를 공부를 시작하면서 기존의 IDC 지식들이 너무 과거의 것이라는 것을 알 수 있었다. 새로운 것들을 받아드리는 것이 빠르지 못하면 뒤쳐질 수 있다는 걸 깨달은 포스트이다. ✔ “GCP SQL/BUCKET” 이란 ? GCP SQL 평소에 서버내에서 설치/구성해서 사용해왔었던 MYSQL/MARIA 등을 구글 플랫폼 자체에서 활용/적용 할 수 있는 기능. 즉 원격으로 사용 할 수 있는 RDB 라고 생각하면 된다.   GCP BUCKET 보통 스토리지는 서버/PC에 다이렉트하게 붙여서 이용해왔다. NFS/ISCSI 등으로 원격지에서 접속이 가능한 기능도 있지만 GCP에서는 BUCKET이라는 형태의 스토리지로…","fields":{"slug":"/gcp-02/"},"frontmatter":{"categories":"CLOUD","title":"[GCP] - SQL/BUCKET 생성","date":"June 25, 2021"}},"next":{"fields":{"slug":"/gcp-first/"}},"previous":{"fields":{"slug":"/gcp-semi/"}}},{"node":{"id":"dc8f4c53-4776-5d97-b3e6-e14f8b8c270c","excerpt":"머리말   새롭게 클라우드 지식을 쌓기 위해서 GCP에 대해서 포스팅 하려고 합니다.   ✔ GCP/COMPUTE INSTANCE 이란 ? 구글 플랫폼 기반에서 사용할 수 있는 가상의 컴퓨터.  이라고 생각하면 됩니다. IaaS(인프라스트럭처인 cpu, mem, disks등의 인프라를 만들어주는 서비스) PaaS(내가 필요한 코드만 짜서 올려서 사용하는 서비스) Saas(내가 코드를 사용하는 것도 필요없고 서비스를 가져와서 사용하게 된다) 까지 다양하게 서비스를 제공하고 있다 ✌ GUI 기반 VM 인스턴스 생성   GCP 웹페이지로 가서 인스턴스를 생성해보겠습니다.    Compute Engine - VM 인스턴스 만…","fields":{"slug":"/gcp-first/"},"frontmatter":{"categories":"CLOUD","title":"[GCP] - 인스턴스 생성","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-iscsi/"}},"previous":{"fields":{"slug":"/gcp-02/"}}},{"node":{"id":"ab9afc05-9d40-5246-b06f-1770a6ba933b","excerpt":"머리말   ISCSI의 경우 실무에서 써본 기억은 잘 나지 않지만 개인적으로 인프라공부나, 가상머신을 구축했을때 몇번 만져 본 적은 있었습니다. 이번 포스트를 적으면서 이론적인 내용에 대해 다시 배웠습니다. ✔ ISCSI 이란 ?   iSCSI(Internet Small Computer System Interface)는 저렴한 비용으로 데이터 저장소를 연결하는데 사용되는   IP 기반의 Storage 네트워킹 표준입니다. 즉, IP 네트웍 상에서 SCSI 명령을 수행함으로써 iSCSI가 로컬 영역 네트워크 (LAN), 광역 네트웍 (WAN) 또는 인터넷 상에서 보다 손쉽게 데이터를 전송하는 것이 가능합니다.   따라서…","fields":{"slug":"/linux-iscsi/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - ISCSI","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-thin-provisioning/"}},"previous":{"fields":{"slug":"/gcp-first/"}}},{"node":{"id":"745de7e4-5502-550a-8d57-8812747acd7f","excerpt":"머리말   Thin provisioning은 경험해본 적도 들어본 적도 한번도 없는 기술입니다. 어디서 쓸까? 생각해보면 메일이나, 클라우드를 제공하는 회사들에서 많이 쓸 것 같은 느낌입니다. ✔ Thin provisioning이란? Thin provisioning 이란 쉽게 얘기하면 사용한 만큼만의 용량을 할당하는 방식입니다. 10G를 할당 받았지만 3G의 공간만을 사용한다면 실제 사용분만큼의 용량을 제공하는 방식입니다. 용량을 더 사용한다면 용량을 확보해주고 줄일 경우 사용했던 공간을 회수해 가는 방식으로. 잉여 자원을 최대한 억제 할 수 있게 됩니다.   그림을 보면 이해가 쉽습니다!! 스크린샷, 2020-08-…","fields":{"slug":"/linux-thin-provisioning/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - This-Provisioning","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-lvm/"}},"previous":{"fields":{"slug":"/linux-iscsi/"}}},{"node":{"id":"845ef170-ee44-5689-a678-0e8f07708de8","excerpt":"머리말   안녕하세요 NASA 입니다. 이번 포스트는 LVM에서 다뤄보겠습니다. ✔ LVM(Logical Volume Manager) 이란? Logical Volume을 효율적이고 유연하게 관리하기 위한 커널의 한 부분이자 프로그램입니다. 기존에는 파일시스템이 블록 장치에 직접 접근해서 읽고/쓰기를 했다면 LVM을 사용하면 파일 시스템이 가상의 블록 장치에 읽고/쓰기를 하게 됩니다.   LVM의 장점 유연한 용량   크기 조정 가능한 스토리지 풀(Pool)   온라인 데이터 재배치   편의에 따라 장치 이름 지정   디스크 스트라이핑   미러 볼륨   볼륨 스냅샷    아래 이미지 처럼 LVM은 물리적 스토리지 이상의…","fields":{"slug":"/linux-lvm/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - LVM","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-raid/"}},"previous":{"fields":{"slug":"/linux-thin-provisioning/"}}},{"node":{"id":"c2037712-9aa6-51d1-bb6e-68c362426cd0","excerpt":"✔ RAID란?  RAID는 Redundant Array of Inexpensive Disks의 약자입니다.  여러 개의 디스크를 배열해 속도의 증대, 안정성의 증대, 효율성, 가용성의 증대를  하는데 쓰이는   즉 쉽게 말해 입니다.   RAID의 사용 목적 서버 운영에 있어 가장 크리티컬 이슈는 하드디스크의 장애로 인한 DATA 손실일 것 입니다. 하드디스크는 사실상 소모품으로 분류되며 I/O가 많은 서버에는 고장이 잦은 것은 당연하죠. 하지만 서버에 저장되는 데이터의 경우 손실 또는 유출 되었을 때 치명적인 것이 대부분일 것으로 대표적으로 은행과 같은 금융, 군사적 목적의 데이터가 있을 것입니다. 이로 인해 백업…","fields":{"slug":"/linux-raid/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - RAID","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-smb/"}},"previous":{"fields":{"slug":"/linux-lvm/"}}},{"node":{"id":"8d2b306b-d519-510a-a4ea-f5e880b8cf59","excerpt":"머리말   SMB에 대해서는 몇번 들어보긴 했지만 정확히는 모르는 상태였습니다. 실제로 실습을 해본 적도 없고 그냥 공유 디렉토리 설정이라고만 알고있었는데 로직등, 실습을 해보면서 대충은 알 것 같습니다.  ✔ SMB (Server Message Block)이란 ? SMB는 Linux 시스템과 Window 시스템의 로컬 디렉토리를 공유할 때 사용합니다. Window 시스템에서 구성 후 Linux 시스템에 연결이 가능하고 반대로 Linux 시스템에서 구성 후 Window 시스템에서도 연결이 가능합니다. SMB/CIFS SMB 프로토콜은 TCP/IP 위에서 동작하며 본래 로컬 네트워크가 아닌 다른 네트워크에 존재하는 시스…","fields":{"slug":"/linux-smb/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - SMB","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-nfs/"}},"previous":{"fields":{"slug":"/linux-raid/"}}},{"node":{"id":"f46b0d1f-c0cc-540f-8f01-2f6f0d7f95f8","excerpt":"머리말   DNS에 대해서 이론적인 내용도 대충 알고 있었다. 이번 포스트를 작성하면서 이론적인 내용과 함께 실제로 구축 실습을 해보면서 정확한 개념을 얻을 수 있었다.  ✔ NFS (Network File system)이란 ? RPC를 이용하여 리모트 호스트 사용자가 원격지 컴퓨터에 있는 파일을 마치 로컬 파일에 access 하듯이 사용 할 수 있도록 하는 클라이언트 / 서버형 파일 시스템 공유 프로토콜 네트워크 파일 시스템의 일종이며 유닉스 환경에서 네트워크를 통해 파일과 응용 프로그램을 호스트간 공유하게 해주는 서비스 대형 서비스 환경 구축 시 공유 파일 서버를 사용하여 데이터의 일관성을 유지 하는 경우가 많은데…","fields":{"slug":"/linux-nfs/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - NFS","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-dns/"}},"previous":{"fields":{"slug":"/linux-smb/"}}},{"node":{"id":"1c7fdc86-6cbb-5090-9d9e-1cf15f78b2c5","excerpt":"머리말  DNS에 대해서 이론적인 내용도 대충 알고 있었습니다만 이번 포스트를 작성하면서 이론적인 내용과 함께 실제로 구축 실습을 해보면서 정확한 개념을 얻을 수 있었습니다.  ✔ DNS (Domain Name Server) 란?  DNS는 도메인 네임 서버를 일컫습니다.  인터넷은 서버들을 유일하게 구분할 수 있는 IP주소를 기본체계로 이용하는데  숫자로 이루어진 조합이라 인간이 기억하기에는 무리가 따릅니다.  따라서 DNS를 이용해 IP주소를 인간이 기억하기 편한 언어 체계로 변환하는 작업이 필요한데  이 역할을 DNS가 하는 것입니다.   특징 PORT : 53 PROTOCOL : TCP/UDP 디렉토리 서비스 …","fields":{"slug":"/linux-dns/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - DNS","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-syslogd/"}},"previous":{"fields":{"slug":"/linux-nfs/"}}},{"node":{"id":"bd163128-e0c1-5954-9d41-6fe0196f9cb0","excerpt":"머리말   Centos Version이 7로 올라감에 따라 새롭게 기능이 추가된 것 중 하나 입니다. 실제로 바이너리 로그등을 확인하고, 분석하는데 불편함이 많았었는데 JOUNALCTL은 사용자의 편리함을 제공하는 것 같습니다.   ✔ SYSLOG 란? 기존의 SYSLOG에서는 운영로그, 설치로그, 보안로그 등을 (바이너리,텍스트) 파일의 형태로 남겼었습니다. 그렇지만 RSYSLOG는 journalD이 추가되며 원시적 로그 파일도 남기게 되면서 시스템 동작, 운영 로그들을 메모리에 Journal 로그(바이너리)로 생성합니다.   커널 및 응용 프로그램이 syslog API를 통해 로그 생성시 (r)syslogd 프로세…","fields":{"slug":"/linux-syslogd/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - SYSLOGD","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-package/"}},"previous":{"fields":{"slug":"/linux-dns/"}}},{"node":{"id":"958f5fd5-f2a2-518e-85ce-899c1a232986","excerpt":"머리말   저의 경우에는 LINUX라고는 CENTOS 와 REDHAT의 경험밖에 없다보니 데비안, 우분투, 등등의 여러 리눅스에서 사용하는 패키지 관리자에 대한 배경지식이 없어서 이 포스트 작성이 큰 도움이 되었습니다.   ✔ 패키지 관리자란? 윈도우로 서버를 운영하면 IIS의 가장 장점은 바로 웹 플랫폼 설치관리자 입니다. 그 이유중에 하나는 복잡한 설치과정을 간단하게 클릭 몇번만으로 설치 및 설정까지 자동으로 해주기 때문에 편리하다고 하였는데 사실 리눅스에도 이와 비슷한 기능을 가지고 있는 패키지 저장소가 있습니디.   리눅스에서의 패키지 관리 시스템은 터미널 명령어로 진행해야 하기 때문에 GUI 방식인 웹 플랫폼…","fields":{"slug":"/linux-package/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - 패키지 관리자 RPM, YUM","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-firewall/"}},"previous":{"fields":{"slug":"/linux-syslogd/"}}},{"node":{"id":"bc98a4b2-be2d-5ad0-9cd8-3f6e865d6438","excerpt":"✔ FIREWALL (침입차단시스템) 란? 리눅스 방화벽은 외부의 네트워크에서 내부의 시스템으로 접근하는 네트워크 패킷을 차단합니다. 리눅스 방화벽의 경우 Netfilter에 의해 적용되며 시스템 내부로 전달, 폐기를 결정하는 모듈입니다. RHEL7부터는 방화벽을 관리하는 데몬이 firewalld로 변경되어 방화벽 설정은 iptables 명령어 대신 아래 명령어를 사용해야 합니다. firewall-cmd (콘솔   firewall-config (X-Windows)   기존에 사용했던 이 완전이 사라진 것은 아닙니다. firewalld이 iptables를 기반으로 동작하고 있을 뿐 입니다. (firewalld은 ipta…","fields":{"slug":"/linux-firewall/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Firewall","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-systemd/"}},"previous":{"fields":{"slug":"/linux-package/"}}},{"node":{"id":"662977c8-879a-59cd-8534-7d40a4356f94","excerpt":"머리말   기존 CentOS Version 5.x , 6.x 만 경험 해본 저로써는 CentOS 7버전 부터는 \n다시 리눅스를 배우고 있다고 생각하게 됩니다. 이번 포스트에서는 기존 버전에서 사용하던 init 에서 바뀐 systemd에 대해 포스트 합니다.   ✔ SYSTEMD 란? 기존 INIT이 사라지고 새롭게 사용하는 프로세스 관리 Demon 역할 : 시스템, 로그, 서비스, 초기화 스크립트 관리 기능 수행 👌 간단 요약 SYSTEMD를 요약하면 부팅 중 시작하는 서비스(혹 데몬)들을 관리하는 것이라고 볼 수 있습니다.     부팅 시점에 정의한 서비스들을 병렬적으로 실행 할 수 있습니다. (init의 경우 직렬…","fields":{"slug":"/linux-systemd/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - SYSTEMD","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-swap/"}},"previous":{"fields":{"slug":"/linux-firewall/"}}},{"node":{"id":"0237d257-e5a3-57a2-82a8-5f8a341d531f","excerpt":"머리말   안녕하세요 NASA 입니다! 이번 포스트에서는 리눅스 가상메모리 즉 SWAP에 대해서 포스트 했습니다.   ✔ 가상메모리 가상메모리 (SWAP) swap 은 물리 메모리가 부족할 경우를 대비해 만든 영역입니다. 간단히 말해서 메모리 부족으로 인한 이슈를 막기위해 HDD로 확보해놓은 메모리 공간입니다. SWAP을 쓰는 이유? 메모리 부족 멀티태스킹(스와핑, 페이징등 우선순위 프로그램의 리사이클을 위해) 메모리(full) 덤핑 스와핑 : 전체 프로세스 주소 공간 또는 공유 할 수 없는 텍스트 데이터 세그먼트를 스왑 장치에 복사하거나  (일반적으로 디스크) 복사하는 것을 말합니다 swap in : 하드디스크의 프…","fields":{"slug":"/linux-swap/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - SWAP","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-partition/"}},"previous":{"fields":{"slug":"/linux-systemd/"}}},{"node":{"id":"828d15a2-3535-5034-9e6d-a0f2ee856e06","excerpt":"머리말   이번 포스트에서는 리눅스 파티션에 대해서 포스트했습니다. 아마 리눅스뿐만 아니라 다른 쪽으로도 유용하게 사용할 수 있는 지식일 것입니다. ✔ 리눅스 파티션 리눅스에서 사용하는 파티션의 종류는 세 가지가 있습니다. 첫째 Primary Partition  파티션이 있습니다. Maximum 4개까지 생성 가능 합니다. (사용하는 용도에 맞게 1개~4개 까지 조절해서 사용) 둘째 Extend Partition  파티션이 있습니다. Maximum 1개까지 만들 수 있습니다. (최대가 1개이기 때문에 조절해서 사용합니다.) 셋째 Ligical Partition  파티션이 있습니다. Extend Patition 안에 만…","fields":{"slug":"/linux-partition/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Partition","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-cron/"}},"previous":{"fields":{"slug":"/linux-swap/"}}},{"node":{"id":"160f9a4e-ca45-5f19-8a90-6f768c6d810d","excerpt":"머리말   이번 포스트에서는 개인적으로 실무에서 가장 많이 사용했던 CROND에 대해서 포스트 해보았습니다. ✔ CRON 리눅스에서는 일반적으로 cron 데몬이 주기적인 작업 실행을 처리합니다. cron의 설정 파일은 cron table을 줄여서 이라 부릅니다.   CRON의 실행 확인 cron은 작동 시 모든 설정파일들을 읽어 메모리에 저장해두고 휴지 상태에 들어갑니다. 그리고 매분마다 활성화돼 변경된 crontab 파일들이 있는지 확인하고 파일이 변경된 경우 설정을 다시 읽어 저장하고 실행해야 할 작업이 있는지 확인하고 실행시킨 후 다시 휴지 상태로 들어갑니다.   cron이 참조하는 crontab 파일 위치 /v…","fields":{"slug":"/linux-cron/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - CRONTAB, CRON","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-acl/"}},"previous":{"fields":{"slug":"/linux-partition/"}}},{"node":{"id":"bdffa384-3510-54b2-8772-32e848ce0547","excerpt":"머리말   이번 포스트에서는 리눅스에서 설정하는 ACL (Access Control List) 대해서 포스트 했습니다.    ✌ ACL (Access Controll List) setfacl 과 getfacl UMASK로는 특정 파일에 alice 사용자에게 읽기 권한만 주고 Eve와 Frank는 읽기/쓰기 권한을 주는 등의 세밀한 권한 조정은 불가능합니다. 이 문제를 해결하기 위해 ACL을 구현하면 cp, mv 같은 파일을 다루는 유틸리티의 권한도 수정 할 수 있게 됩니다.   ACL 설정 (Link to ACL 설정) ACL에는 access ACL 과 Default ACL 두 가지 형식이 존재합니다.. \t acces…","fields":{"slug":"/linux-acl/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - Access Control List (ACL)","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-chmod/"}},"previous":{"fields":{"slug":"/linux-cron/"}}},{"node":{"id":"d015d803-037c-526d-9a78-a2abd4724d25","excerpt":"머리말   이번 포스트에서는 리눅스 권할 설정에 대해서 정리했습니다. 정말! 정말! 많이 사용하는 것들이기 때문에 머리에 박아 둬야 합니다.  ✔ 권한 설정 파일, 디렉토리 권한 설정      명령을 사용하여 파일, 디렉토리 리스트를 출력하면 을 확인 할 수 있습니다. 출력 결과는 각각 다음을 나타냅니다 파일 종류 및 권한(퍼미션) 링크수 사용자(소유자) 그룹 파일크기 수정시간 파일이름 권한 설정 명령어 chmod chown chgrp  - 개별적으로 파일 권한 변경하기, 알파벳 (rwx), 숫자 (umask) 로 권한을 설정 할 수 있습니다.  - 파일의 소유자 변경 특수권한 1 SetUID 소유자만 접근 가능한 파…","fields":{"slug":"/linux-chmod/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - 권한 설정 chmod, Setuid...","date":"June 23, 2021"}},"next":{"fields":{"slug":"/network-for-beginner2/"}},"previous":{"fields":{"slug":"/linux-acl/"}}},{"node":{"id":"bea7d5d5-4965-59de-913e-4a263b3d1214","excerpt":"머리말   이전 포스트인 네트워크 기초 Part - 1에서 미처 정리하지 못한 부분까지 정리한 포스트입니다!.  👍 1. 네트워크 장비 라우터 : 네트워크 사이에 데이터 전송을 수행 라우터에 의해 네트워크를 상호 연결할 수 있다. 라우터는 IP 주소를 사용, 네트워크 간의 데이터 전송을 수행하며 이를  ‘Routing’ 이라고 한다. 라우팅을 위해서는 미리 라우팅 테이블에 네트워크 정보를 등록해야한다. 테이블에 등록되지 않은 주소가 목적지인 데이터는 라우터에 의해 파기된다.    스위치 :  같은 네트워크 내부에서 데이터 전송을 수행 스위치는 PC나 서버에 있어 네트워크 입구에 해당하는 \n네트워크 기기이다. 스위치는 …","fields":{"slug":"/network-for-beginner2/"},"frontmatter":{"categories":"NETWORK","title":"[Routing, Switching] 네트워크 기초 Part - 2","date":"June 23, 2021"}},"next":{"fields":{"slug":"/network-for-beginner/"}},"previous":{"fields":{"slug":"/linux-chmod/"}}},{"node":{"id":"84beed64-d6c6-5d9f-8c64-1b974d8b31e1","excerpt":"머리말   이전 직장에서 스위치, 라우터등을 직접만지고 설정해보면서 기초지식이 충분하다고 생각했었지만 이 역시도 많이 희미해져있는 상태였습니다. 그래도 이 포스트를 작성하며 정리를 해보니 그래도 많이 리와인드 된 것 같아서 기분이 좋습니다.   👍 1. OSI 7 계층 OSI 7 계층이란? ISO(국제표준화기구)에서 개발한 모델 컴퓨터 네트워크 프로토콜 디자인과 통신을 계층을 나누어 설명한 것   계층 별 프로토콜 및 서비스 CSMA/CD (arrier Sense Multiple Access/Collision Detection) 반송파 감지 다중 엑세스/ 충돌검출 PDU (Protocol Data Unit) SDU (…","fields":{"slug":"/network-for-beginner/"},"frontmatter":{"categories":"NETWORK","title":"[OSI 7-layer, TCP/IP] - 네트워크 기초 Part - 1","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-for-beginner/"}},"previous":{"fields":{"slug":"/network-for-beginner2/"}}},{"node":{"id":"56bee2ed-c5ac-5157-a832-da1dacb23afa","excerpt":"머리말  저는 2016년? 정도부터 IDC Infra와 Backend FrameWork을 다루는 엔지니어로 약 2년정도 일을 했었지만 군대의 공백 때문에 실무에서 쌓아놨었던 지식들이 희미해지기 시작했습니다. 그렇기 때문에 첫 블로그 글은 개발이나 인프라 모든 분야에서 필요한 리눅스를 다루며 다시 리와인드하는 포스트로 시작해보겠습니다.  ✔ 리눅스(LINUX) OS의 기본 구성 요소 커널 (Kernel) 파일 입출력, 프로세스 관리 등과 같이 운영체제의 기능을 담당 프로세스 관리 : 프로세스 및 스레드 생성과 삭제, 스케줄링 등     파일 관리 : 디스크 상의 파일을 관리   메모리 관리 : 메인 메모리를 효과적으로 …","fields":{"slug":"/linux-for-beginner/"},"frontmatter":{"categories":"LINUX","title":"[LINUX] - 리눅스 기초","date":"June 23, 2021"}},"next":null,"previous":{"fields":{"slug":"/network-for-beginner/"}}}]}},"staticQueryHashes":["1073350324","2938748437"]}