{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/GCP","result":{"pageContext":{"currentCategory":"GCP","categories":["All","LINUX","AZURE","DATA","Kubernetes","GCP","DevOps","DOCKER","Error-Report","NETWORK","AWS"],"edges":[{"node":{"id":"14668db0-2f50-511a-abf9-9d92fcdc88bd","excerpt":"머리말   저번 포스트에서 DataProc에 대한 설명과 간단한 사용법을 다뤄봤었습니다. 이번에는 GCP에서 파트너 SaaS형태로 제공해주는 DataBricks를 사용해서 지난번과 동일한 데이터, 스트립트를 이용해서 성능이나, 사용법에 대한 테스트를 해봤습니다. 물논 이번에도 파이썬을 첨가해서   ✔ DataBricks? og-databricks Databricks란? 간단 요약해서 Spark,Hadoop 등 빅데이터 관련 솔루션 실행환경을 제공하는 클라우드 서비스입니다. 통합 분석 플랫폼으로, 한 WorkSpace내에서 여러 서비스를 사용해 모든 분석이 가능합니다. 이전에 Spark, Hadoop을 ON-Premis…","fields":{"slug":"/data-databricks/"},"frontmatter":{"categories":"GCP DATA","title":"[DATA, GCP] - GCP DataBricks 사용기","date":"September 12, 2021"}},"next":{"fields":{"slug":"/gcp-dataproc2/"}},"previous":{"fields":{"slug":"/data-gadata-appflow/"}}},{"node":{"id":"c0b1f1d9-1ce1-51df-9998-f2fdcca0e5a7","excerpt":"머리말   저번 포스트에서 DataProc에 대한 설명과 간단한 사용법을 다뤄봤었습니다. 이번에는 DataProc Cluster에 Pyspark Script를 사용해서 \n자동화 JOB을 만들어 보겠습니다. 파이썬을 첨가해서   ✔ Data Data의 경우에는 이전 포스트에서 다뤘었던 Covid-19의 기상 데이터를 기반으로 진행합니다.   12312312 용량 : 약 51GB 행 : 542,304,210 2222 데이터 형식 요약 👍 Python Script 위의 데이터에서 특정 그룹(나라, 날짜) 별로 MAX,MIN,AVG 값들의 평균 값을 구하는 스크립트  간단 설명 : GCS에서 CSV Format의 Data를 …","fields":{"slug":"/gcp-dataproc2/"},"frontmatter":{"categories":"GCP DATA","title":"[DATA, GCP] - GCP DataProc 2탄 Pyspark JOB Access","date":"September 10, 2021"}},"next":{"fields":{"slug":"/gcp-dataproc/"}},"previous":{"fields":{"slug":"/data-databricks/"}}},{"node":{"id":"f1eefdc3-7c74-544e-b4c9-728dcf1c72c7","excerpt":"머리말   이번에는 DataProc(Hadoop/Spark)를 사용하여 \n대용량의 데이터를 처리하는 방법에 대해서 다룹니다. 물론 파이썬을 첨가해서   ✔ DataProc에 대해서.. Dataproc은 일괄 처리, 쿼리, 스트리밍, 머신 러닝에 오픈소스 데이터 도구를 활용할 수 있는 관리형 Spark 및 Hadoop 서비스입니다. 즉 지금까지 귀찮게 Spark, Hadoop을 연동하는 과정을 없애고 사용만하면 되는 서비스라고 볼 수 있습니다.   여기서 DataFlow와 DataProc의 차이에 대해서 궁금증이 생겼는데 두 툴 모두 ETL을 하는 툴에 대해서는 공통점을 가지고 있지만 DataFlow는 Serverles…","fields":{"slug":"/gcp-dataproc/"},"frontmatter":{"categories":"GCP DATA","title":"[DATA, GCP] - GCP DataProc spark Cluster로 ETL 후 BigQuery에 적재","date":"September 08, 2021"}},"next":{"fields":{"slug":"/azure-datafactory/"}},"previous":{"fields":{"slug":"/gcp-dataproc2/"}}},{"node":{"id":"d7e3e240-ef5e-5891-af05-6c06162c25f1","excerpt":"머리말   요즘 포스트를 작성 할 시간이 부족했습니다…(일…) 그래서 오랜만에 포스트를 올린 기념으로 이번 내용을 더욱 알차게 준비했습니다. 이번 포스트에서는 GCP의 DataFlow를 사용해 GCS에 있는 CSV 파일을 간단한 Parsing 작업을 한 뒤 BigQuery Table에 적재하는 부분을 다뤘습니다. 물론 파이썬을 첨가해서   ✔ DataFlow에 대해서.. DataFlow는 GCP에서 DataPipeline(ETL, MR 등)을 Apache Beam 기반으로 동작하도록 만든 Runtime Service 입니다. 음 간단하게 말하면 Spark Streming이나 Batch 처리를 Cloud를 사용해 Paa…","fields":{"slug":"/data-gcpdataflow/"},"frontmatter":{"categories":"DATA GCP","title":"[DATA] - GCP DataFlow, csv from GCS to BigQuery With Python","date":"September 02, 2021"}},"next":{"fields":{"slug":"/azure-coludshellerror/"}},"previous":{"fields":{"slug":"/azure-datafactory/"}}},{"node":{"id":"801845e2-ac0a-5de8-bf0a-12fd8d8036e2","excerpt":"머리말   이번 포스트에서는 앱 구동을 위한 MYSQL 이중화입니다 이전 포스트에서 앱 배포를 완료했지만 MYSQL pod의 경우 볼륨의 문제로 하나밖에 뜨지 않아 DB 데이터를 어떻게 저장할지에 대한 고민이 있었습니다. 고민해본 결과 NFS를 만들어서 그쪽에 데이터를 저장해놓고 POD가 실행될때마다 NFS를 읽어오자! 라는 결론이 나왔습니다 그래서 NFS 서버를 구축하려고 하려는 찰나 GCP에서 API 서비스로 제공한다는 소식을 듣고 바로 사용해 보았습니다 사용 할 툴을 다음과 같습니다.   GCP FileStore k8s PV,PVC ArgoCD ✔ 발생 이슈 MYSQL Pod를 두개 이상 띄우려고 할때 아래와 같…","fields":{"slug":"/devops-gcpfilestore/"},"frontmatter":{"categories":"DevOps GCP","title":"[DEVOPS] - GCP의 FileStore (NFS) 를 PV로 사용해보자","date":"August 07, 2021"}},"next":{"fields":{"slug":"/devops-cicd2/"}},"previous":{"fields":{"slug":"/devops-jenkinspush/"}}},{"node":{"id":"4c31f4f6-beeb-5136-85e5-ea2c0b6b62e5","excerpt":"머리말   가급적이면 모든 업무를 코드화 하고 싶었습니다. 그러기위해서 가장 기초가 되어야 하는 부분은 원격접속이라고 생각해서 포스팅합니다. ✔ Google Cloud SDK를 설치 공식 DOC Google Cloud SDK 설치 : 이 포스트는  환경에서 진행하였습니다 패키지 소스로 Cloud SDK 배포 URI를 추가합니다. 설치 전 apt-transport-https 의 설치 유무를 확인합니다. Google Cloud 공개 키를 가져옵니다. Cloud SDK를 업데이트하고 설치합니다.   gcloud init 명령을 통해 사용합니다! 그럼 특정 계정 접속을 선택할 수 있는데 알맞게 선택합니다   계정 선택!   …","fields":{"slug":"/gcp-cloudshell/"},"frontmatter":{"categories":"GCP","title":"[GCP] - GCP Cloud shell 원격 접속 하기","date":"August 07, 2021"}},"next":{"fields":{"slug":"/devops-argocd/"}},"previous":{"fields":{"slug":"/devops-cicd2/"}}},{"node":{"id":"3530a618-aa45-5512-8771-62a86a0ea7dc","excerpt":"머리말   안녕하세요 NASA입니다!!. 이번 포스트에서는 Open Source인 Rancher를 이용한 k8s 클러스터 구축에 대한 포스트입니다 이전 포스트와 다른점은 이전에는 이미 구성되어있는 클러스터를 사용했다면 이번 포스트에서는 GKE를 사용했다는 점입니다!! 사용 할 툴을 다음과 같습니다.   docker, Rancher (GKE) k8s ✔ 환경구성 환경구성은 다음과 같습니다. 스크린샷, 2020-10-13 17-18-15 Rancher : Rancher master가 띄워져있는 Cluster 관리 서버 Jenkins : 이전 포스트에서 설정한 CI 작동 서버 gke : GKE 클러스터 노드 GKE SERV…","fields":{"slug":"/devops-rancher-gke/"},"frontmatter":{"categories":"DevOps GCP","title":"[DEVOPS] - GKE Cluster를 Rancher에 연동하기","date":"August 06, 2021"}},"next":{"fields":{"slug":"/devops-rancher/"}},"previous":{"fields":{"slug":"/devops-argocd/"}}},{"node":{"id":"02ef2350-d7b7-5949-8669-9c9f4ed8580e","excerpt":"머리말   이전 포스트에서는 kubespay 자동화 툴을 사용해서 K8S 클러스터를 구축 했었습니다. 이번 포스트에서는 kubeadm을 이용해서 K8S 클러스터를 구축하는 방법에 대해서 포스트했습니다.   ✔ 사전준비 사전 준비의 경우 kubespray와 동일하게 GCP VM Instance에서 구성했기 때문에 방법이 동일합니다. 사전 준비는 이전 포스트인 kubespray를 확인해주세요. ✌ 쿠버네티스  설치하기 kubeadm 본격적인 설치 과정입니다.\n은  과  을  때문에 직접 설치해야 합니다.   전체 Server에 아래 를 추가합니다.   CENSOS yum update 도커 설치 전 사전 세팅  도커 저장소…","fields":{"slug":"/kubernetes-kubeadm/"},"frontmatter":{"categories":"Kubernetes GCP","title":"[Kubernetes] - Kubernetes 환경구성 on GCP Using kubeadm","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubetnetes-kubespary/"}},"previous":{"fields":{"slug":"/kubernetes-error1/"}}},{"node":{"id":"22b18939-b966-58ca-8408-1ddb10464062","excerpt":"머리말   쿠버네티스 환경을 구성하는 방법은 여러가지가 존재합니다 서버를 준비하는 방법은 또한 여러 가지가 있겠지만 가장 쉽게 생각해볼 수 있는 건  와  를 이용한 로 구성하는 것 입니다. 하지만 이번 포스트에서는 GCP STUDY + Kubernetes STUDY 겸 GCP로 진행했습니다. 사실 GCP 무료 크레딧이 아까운 마음이 더 크긴 했습니다. ✔ 사전준비 쿠버네티스는 3개월 마다 새로운 버전이 릴리즈 되고 해당 버전은 9개월 동안 버그와 보안 이슈를 수정하는 패치가 이루어 집니다.   이번 포스트에 구성할 노드는 와 로 총 의 서버가 필요합니다. 노드의 최소 요구 사양은 다음과 같습니다. 항목 사양 CPU …","fields":{"slug":"/kubetnetes-kubespary/"},"frontmatter":{"categories":"Kubernetes GCP","title":"[Kubernetes] - Kubernetes 환경구성 on GCP Using KubeSpary","date":"June 29, 2021"}},"next":{"fields":{"slug":"/kubernetes01/"}},"previous":{"fields":{"slug":"/kubernetes-kubeadm/"}}},{"node":{"id":"2c6aaf2e-afa2-5601-8840-df15a9f171b6","excerpt":"머리말    GCP를 공부하기 위해 모인 사람들로 구성해서 간단한 토이 프로젝트를 진행해보았다.  리눅스를 처음 공부하듯 GCP에서도 웹페이지를 띄우는 프로젝트를 우선 진행해보았다.   ✔ GCP를 사용한 웹 사이트 구축 토이 프로젝트 사용기술 GCP 인스턴스 SQL (VPC) 로드밸런싱 오토스케일링 HTTP/APACHE/MYSQL/Wordpress DNS  개요   오토스케일링은 클라우드 환경의 가장 기본적 요소들 중에 하나입니다.   트래픽 집중에 따라 서버, 스토리지 등의 자원이 자동으로 확장하면서  안정적인 서비스를 유지 할 수 있습니다.   서버의 개수가 늘어나는 것을   줄어드는 것을 이라고 한다.   오토…","fields":{"slug":"/gcp-semi/"},"frontmatter":{"categories":"GCP","title":"[GCP] - wordpress 생성해보기","date":"June 25, 2021"}},"next":{"fields":{"slug":"/gcp-02/"}},"previous":{"fields":{"slug":"/docker-install/"}}},{"node":{"id":"b2d897ea-0b3a-513b-94ba-e1357a3a976b","excerpt":"머리말   GCP를 공부를 시작하면서 기존의 IDC 지식들이 너무 과거의 것이라는 것을 알 수 있었다. 새로운 것들을 받아드리는 것이 빠르지 못하면 뒤쳐질 수 있다는 걸 깨달은 포스트이다. ✔ “GCP SQL/BUCKET” 이란 ? GCP SQL 평소에 서버내에서 설치/구성해서 사용해왔었던 MYSQL/MARIA 등을 구글 플랫폼 자체에서 활용/적용 할 수 있는 기능. 즉 원격으로 사용 할 수 있는 RDB 라고 생각하면 된다.   GCP BUCKET 보통 스토리지는 서버/PC에 다이렉트하게 붙여서 이용해왔다. NFS/ISCSI 등으로 원격지에서 접속이 가능한 기능도 있지만 GCP에서는 BUCKET이라는 형태의 스토리지로…","fields":{"slug":"/gcp-02/"},"frontmatter":{"categories":"GCP","title":"[GCP] - SQL/BUCKET 생성","date":"June 25, 2021"}},"next":{"fields":{"slug":"/gcp-first/"}},"previous":{"fields":{"slug":"/gcp-semi/"}}},{"node":{"id":"dc8f4c53-4776-5d97-b3e6-e14f8b8c270c","excerpt":"머리말   새롭게 클라우드 지식을 쌓기 위해서 GCP에 대해서 포스팅 하려고 합니다.   ✔ GCP/COMPUTE INSTANCE 이란 ? 구글 플랫폼 기반에서 사용할 수 있는 가상의 컴퓨터.  이라고 생각하면 됩니다. IaaS(인프라스트럭처인 cpu, mem, disks등의 인프라를 만들어주는 서비스) PaaS(내가 필요한 코드만 짜서 올려서 사용하는 서비스) Saas(내가 코드를 사용하는 것도 필요없고 서비스를 가져와서 사용하게 된다) 까지 다양하게 서비스를 제공하고 있다 ✌ GUI 기반 VM 인스턴스 생성   GCP 웹페이지로 가서 인스턴스를 생성해보겠습니다.    Compute Engine - VM 인스턴스 만…","fields":{"slug":"/gcp-first/"},"frontmatter":{"categories":"GCP","title":"[GCP] - 인스턴스 생성","date":"June 23, 2021"}},"next":{"fields":{"slug":"/linux-iscsi/"}},"previous":{"fields":{"slug":"/gcp-02/"}}}]}},"staticQueryHashes":["1073350324","2938748437"]}