{"componentChunkName":"component---src-templates-blog-template-js","path":"/data-hadoop/","result":{"data":{"cur":{"id":"e82d4a67-91b1-5218-9fc2-35c7377e5ffc","html":"<p>머리말  </p>\n<p>이번 내용은 이전에 Spark의 이론적인 설명을 이어서 더 대표적인 Hadoop에 대해서 이론적인 내용들을 정리해보는 포스트입니다.<br>\n저는 여러 포스트로 실제 Cluster를 구축하긴 했지만 HDFS가 데이터를 어떻게 저장하는지, ecosystem이 뭐지? 라는<br>\n의문이 많이 남았기에 궁금한 내용들을 정리할 필요를 느꼈습니다.  </p>\n<hr>\n<h2 id=\"-apache-hadoop\" style=\"position:relative;\"><a href=\"#-apache-hadoop\" aria-label=\" apache hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Apache Hadoop?</h2>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110746690-8395f600-8280-11eb-867b-616f6c82b8fb.JPG\" alt=\"1111123123\"></p>\n<p>Hadoop : <em>하둡 소프트웨어 라이브러리는 간단한 프로그래밍 모델을 사용하여<br>\n여러대의 컴퓨터 클러스터에서 대규모 데이터 세트를 분산 처리 할 수있게 해주는 프레임워크 이다.</em></p>\n<p>라고 모든 글에서 설명을 하는데 나는 그냥 데이터를 분산 저장하는 파일시스템이라고 이해했다.<br>\n솔직히 아직 많이 다뤄보지 못해서 정확한 의미는 잘 모르겠고<br>\n가장 주력으로 두고 있는 HDFS와 MapReduce 방식을 이해하면 프레임 워크라는게 어떤 말인지 대충 이해는 가고<br>\n나아가서는 EcoSystem에 대해 이해를 한다면 어떤 느낌인지 감이 올 것같다.  </p>\n<p>하둡의 초기에 HDFS, MapReduce 프레임워크로 시작되었으나<br>\n현재에는 여러 데이터저장, 실행엔진, 프로그래밍 및 데이터처리 같이<br>\n하둡 생태계 (Hadoop Ecosystem)을 포함하는 의미로 확장 발전 되었다고 한다.</p>\n<br/>\n<ul>\n<li>\n<h3 id=\"hadoop-ecosystem\" style=\"position:relative;\"><a href=\"#hadoop-ecosystem\" aria-label=\"hadoop ecosystem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop Ecosystem</h3>\n<p>위에서 Hadoop을 분산 FrameWork이라고 설명했었는데<br>\nHadoop Ecosystem이 그 FrameWork을 이루는 프로젝트의 모임이라고 생각하면 된다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110749647-be9a2880-8284-11eb-81ba-ab6f7a2e6dc1.png\" alt=\"123123123\"></p>\n<br/>\n<p>이 많은 Service 들을 정리하면 다음과 같다. </p>\n<ul>\n<li>Hadoop Core Project : HDFS(분산 데이터 저장), MapReduce(분산 처리)</li>\n<li>Hadoop Sub Project : 나머지 프로젝트 -> 데이터 마이닝, 수집, 분석 등을 수행한다.</li>\n</ul>\n<p>너무 많은 서비스에 저도 이해가 잘 안되서 간단하게 정리를 해봤습니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110750345-ad055080-8285-11eb-88f1-822e3be5c029.JPG\" alt=\"11111123233\"></p>\n<br/>\n<p>다른 분들이 각 프로젝트 들에 대해서 잘 정리해놓은 것도 있네요</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110750466-db832b80-8285-11eb-8361-c32461fc97b8.JPG\" alt=\"33333333\"></p>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"-hadoop-ecosystem-core-구성-요소\" style=\"position:relative;\"><a href=\"#-hadoop-ecosystem-core-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\" aria-label=\" hadoop ecosystem core 구성 요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✌ Hadoop EcoSystem Core 구성 요소</h2>\n<br/>\n<ul>\n<li>\n<h3 id=\"hdfs-hadoop-distributed-file-system\" style=\"position:relative;\"><a href=\"#hdfs-hadoop-distributed-file-system\" aria-label=\"hdfs hadoop distributed file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS (Hadoop Distributed File System)</h3>\n<p>Hadoop Ecosystem의 환경에서 데이터를 저장하는 분산형 파일 시스템<br>\nHDFS는 Hadoop Framework을 위해 JAVA로 작성된 분산 확장 파일 시스템입니다.<br>\nHDFS는 대용량 파일을 여러 서버에 나누고, 중복 저장함으로써 안정성을 높힙니다. </p>\n<br/>\n</li>\n<li>\n<h4 id=\"특징\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95\" aria-label=\"특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h4>\n<ol>\n<li>HDFS는 다수의 노드에 복제 데이터도 함께 저장해 데이터 유실을 방지한다.  </li>\n<li>HDFS에 저장된 파일을 조회하려면 스트리밍 방식으로 데이터에 접근해야한다  </li>\n<li>한번 저장한 데이터는 수정할 수 없고, 읽기만 가능해서 데이터 무결성을 유지한다.<br>\n4.데이터 수정은 불가능하지만 파일 이동, 삭제, 복사할 수 있는 인터페이스를 제공한다.</li>\n</ol>\n<br/>\n</li>\n<li>\n<h4 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110756535-aed31200-828d-11eb-8d1e-e2bd0843713f.JPG\" alt=\"222211312\"></p>\n<p>HDFS는 마스터/슬레이브(master/slave)구조를 가집니다. </p>\n<br/>\n</li>\n<li>\n<h4 id=\"hdfs의-특징\" style=\"position:relative;\"><a href=\"#hdfs%EC%9D%98-%ED%8A%B9%EC%A7%95\" aria-label=\"hdfs의 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS의 특징</h4>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> Block 구조의 FileSystem<span class=\"token punctuation\">,</span> 저장파일은 특정 사이즈의 Block으로 나눠져 분산된 서버에 저장된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> 하나의 Block은 <span class=\"token number\">3</span>개<span class=\"token punctuation\">(</span>수정 가능<span class=\"token punctuation\">)</span>로 복제되며<span class=\"token punctuation\">,</span> 각각 다른 HDFS의 DataNode에 분산저장된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> HDFS에는 NameNode 서버 한 대<span class=\"token punctuation\">,</span> Slave 역할을 하는 DataNode 서버가 여러 대로 구성된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> NameNode는 HDFS의 모든 <span class=\"token function\">Metadata</span><span class=\"token punctuation\">(</span>블록들이 저장되는 디렉토리의 이름<span class=\"token punctuation\">,</span> 파일명등<span class=\"token range operator\">..</span><span class=\"token punctuation\">)</span>를 관리하고  \n   Client가 이를 이용하여 HDFS에 저장된 파일에 접근할 수 있다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> 하둡 어플리케이션은 HDFS에 파일을 저장하거나<span class=\"token punctuation\">,</span> 저장된 파일을 읽기 위해 HDFS Client를 사용하며 API형태로 사용자에게 제공된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> DataNode는 주기적으로  HeartBeat 전송한다 \n   <span class=\"token punctuation\">(</span>NameNode에서 <span class=\"token class-name\">Block</span> Report <span class=\"token punctuation\">:</span> 노드에 저장되어 있는 블록의 정보 <span class=\"token operator\">=</span> Metadata<span class=\"token punctuation\">)</span>\n   이를 통해 NameNode는 DataNode가 정상 동작하는지 확인한다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">7</span><span class=\"token punctuation\">.</span> Clients는 NameNode에 접속해서 원하는 파일이 저장된 블록의 위치를 확인하고<span class=\"token punctuation\">,</span>  \n   해당 Block이 저장된 DataNode에서 직접 데이터를 조회한다<span class=\"token punctuation\">.</span>  </code></pre></div>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"hdfs-file-저장-flow\" style=\"position:relative;\"><a href=\"#hdfs-file-%EC%A0%80%EC%9E%A5-flow\" aria-label=\"hdfs file 저장 flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS File 저장 Flow</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110758607-0bcfc780-8290-11eb-91ad-1b1e234128d2.png\" alt=\"다운로드11\"></p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> APP이 Client에게 파일 저장을 요청  \n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> Client는 NameNode에게 Block이 저장될 경로 생성을 요청한다<span class=\"token punctuation\">.</span> \n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> NameNode는 해당 경로가 존재하지 않으면 생성한 뒤  \n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> NameNode는 그 경로에 수정하지 못하게 LOCKING을 걸어둡니다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> 그 후 Client에게 Block을 저장할 DataNode 목록을 반환하고  \n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> Client는 첫번째 DataNode에 Data Block을 전송 \n\n<span class=\"token number\">7</span><span class=\"token punctuation\">.</span> 첫번째 DataNode는 Local에 저장한 뒤 두번째 DataNode로 전송 \n\n<span class=\"token number\">8</span><span class=\"token punctuation\">.</span> 두번째 DataNode는 동일하게 저장한 뒤 세번째로 전송 \n\n<span class=\"token number\">9</span><span class=\"token punctuation\">.</span> 세번째 DataNode부터 Local에 저장완료 후 넘겨준 DataNode에게 완료 Return을 준다 \n\n<span class=\"token number\">10</span><span class=\"token punctuation\">.</span> 최종적으로는 첫번째 DataNode가 Client에게 저장완료를 Return</code></pre></div>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"hdfs-file-읽기-flow\" style=\"position:relative;\"><a href=\"#hdfs-file-%EC%9D%BD%EA%B8%B0-flow\" aria-label=\"hdfs file 읽기 flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS File 읽기 Flow</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110759735-471ec600-8291-11eb-9e63-5e5164a004d1.png\" alt=\"64982211\"></p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> APP이 Client에게 파일 읽기를 요청\n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> Client는 NameNode에게 파일이 어느 DataNode의 어떤 블록에 저장되어 있는지 정보를 요청\n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> MetaData를 통해 파일이 저장된 블록 리스트를 Client에게 반환\n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> Client는 해당 DataNode에 접근해 Block 조회 요청\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> DataNode는 Client에게 요청된 Block을 전송\n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> Client는 App에 데이터를 전달</code></pre></div>\n<br/>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<h3 id=\"mapreduce-a-namea4a\" style=\"position:relative;\"><a href=\"#mapreduce-a-namea4a\" aria-label=\"mapreduce a namea4a permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce <a name=\"a4\"></a></h3>\n<p>대용량의 데이터 처리를 위한 분산 프로그래밍 Model, 소프트웨어 FrameWork라고 불린다.<br>\n대규모 분산 컴퓨팅 환경에서 MapReduce를 이용해 대량의 데이터를 병렬로 분석이 가능하고<br>\n직접 작성하는 Map과 Reduce 라는 두 개의 메소드로 구성된다.<br>\n요새는 HIVE등 SQL과 유사한 구문으로 MapReduce Code를 만들어 사용한다.</p>\n<p>MapReduce는 Hadoop 클러스터의 데이터를 처리하기 위한 시스템으로,<br>\n총 2개 Map , Reduce의 phase로 구성되어 있다.</p>\n<p>Map과 Reduce사이에는 Shuffle과 Sort라는 스테이지가 존재한다.<br>\n각 Map Task는 전체 데이터 세트에 대한 별개의 부분에 대한 작업을 수행하게 되는데<br>\n기본적으로 하나의 HDFS Block을 대상으로 수행하게 된다.<br>\n모든 Map Task가 종료되면 MapReduce 시스템은 intermediate<br>\n데이터를 Reduce phase를 수행할 노드로 분산하여 전송한다.</p>\n<br/>\n</li>\n<li>\n<h4 id=\"map--reduce\" style=\"position:relative;\"><a href=\"#map--reduce\" aria-label=\"map  reduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MAP &#x26; REDUCE</h4>\n<p>똑똑한 1명이 다량의 일을 처리하는 것<br>\n평범한 100명이 다량의 일을 처리하는 것<br>\n상식적으로 둘 중에 100명 진행하는 것이 훨씬 더 빠를 것이다.<br>\n위의 예가 분산처리의 핵심이지만 100명 각각의 결과를 취합하고 정리하는 시간의 소모도 크다.<br>\n또한 탐색할 데이터가 비정형이라서 갯수가 101개라거나, 길이가 서로 다르다거나 하면<br>\n이를 동일한 업무크기로 나누는 일도 쉽지가 않다.</p>\n<h3 id=\"mapreduce는-이러한-처리를-도와주는-역할을-한다\" style=\"position:relative;\"><a href=\"#mapreduce%EB%8A%94-%EC%9D%B4%EB%9F%AC%ED%95%9C-%EC%B2%98%EB%A6%AC%EB%A5%BC-%EB%8F%84%EC%99%80%EC%A3%BC%EB%8A%94-%EC%97%AD%ED%95%A0%EC%9D%84-%ED%95%9C%EB%8B%A4\" aria-label=\"mapreduce는 이러한 처리를 도와주는 역할을 한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce는 이러한 처리를 도와주는 역할을 한다.</h3>\n<br>\n</li>\n<li>\n<h4 id=\"분산형-파일시스템에서는\" style=\"position:relative;\"><a href=\"#%EB%B6%84%EC%82%B0%ED%98%95-%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C%EB%8A%94\" aria-label=\"분산형 파일시스템에서는 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>분산형 파일시스템에서는?</h4>\n<p>① MapReduce 작업이 끝나면 HDFS에 파일이 써지고(write)<br>\n② MapReduce 작업이 시작될 때는 HDFS로 부터 파일을 가져오는(Read) 작업이 수행된다.</p>\n<p>MapReduce는 명칭 그대로 Map단계 &#x26; Reduce단계로 이루어진다.</p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h3 id=\"map\" style=\"position:relative;\"><a href=\"#map\" aria-label=\"map permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MAP</h3>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110880244-aa583900-8321-11eb-8a05-de07fbfd261d.png\" alt=\"111111\"></p>\n<ul>\n<li>위의 그림처럼 흩어져 있는 분산 클러스터에서 각각의 데이터를 <code class=\"language-text\">(key, value의 형태)</code>로 분류합니다.  </li>\n<li>MapReduce의 Job의 입력 크기를 <code class=\"language-text\">스플릿</code>이라고 합니다<br>\n-> 각 스플릿마다 하나의 Map Task를 생성하게되고<br>\n-> 만들어진 Map Task는 스플릿의 레코드를 Map 함수로 처리<br>\n-> (key, value) 구조를 가지는 중간 산출물이 생성!</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h3 id=\"reduce\" style=\"position:relative;\"><a href=\"#reduce\" aria-label=\"reduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reduce</h3>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110882149-d88b4800-8324-11eb-9370-ba6df69a549d.png\" alt=\"11123323\"></p>\n<p>위의 그림은 문자열 데이터를 포함된 단어의 빈도 별로 나눠 출력해주는 Reduce 과정입니다.<br>\nMapReduce는 다음과 같은 과정으로 데이터를 다룹니다.</p>\n<ul>\n<li>Splitting : 문자열 데이터를 라인별로 나누는 과정</li>\n<li>Mapping : 라인별로 문자열을 입력 -> (key, value) 형태로 출력</li>\n<li>Shuffling : 같은 key를 가지는 데이터끼리 분류</li>\n<li>Reducing : 각 key 별로 빈도수를 합산해서 출력</li>\n<li>Final Result : 리듀스 메소드의 출력 데이터를 합쳐서 하둡 파일시스템에 저장</li>\n</ul>\n<br/>\n</li>\n<li>\n<p>간단하게 Map, Reduce 영역을 분리한 그림 </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110893271-fa8ec580-8338-11eb-883a-a4b715313a3d.png\" alt=\"33333\"></p>\n</li>\n</ul>\n<br>\n<ul>\n<li>\n<h3 id=\"mapreduce-jop\" style=\"position:relative;\"><a href=\"#mapreduce-jop\" aria-label=\"mapreduce jop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce Jop</h3>\n<p>Job은 ‘Full Program’ 즉, 전체 프로그램을 의미합니다.<br>\n데이터 집합을 통해 Mapper와 Reducer를 전체 실행하고<br>\nTask는 데이터 Block을 통해 하나의 Mapper 또는 Reducer를 실행하게 됩니다.</p>\n<ul>\n<li>Client가 수행하려는 작업단위<br>\n입력데이터, 맵리듀스 프로그램, 설정 정보로 구성.</li>\n<li>Hadoop은 Job을 Map Task와 Reduce Task로 작업을 나누어서 실행</li>\n<li>Job이 실행되는 과정을 제어 해주는 노드</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"mapreduce-시스템-구성\" style=\"position:relative;\"><a href=\"#mapreduce-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B5%AC%EC%84%B1\" aria-label=\"mapreduce 시스템 구성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce 시스템 구성</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110894214-cfa57100-833a-11eb-9a91-388e8d72ce48.png\" alt=\"image44444\"></p>\n<p>MapReduce System은 Client, JobTracker, TaskTracker로 구성된다.</p>\n<ul>\n<li>JobTracker 는 NameNode(Master)에 위치</li>\n<li>TaskTracker 는 DataNode(Slave)에 위치</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"client\" style=\"position:relative;\"><a href=\"#client\" aria-label=\"client permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Client</h3>\n<p>분석하고자 하는 데이터를 Job의 형태로 JobTracker에게 전달한다.</p>\n<br/>\n</li>\n<li>\n<h3 id=\"jobtracker\" style=\"position:relative;\"><a href=\"#jobtracker\" aria-label=\"jobtracker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>JobTracker</h3>\n<ul>\n<li>NameNode에 위치  </li>\n<li>Hadoop Cluster의 전체 Job들을 스케줄링하고 모니터링</li>\n</ul>\n<p>맵 리듀스 Job들은 JobTracker라는 소프트웨어 데몬에 의해 제어된다.<br>\nJobTracker들은 다음과 같은 역할을 수행한다.</p>\n<ul>\n<li>\n<ol>\n<li>Client는 MapReduce의 Job을 JobTracker에게 보낸다  </li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li>JobTracker는 Clsuter의 다른 노드들에게 맵과 리듀스 Task를 할당한다.  </li>\n</ol>\n</li>\n<li>\n<ol start=\"3\">\n<li>해당 노드들은 TaskTracker라는 데몬에 의해 각각 실행되고  </li>\n</ol>\n</li>\n<li>\n<ol start=\"4\">\n<li>TaskTracker는 Map,Reduce Task를 인스턴스화 한 뒤 진행 상황을 JobTracker에게 보고한다.</li>\n</ol>\n</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"tasktracker\" style=\"position:relative;\"><a href=\"#tasktracker\" aria-label=\"tasktracker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TaskTracker</h3>\n<ul>\n<li>DataNode에서 실행되는 데몬 (DataNode에 위치)</li>\n<li>사용자가 설정한 맵리듀스 프로그램을 실행해 JobTracker로부터 작업을 요청받은뒤  </li>\n<li>Map과 Reduce 요청 개수만큼 Map,Reduce Task를 생성한 뒤 JobTracker에게 보고한다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>이번 포스트에서는 Hadoop에 대한 간단한 설명들과 EcoSyetem의 Core Preeject 부분을 자세히 살펴봤습니다.<br>\n원래 Sub까지 한 포스트에서 다루려고 했지만 포스트가 너무 길어져서 다음포스트에서 이어서 설명하겠습니다.    </p>\n<br/>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#-apache-hadoop\">✔ Apache Hadoop?</a></li>\n<li><a href=\"#-hadoop-ecosystem-core-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\">✌ Hadoop EcoSystem Core 구성 요소</a></li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","excerpt":"머리말   이번 내용은 이전에 Spark의 이론적인 설명을 이어서 더 대표적인 Hadoop에 대해서 이론적인 내용들을 정리해보는 포스트입니다. 저는 여러 포스트로 실제 Cluster를 구축하긴 했지만 HDFS가 데이터를 어떻게 저장하는지, ecosystem이 뭐지? 라는 의문이 많이 남았기에 궁금한 내용들을 정리할 필요를 느꼈습니다.   ✔ Apache Hadoop? 1111123123 Hadoop : 하둡 소프트웨어 라이브러리는 간단한 프로그래밍 모델을 사용하여 여러대의 컴퓨터 클러스터에서 대규모 데이터 세트를 분산 처리 할 수있게 해주는 프레임워크 이다. 라고 모든 글에서 설명을 하는데 나는 그냥 데이터를 분산 저…","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Apache Hadoop, HDFS, MapReduce","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/data-hadoop/"}},"next":{"id":"2a5bcac3-907a-58f0-81da-8f92654bc3e6","html":"<p>머리말  </p>\n<p>이번에는 데이터의 가장 기초적인 오픈소스인 Apache Spark에 대한 내용 정리입니다.<br>\n아무것도 모르는 생짜 초보이기 때문에 틀린 부분이 많을 수 있습니다.  </p>\n<hr>\n<h2 id=\"-apache-spark-hadoop\" style=\"position:relative;\"><a href=\"#-apache-spark-hadoop\" aria-label=\" apache spark hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Apache Spark? Hadoop?</h2>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109732527-b3018e80-7c00-11eb-8fc9-53e9618bfac5.JPG\" alt=\"캡처1\"></p>\n<p>주워들은 말로는 데이터 시장은 오픈소스인 Hadoop과 Apache가 경쟁하며 성장하고 있다고 알고 있다<br>\n그런데 또 다른 글들을 보니 이미 업계에서는 두 오픈소스를 동시에 사용한다고도 한다.<br>\n경쟁하는 관계인데 또 상생을 하고 있다는게 무슨소리지?<br>\n다시 한번 찾아보니 각각의 툴의 용도에 대해서 알지 못했던 나의 오착이었다.  </p>\n<br/>\n<p>내가 이해한 두 앱의 용도를 간단하게 설명해보면<br>\n우선 두 툴은 빅데이터 처리 플랫폼, 프레임워크라는 공통점을 가지고 있지만 </p>\n<ul>\n<li>\n<h3 id=\"hadoop\" style=\"position:relative;\"><a href=\"#hadoop\" aria-label=\"hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop</h3>\n<p>분산 데이터 Infrastructure를 주로 하며,<br>\n대량의 데이터를 Server Cluster 내 복수 노드들에 분산시키는 역할을 한다.<br>\n이를 통해 데이터 처리를 위한 필요한 하드웨어의 비용부담을 줄여준다.   </p>\n</li>\n</ul>\n<p>반면에 Spark는 분산 데이터 컬렉션 상부에서 동작하는 <code class=\"language-text\">데이터 프로세싱 툴</code>로<br>\n분산형 스토리지의 역할은 수행하지 않는다고 한다.<br>\n대충 이 대목에서 왜 두 오픈소스를 상생하면서 쓰는지 감이오기 시작했다.  </p>\n<p>Hadoop은 HDFS(Hadoop Database filesystem)을 사용하며 맵리듀스를 핵심 구성 요소로 제공한다.  따라서 Spark가 없어도 된다.<br>\n반대로 Spark도 HDFS가 아닌 AWS,GCP,Azure 등과 융합될 수 있기에 Hadoop이 없어도 된다.<br>\n그러나 Hadoop과 Spark를 같이 사용할때가 가장 적합하다고 한다.  </p>\n<br/>\n<p>두 툴의 확실한 차이는 속도에서 확인이 가능하다. </p>\n<p>일반적인 상황에서 Hadoop보다 스파크의 속도가 월등히 빠르다고 한다.<br>\n이유는 데이터 프로세싱 절차의 차이 때문인데<br>\nHadoop은 MapReduce를 사용하기 때문이고, Spark는 DataSet 전체를 한번에 다루기 때문에…<br>\n또한 아래에서 다시 설명하겠지만 Hadoop은 HW에서, Spark는 메모리에서 동작하기 때문이다..  </p>\n<br/>\n<ul>\n<li>\n<p>Hadoop의 Mapreduce WorkFlow  </p>\n<p>Input -> Splitting -> Mapping -> Shuffling -> Reducing -> Final Result</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109735558-4ee1c900-7c06-11eb-85aa-5fd05dc011f1.jpg\" alt=\"99F6AA445B5975A320\"></p>\n<p><em>INPUT : 먼저 클러스터에서 데이터를 읽고</em><br>\n<em>클라이언트->네임노드->클라이언트->데이터 노드-> 마스터(Job Tracker)</em><br>\n<em>태스크 단위로 쪼개어 Tasketracker(worker)에 배정하고</em><br>\n<em>Map 단계를 수행한 후, 중간 결과물을 로컬 디스크에 저장을 한다.</em><br>\n<em>그리고 그 결과물을 다시 combine, partioning을 거쳐 나온 2차 중간 결과물을 디스크에 분할 저장한다.</em><br>\n<em>그리고 최종적으로 shuffling을 통해 reduce 작업에 할당된 후</em><br>\n<em>reduce 작업을 거쳐 최종적으로 나온 결과물이 HDFS에 저장된다”.</em></p>\n</li>\n</ul>\n<br/>\n<p>이에 반해, 스파크는 모든 데이터 운영을 메모리 내에서 실시간에 가깝게 처리할 수 있다(인메모리).<br>\n데이터를 읽고, 처리 분석을 거친 결과물을 클러스터에 입력하는 전 과정이 동시에 진행되는 것이다.<br>\n배치 프로세싱 경우에 스파크가 10배 빠르고, 인 메모리 Analytics의 경우, 100배 빠르다고 알려져있다.   </p>\n<br/>\n<p>나는 여기서 왜 Spark가 더 좋은데 Hadoop을 쓰지? 라는 의문이 들었다.<br>\n그러나 대부분의 Data 운영, 리포팅 요구의 대부분이 정적인 것들이고 시간의 여유가 있다면 Mapreduce의 방식을 채택한다고 한다.<br>\n다만 Spark가 필수적으로 필요할 때가 있는데 이는 비즈니스 공장의 센서 등 실시간으로 수집되는 스트리밍 데이터를 처리하거나, ML 알고리즘과 같이 APP의 복합적인 운영을 할때라고 한다.<br>\n그리고 애초에 Hadoop만 사용하다가 위와 같이 실시간 적인 데이터 처리를 위해서 도입한 것이<br>\nSpark라서 그냥 두 툴을 같이 쓰는게 최적이라고 한다.  </p>\n<br/>\n<hr>\n<h2 id=\"-apache-spark\" style=\"position:relative;\"><a href=\"#-apache-spark\" aria-label=\" apache spark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✌ Apache Spark</h2>\n<p>그럼 간단하게 데이터 플랫폼 2개의 툴에 대해서 설명했으니<br>\n오늘 포스트의 주제인 Spark에 대한 내용으로 돌아와보자 </p>\n<ul>\n<li>\n<h3 id=\"spark의-구성-요소\" style=\"position:relative;\"><a href=\"#spark%EC%9D%98-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\" aria-label=\"spark의 구성 요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark의 구성 요소</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109738566-61aacc80-7c0b-11eb-9c66-5f50dff0e63b.jpg\" alt=\"components_of_spark\"></p>\n<p>Spark는 다음 그림과 같은 구성 요소를 가지고 있습니다.</p>\n</li>\n</ul>\n<h3 id=\"apache-spark-core\" style=\"position:relative;\"><a href=\"#apache-spark-core\" aria-label=\"apache spark core permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Apache Spark Core</h3>\n<ul>\n<li>Spark job과 다른 Spark 컴포넌트에 필요한 기본 기능을 제공합니다.  </li>\n<li>주로 분산 데이터 컬렉션(DataSet)을 추상화한 객체 RDD로 다양한 연산, 변환 메소드를 제공합니다.</li>\n<li>HDFS, GlusterFS, S3등 여러 Filsystem에 접근이 가능합니다.  </li>\n<li>공유 변수, 누적 변수를 사용해 컴퓨팅 노드 간 정보를 공유합니다.  </li>\n<li>Spark core에는 네트워킹, 보안, 스케쥴링 및 데이터 셔플링 등 기본 기능을 제공합니다.  </li>\n</ul>\n<h3 id=\"spark-sql\" style=\"position:relative;\"><a href=\"#spark-sql\" aria-label=\"spark sql permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark SQL</h3>\n<ul>\n<li>Spark와 하이브 SQL이 지원하는 SQL을 사용해 대규모 분산 정형 데이터를 다룰 수 있습니다.  </li>\n<li>JSON File, Parquet 파일, RDB 테이블, 하이브 테이블 등 여러 정형 데이터를 읽고 쓸 수 있습니다.  </li>\n<li>DataFrame 과 DataSet의 연산을 RDD 연산으로 변환해 일반 Spark job으로 실행.  </li>\n</ul>\n<h3 id=\"spark-streaming\" style=\"position:relative;\"><a href=\"#spark-streaming\" aria-label=\"spark streaming permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Streaming</h3>\n<ul>\n<li>실시간 스트리밍 데이터를 처리하는 프레임 워크.  </li>\n<li>HDFS, Kafka, Flume, 트위터 등 커스텀 리소스도 사용 가능합니다.</li>\n<li>다른 Spark 컴포넌트 겸용, 실시간 데이터 처리를 ML, SQL, Graph와 통합 연산이 가능.  </li>\n</ul>\n<h3 id=\"spark-mllib\" style=\"position:relative;\"><a href=\"#spark-mllib\" aria-label=\"spark mllib permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark MLlib</h3>\n<ul>\n<li>머신 러닝 알고리즘 라이브러리.</li>\n<li>RDD, DataFrame의 DataSet을 변환하는 머신 러닝 모델을 구현 가능.  </li>\n</ul>\n<h3 id=\"spark-graphx\" style=\"position:relative;\"><a href=\"#spark-graphx\" aria-label=\"spark graphx permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark GraphX</h3>\n<ul>\n<li>그래프 RDD 형태의 그래프 구조를 만들 수 있는 기능을 제공.</li>\n</ul>\n<br/>\n<h3 id=\"spark-cluster의-구조와-실행과정\" style=\"position:relative;\"><a href=\"#spark-cluster%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%EC%8B%A4%ED%96%89%EA%B3%BC%EC%A0%95\" aria-label=\"spark cluster의 구조와 실행과정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Cluster의 구조와 실행과정</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109743000-5491db80-7c13-11eb-9d18-516463788a2a.png\" alt=\"다운로드\"></p>\n<ul>\n<li>Spark Application은 실제 작업을 수행하는 역할이고  </li>\n<li>Cluster Manager는 Application 사이에 자원을 중계해주는 역할을 담당합니다.  </li>\n</ul>\n<br/>\n<h3 id=\"spark-application\" style=\"position:relative;\"><a href=\"#spark-application\" aria-label=\"spark application permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Application</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109753108-ff5ec580-7c24-11eb-989a-fd120dee21ad.png\" alt=\"다운로드\"></p>\n<p>Spark Application은 Driver 프로세스와 Excutors 두개로 구성됩니다.  </p>\n<ul>\n<li>Spark Driver (Master) : 한개의 노드에서만 실행되고, Spark 전체의 main()함수를 실행합니다.<br>\nApplication 내 정보의 유지관리, Excutors의 실행 및 실행 분석, 배포 등 Master의 역할을 수행합니다.<br>\n즉 간단하게 사용자가 구성한 JOB을 TASK 단위로 변환해 Executor로 전달합니다.  </li>\n</ul>\n<br/>\n<ul>\n<li>Executer (Worker Node) : 다수의 Worker Node에서 실행되는 프로세스<br>\nMaster(Spark Driver)가 할당한 작업(TASK)를 수행한 결과를 반환.<br>\n추가로 블록매니저를 통해서 Cache하는 RDD를 저장합니다.  </li>\n</ul>\n<br/>\n<h3 id=\"cluster-manager\" style=\"position:relative;\"><a href=\"#cluster-manager\" aria-label=\"cluster manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cluster Manager</h3>\n<p>이름 그대로 Spark Application의 Resource를 효율적으로 분배하는 역할을 담당합니다.<br>\n바로 위에서 Driver에서 Executors로 task를 할당하고 관리한다고 설명했는데<br>\n그 작업을 진행하기 위해 Clouster Mananger에 의존하고 있습니다.(없어선안됨…)<br>\n즉 TASK의 할당 및 관리는 Driver -> Executors 구조가 아니라<br>\nDriver &#x3C;-> Cluster Manager &#x3C;-> Executors 구조 입니다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109754173-e820d780-7c26-11eb-99e7-05e46796c3d8.JPG\" alt=\"222\"></p>\n<p>현재 Spark 3.0 기준 대표적인 Cluster Manager의 종류는 위 3가지 +  Spark StandAlone 입니다.<br>\n근데 대부분 YARN,k8s 두 종류만 사용하는 듯…?  </p>\n<p>다른 Manager는 이해가 되는데 StandAlone은 무슨말일까..?  </p>\n<ul>\n<li>StandAlone\nSpark StandAlone은 Cluster로 구성하지 않고 단일 컴퓨터에서 동작시키는 거였다.<br>\n원래라면 나눠져야 할 Driver와 Executor는 각각 Thread로 동작한다고 한다.<br>\nCluster로 구성한다면 Worker Node에 여러개의 Executor를 실행 시킬 수 있지만 StandAlone의 경우 1개씩만 동작한다.  </li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"spark-apis\" style=\"position:relative;\"><a href=\"#spark-apis\" aria-label=\"spark apis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark APIs</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109767953-9c2c5d80-7c3b-11eb-914f-00aee9d23e95.png\" alt=\"3rF6p\"></p>\n<p>Spark Application은 v1 ~ v3를 거쳐 다음과 같이 3가지의 APIs를 사용합니다.  </p>\n<h4 id=\"rdd-resillient-distributed-dataset\" style=\"position:relative;\"><a href=\"#rdd-resillient-distributed-dataset\" aria-label=\"rdd resillient distributed dataset permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>RDD (Resillient Distributed DataSet)</h4>\n<p>RDD는 이름을 그대로 풀어쓰면 이해하기가 쉽습니다.  </p>\n<ul>\n<li>Resillient : Mem 내 데이터 손실 시 다시 생성이 가능하다</li>\n<li>Distributed : Cluster를 통해 메모리에 분산되어서 저장된다 (분산) </li>\n<li>DataSet : 파일을 통해 가져 올 수 있다. 변경되지 않는다.  </li>\n</ul>\n<p>정리하면 여러 분산 노드에 걸쳐서 저장되는 변경이 불가능한 데이터의 집합입니다.   </p>\n<p>RDD의 생성은 2가지 방법으로서 생성됩니다.  </p>\n<ul>\n<li>외부로 부터 Data를 로딩할때 (Disk)</li>\n<li>코드에서 생성된 Data를 저장할 때</li>\n</ul>\n<p>추가적으로 RDD에서 제공하는 Operations(function) 역시 2가지만 존재합니다.  </p>\n<ul>\n<li>\n<h4 id=\"transformation-변환--존재하는-rdd에서-새로운-rdd를-생성하는-함수\" style=\"position:relative;\"><a href=\"#transformation-%EB%B3%80%ED%99%98--%EC%A1%B4%EC%9E%AC%ED%95%98%EB%8A%94-rdd%EC%97%90%EC%84%9C-%EC%83%88%EB%A1%9C%EC%9A%B4-rdd%EB%A5%BC-%EC%83%9D%EC%84%B1%ED%95%98%EB%8A%94-%ED%95%A8%EC%88%98\" aria-label=\"transformation 변환  존재하는 rdd에서 새로운 rdd를 생성하는 함수 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Transformation (변환) : 존재하는 RDD에서 새로운 RDD를 생성하는 함수</h4>\n<ul>\n<li>예를 들어 {1,2,3,3} 의 값을 가진 RDD에 Transformation을 사용하면  </li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109771135-d0a21880-7c3f-11eb-841a-287b875cb201.JPG\" alt=\"캡처222\"></p>\n<ul>\n<li>추가적으로 {1,2,3},{3,4,5} 두 값을 가진 RDD의 경우 </li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109771264-f4655e80-7c3f-11eb-80d5-0ee52f6f90dc.JPG\" alt=\"캡처333\"></p>\n<p>그림을 보면 이해가 쉬울 것이다. 대충 RDD의 데이터를 가지고 사용하는 작업이니… </p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"action-액션--실제로-job을-실행하는-함수-값을-받아오거나-저장한다\" style=\"position:relative;\"><a href=\"#action-%EC%95%A1%EC%85%98--%EC%8B%A4%EC%A0%9C%EB%A1%9C-job%EC%9D%84-%EC%8B%A4%ED%96%89%ED%95%98%EB%8A%94-%ED%95%A8%EC%88%98-%EA%B0%92%EC%9D%84-%EB%B0%9B%EC%95%84%EC%98%A4%EA%B1%B0%EB%82%98-%EC%A0%80%EC%9E%A5%ED%95%9C%EB%8B%A4\" aria-label=\"action 액션  실제로 job을 실행하는 함수 값을 받아오거나 저장한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Action (액션) : 실제로 JOB을 실행하는 함수, 값을 받아오거나 저장한다.</h4>\n<ul>\n<li>예를 들어 {1,2,3,3} RDD에서 Action 함수를 사용하면  </li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109771572-502fe780-7c40-11eb-8c9c-8cd33e05c808.JPG\" alt=\"캡처4444\"></p>\n<p>reduce 함수를 예로 들면 rdd.reduce(x,y: x+y) 이다.<br>\n그럼 RDD {1,2,3,3}의 값들이 각각 x,y가 되어 합한 1+2+3+3 = 9가 연산 후 반환된다.  </p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<p>간단하게 위의 Flow를 요악한 그림</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109773128-2d063780-7c42-11eb-9872-47784860e468.png\" alt=\"다운로드33333\"></p>\n</li>\n</ul>\n<p>추가적인 함수의 경우 다른 포스트에서 정리 할 예정입니다.!!</p>\n<br/>\n<h4 id=\"dataframe\" style=\"position:relative;\"><a href=\"#dataframe\" aria-label=\"dataframe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataFrame</h4>\n<p>Spark v1.3 이후 부터 RDD에서 발전한 개념?<br>\n기존의 RDD의 단점들 속도, 최적화 등을 보완하였다고 합니다.<br>\n여기저기서 찾아본 것으로는 scala에서 다음과 같이 사용이 가능하다고 한다.  </p>\n<p>val df = spark.sql(“실행 Query”)  </p>\n<p>대충 이해하자면 스키마의 최적화부분? 비정형 dataset으로 이해했던 RDD와 다르게 정형 데이터 (테이블)식으로 처리하는 듯 하다.(SQL 사용가능)<br>\n근데 DataSet이 있어서 DataFrame은 완벽히 이해하고 넘어가지 않아도 될 듯??  </p>\n<br/>\n<h4 id=\"dataset\" style=\"position:relative;\"><a href=\"#dataset\" aria-label=\"dataset permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DataSet</h4>\n<p>Spark v1.6에서 추가되었다고 합니다.<br>\n데이터 타입체크, 직렬화를 위한 인코더, 카탈리스트 옵티마이저를 지원하고<br>\n데이터 처리 속도를 더욱 증가시켰다고 하는데;;; 잘모르겠다..<br>\nSpark v2.0에서 DataFrame + Dataset = Dataset으로 통합되었다고 하고 따로 DataFrame을 선언하는 느낌인듯 합니다.  </p>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>Spark의 기본 개념의 50%정도는 이해한 것 같습니다.<br>\n다음 포스트에서는 마저 정리 못한 APIs와 JOB, STAGE, TASK에 대해서 정리 예정입니다. </p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#-apache-spark-hadoop\">✔ Apache Spark? Hadoop?</a></li>\n<li>\n<p><a href=\"#-apache-spark\">✌ Apache Spark</a></p>\n<ul>\n<li><a href=\"#apache-spark-core\">Apache Spark Core</a></li>\n<li><a href=\"#spark-sql\">Spark SQL</a></li>\n<li><a href=\"#spark-streaming\">Spark Streaming</a></li>\n<li><a href=\"#spark-mllib\">Spark MLlib</a></li>\n<li><a href=\"#spark-graphx\">Spark GraphX</a></li>\n<li><a href=\"#spark-cluster%EC%9D%98-%EA%B5%AC%EC%A1%B0%EC%99%80-%EC%8B%A4%ED%96%89%EA%B3%BC%EC%A0%95\">Spark Cluster의 구조와 실행과정</a></li>\n<li><a href=\"#spark-application\">Spark Application</a></li>\n<li><a href=\"#cluster-manager\">Cluster Manager</a></li>\n<li>\n<p><a href=\"#spark-apis\">Spark APIs</a></p>\n<ul>\n<li><a href=\"#rdd-resillient-distributed-dataset\">RDD (Resillient Distributed DataSet)</a></li>\n<li><a href=\"#dataframe\">DataFrame</a></li>\n<li><a href=\"#dataset\">DataSet</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Apache Spark란??","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/date-spark/"}},"prev":{"id":"3b573dbf-a917-56a5-9a76-6736d98f7ec3","html":"<p>머리말  </p>\n<p>이전 포스트에서 Hadoop EcoSystem 중 Core Project에 대해서 다뤘었습니다.<br>\n이번 포스트에서는 데이터를 수집하거나 DB화 하는 오픈소스들의 모음인 SUB Project들에 대해서 다룹니다.<br>\n모든 프로젝트를 다루지는 않고 앞으로 사용하게 될 것 같은 프로젝트 위주로 정리했습니다.    </p>\n<hr>\n<h2 id=\"-hadoop-ecosystem-sub-project\" style=\"position:relative;\"><a href=\"#-hadoop-ecosystem-sub-project\" aria-label=\" hadoop ecosystem sub project permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Hadoop EcoSystem Sub Project</h2>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110749647-be9a2880-8284-11eb-81ba-ab6f7a2e6dc1.png\" alt=\"123123123\"></p>\n<p><a href=\"https://nasa1515.tech/data-hadoop/\">이전포스트</a>에서는 Hadoop EcoSystem의 Core Project 부분에 대해서 다뤘습니다.<br>\nCore Project는 다 설명했고 이제 Hadoop Sub Project의 차례 입니다. </p>\n<ul>\n<li>Hadoop Core Project : HDFS(분산 데이터 저장), MapReduce(분산 처리)</li>\n<li><code class=\"language-text\">Hadoop Sub Project : 나머지 프로젝트 -> 데이터 마이닝, 수집, 분석 등을 수행한다.</code></li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"zookeeper주키퍼---분산-코디네이터\" style=\"position:relative;\"><a href=\"#zookeeper%EC%A3%BC%ED%82%A4%ED%8D%BC---%EB%B6%84%EC%82%B0-%EC%BD%94%EB%94%94%EB%84%A4%EC%9D%B4%ED%84%B0\" aria-label=\"zookeeper주키퍼   분산 코디네이터 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Zookeeper(주키퍼) - 분산 코디네이터</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111092196-b984f400-8578-11eb-9c77-727e7c82d5ae.jpg\" alt=\"111231\"></p>\n<p>위의 Hadoop EcoSystem을 보면 Hadoop(코끼리)부터 꿀벌 등 배부분 동물들의 이름을 딴 것들이 많습니다.<br>\n각 동물은 하나의 FramWork으로 이루어져있는데 Zookeeper는 이름으로도 그 역할이 짐작이 가능합니다.<br>\nZookeeper는 분산 시스템 간의 <code class=\"language-text\">정보 공유</code> 및 <code class=\"language-text\">상태 체크</code>, <code class=\"language-text\">동기화</code>를 처리하는 프레임워크입니다.<br>\n이러한 시스템을 코디네이션 서비스 시스템이라고 부르는데.<br>\nZookeeper를 많이 사용하는 이유는 기능에 비해 시스템이 단순하기 때문입니다.<br>\n분산 큐, 락, 피어 그룹 대표 산출 등의 기능을 가지는데 몇 개의 기본 기능만으로도 사용이 가능합니다.<br>\n즉 간단하게 요약하면 분산 환경에서 서버들간 상호 조정이 필요한 서비스를 제공합니다.  </p>\n<ul>\n<li>하나의 서버에만 서비스가 집중되지 않도록 서비스를 분산하여 조정  </li>\n<li>하나의 서버에서 처리한 결과를 다른 서버와 동기화</li>\n<li>운영(Active)서버에서 문제가 발생하면 다른 서버로 바꿔 서비스 중지 없이 제공  </li>\n<li>분산 환경을 구성하는 서버들의 환경설정을 통합적으로 관리한다.  </li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"oozie우지\" style=\"position:relative;\"><a href=\"#oozie%EC%9A%B0%EC%A7%80\" aria-label=\"oozie우지 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Oozie(우지)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111094519-cf95b300-857e-11eb-8c6e-7c31ab91b513.png\" alt=\"1_uoVl2GcziNS1uEHIt9wlOg\"></p>\n<p>Hadoop ecosystem에서 사용하는 Workflow Scheduler(혹은 orchestration) 프레임워크입니단.</p>\n<p>즉 하둡의 워크플로우를 관리하며,<br>\n일정한 시간이 경과하거나 또는 주기적으로 반복해서 실행될 수 있는 잡들에 대하여 관리하고,<br>\nMapReduce job, pig 잡 등의 시작과 완료 그리고 실행 중 에러등의 이벤트를 Call Back 할 수 있습니다.</p>\n<p>Oozie에서 제공하는 기능은 크게 아래의 3가지 입니다.</p>\n<p>Scheduling</p>\n<ul>\n<li>특정 시간에 액션 수행</li>\n<li>주기적인 간격 이후에 액션 수행</li>\n<li>이벤트가 발생하면 액션 수행</li>\n</ul>\n<p>Coordinating</p>\n<ul>\n<li>이전 액션이 성공적으로 끝나면 다음 액션 시작</li>\n</ul>\n<p>Managing</p>\n<ul>\n<li>액션이 성공하거나 실패했을 때 이메일 발송</li>\n<li>액션 수행시간이나 액션의 단계를 저장</li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"pig-피그\" style=\"position:relative;\"><a href=\"#pig-%ED%94%BC%EA%B7%B8\" aria-label=\"pig 피그 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pig (피그)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111102796-4c7d5880-8590-11eb-8283-6c0f34676d58.png\" alt=\"Apache-Pig-Architecture-24\"></p>\n<p>하둡에 저장된 데이터를 MapReduce 코딩을 하지 않고 SQL과 유사한 스크립트를 이용해서<br>\n데이터를 처리하고, API를 단순화한 형태로 사용할 수 있습니다.<br>\n간단히 Hadoop의 MapReduce API를 단순화 시킨 FrameWork으로 Join 기능등을 쉽게 처리 가능하다.  </p>\n<br/>\n<hr>\n<h3 id=\"hive-하이브\" style=\"position:relative;\"><a href=\"#hive-%ED%95%98%EC%9D%B4%EB%B8%8C\" aria-label=\"hive 하이브 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HIVE (하이브)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111102972-abdb6880-8590-11eb-8cb7-34bf542bf564.jpg\" alt=\"11123\"></p>\n<p>가장 Hive를 쉽게 설명할 수 있는 용어는 Hadoop의 SQL 이라 표현하는게 좋을 것 같다<br>\n즉 HIVE는 Hadoop에서 SQL로 편하게 질의하며 데이터를 가져올 수 있는 툴 정도? 이다<br>\nHIVEQL이라는 자체 쿼리는 제공해서 실행되면 Mapreduce의 Job으로 변환 된다.<br>\n그래서 SQL은 익숙하지만 JAVA에 익숙하지 않은 사람들이 많이 사용한다.</p>\n<br/>\n<hr>\n<h3 id=\"hbase\" style=\"position:relative;\"><a href=\"#hbase\" aria-label=\"hbase permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HBase</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111104978-34f49e80-8595-11eb-8446-93ecceb45fd6.jpg\" alt=\"Architecture-of-Apache-HBase\">\n출처: <a href=\"https://thirdeyedata.io/apache-hbase/\">thirdeyedata 사이트</a>)</p>\n<p>HDFS, MapReduce로 분산하여 처리한 데이터를 저장하는 컬럼기반 DB 역할을 담당한다.<br>\nHDFS위에서 Bigtable과 같은 기능을 제공하며 실시간 랜덤 조회, 업데이트가 가능하다.<br>\nNoSQL로 분류되어, 스키마 변경없이 자유롭게 저장이 가능합니다.  </p>\n<br/>\n<hr>\n<h3 id=\"yarn-yet-another-resource-negotiator\" style=\"position:relative;\"><a href=\"#yarn-yet-another-resource-negotiator\" aria-label=\"yarn yet another resource negotiator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Yarn (Yet Another Resource Negotiator)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111107613-87848980-859a-11eb-945f-f635052488ce.png\" alt=\"111111123123\"></p>\n<p>모든 사이트에서 공통적으로 Yarn을 표현하는 단어는 <code class=\"language-text\">Resource Managemnet</code>이빈다.<br>\n제 개인적으로도 이게 Yarn의 <code class=\"language-text\">핵심기능</code>인 것 같습니다.  </p>\n<p>Yarn은 기존 Hadoop 1.X Version 에서의 문제점을 해결하기 위해서 등장했습니다.<br>\n이전에는 MapReduce의 JopTracker에 의해서 Resource가 관리가 되고 있었어서<br>\n속도 측면이나 여러 클러스터끼리 연동하기 어려운 문제가 있었습니다.<br>\n그러나 이후 Hadoop 2.X Version 에서부터는 MapReduce의 클러스터 구성 기능이 Yarn으로 정의되며<br>\nMapReduce는 컴퓨팅을 위한 프로그램만 제공하는 것으로 하고<br>\n클러스터의 Resourece 관리, 장애 관리등은 Yarn을 통해 진행됩니다.  </p>\n<p>Yarn의 핵심 구성 요소는 <code class=\"language-text\">ResourceManager</code>와 <code class=\"language-text\">NodeManager</code> 입니다. </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111108321-fadacb00-859b-11eb-9a3a-1e1ea1cabbe6.png\" alt=\"112112\"></p>\n<ul>\n<li>\n<h4 id=\"resource-manager\" style=\"position:relative;\"><a href=\"#resource-manager\" aria-label=\"resource manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resource Manager</h4>\n<ul>\n<li>Yarn 클러스터의 Master 1개나 이중화 용 두개의 서버에만 실행.   </li>\n<li>클러스터 전체의 리소스를 관리  </li>\n<li>Yarn 클러스터의 Resource를 사용하고자 하는 다른 요청을 받아 리소스 할당  </li>\n<li>MapReduce의 JopTraker의 기능을 물려받았다</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"node-manager\" style=\"position:relative;\"><a href=\"#node-manager\" aria-label=\"node manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Node Manager</h4>\n<ul>\n<li>Yarn 클러스터의 Worker 서버, ResourceManager를 제외한 모든 서버 실행  </li>\n<li>사용자가 요청한 프로그램을 실행하는 Container를 Fork 시키고 모니터링<br>\nContainer 장애상황이나 리소스 사용량을 모니터링 한다.  </li>\n<li>MapReduce의 TaskTraker의 기능을 물려받았다.  </li>\n</ul>\n</li>\n</ul>\n<br>\n<h3 id=\"yarn의-running-processapplicationmaster\" style=\"position:relative;\"><a href=\"#yarn%EC%9D%98-running-processapplicationmaster\" aria-label=\"yarn의 running processapplicationmaster permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Yarn의 Running Process/ApplicationMaster</h3>\n<p><a href=\"https://ggoals.tistory.com/76\">내용출처</a></p>\n<p>YARN 클러스터에 job 을 요청한 경우 어떠한 방식으로 실행이 되는지 정리해보자  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111110273-915cbb80-859f-11eb-9acf-297a865f8c39.png\" alt=\"다운로드 (3)\"></p>\n<ul>\n<li>RM(Resource Manager) : 글로벌 스케줄러  </li>\n<li>NM(Node Manager) : Task Tracker </li>\n<li>AM(Application Master) : 한 개의 app을 관리하는 Master </li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"1-client가-app을-실행하고-cluster의-rm에게-알려준다\" style=\"position:relative;\"><a href=\"#1-client%EA%B0%80-app%EC%9D%84-%EC%8B%A4%ED%96%89%ED%95%98%EA%B3%A0-cluster%EC%9D%98-rm%EC%97%90%EA%B2%8C-%EC%95%8C%EB%A0%A4%EC%A4%80%EB%8B%A4\" aria-label=\"1 client가 app을 실행하고 cluster의 rm에게 알려준다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Client가 App을 실행하고 Cluster의 RM에게 알려준다.</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111109067-5ce80000-859d-11eb-9ce6-3be34d99f6bd.png\" alt=\"다운로드\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"2-rm은-worker-중-하나에-container를-생성한다\" style=\"position:relative;\"><a href=\"#2-rm%EC%9D%80-worker-%EC%A4%91-%ED%95%98%EB%82%98%EC%97%90-container%EB%A5%BC-%EC%83%9D%EC%84%B1%ED%95%9C%EB%8B%A4\" aria-label=\"2 rm은 worker 중 하나에 container를 생성한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. RM은 Worker 중 하나에 Container를 생성한다</h4>\n<p>그 후 Container 안에서는 Application Master가 실행된다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111109363-f31c2600-859d-11eb-8333-6e0738df5952.png\" alt=\"다운로드 (1)\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"3-am은-task를-싱핸할-컨테이너를-rm에-요청한다\" style=\"position:relative;\"><a href=\"#3-am%EC%9D%80-task%EB%A5%BC-%EC%8B%B1%ED%95%B8%ED%95%A0-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88%EB%A5%BC-rm%EC%97%90-%EC%9A%94%EC%B2%AD%ED%95%9C%EB%8B%A4\" aria-label=\"3 am은 task를 싱핸할 컨테이너를 rm에 요청한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. AM은 Task를 싱핸할 컨테이너를 RM에 요청한다.</h4>\n<p>그럼 RM은 남은 자원을 소유한 Work 호스트의 Node Manager를 통해서<br>\nTask를 실행 할 Container를 생성하고 AM에게 알려준다. </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111109497-34143a80-859e-11eb-8391-62af97606600.png\" alt=\"다운로드 (2)\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"4-모든-task가-종료된다\" style=\"position:relative;\"><a href=\"#4-%EB%AA%A8%EB%93%A0-task%EA%B0%80-%EC%A2%85%EB%A3%8C%EB%90%9C%EB%8B%A4\" aria-label=\"4 모든 task가 종료된다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 모든 task가 종료된다.</h4>\n<p>AM도 종료되고 클러스터에 할당된 컨테이너의 자원도 모두 de-allocated 된다.<br>\n그리고 Application client 도 종료된다</p>\n</li>\n</ul>\n<br/>\n<p>Yarn의 결론 </p>\n<p>결국 Yarn은 app의 job을 분산처리된 환경에서 처리할 수 있도록 도와주는 서비스 이다.<br>\n위에서 설명한 RM(Resource Manager),AM(Application Manager),NM(Node..)가<br>\n주요 컴포넌트이고 하나의 JOB을 처리하기 위해 여러 TASK를 나누고<br>\n이를 분산환경에서 처리하기 위해 Container라는 개념이 존재한다.<br>\n즉 기존 Hadoop 1.X Version에서의 분산처리 MapReduce의 문제를<br>\nYarn으로 프로세싱을 나누어 적합하게 처리하는 목적이다. </p>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>이번 포스트에서도 자세하게 EcoSystem에 대해서 설명하고 싶었지만<br>\n이론적인 내용들만 다루다보니 또 주제에서 약간 벗어난 것 같습니다<br>\n추후 Sub Project tools을 각각 사용해보면서 자세하게 다시 리뷰 해야 할 것 같습니다.  </p>\n<br/>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#-hadoop-ecosystem-sub-project\">✔ Hadoop EcoSystem Sub Project</a></p>\n<ul>\n<li><a href=\"#zookeeper%EC%A3%BC%ED%82%A4%ED%8D%BC---%EB%B6%84%EC%82%B0-%EC%BD%94%EB%94%94%EB%84%A4%EC%9D%B4%ED%84%B0\">Zookeeper(주키퍼) - 분산 코디네이터</a></li>\n<li><a href=\"#oozie%EC%9A%B0%EC%A7%80\">Oozie(우지)</a></li>\n<li><a href=\"#pig-%ED%94%BC%EA%B7%B8\">Pig (피그)</a></li>\n<li><a href=\"#hive-%ED%95%98%EC%9D%B4%EB%B8%8C\">HIVE (하이브)</a></li>\n<li><a href=\"#hbase\">HBase</a></li>\n<li><a href=\"#yarn-yet-another-resource-negotiator\">Yarn (Yet Another Resource Negotiator)</a></li>\n<li><a href=\"#yarn%EC%9D%98-running-processapplicationmaster\">Yarn의 Running Process/ApplicationMaster</a></li>\n</ul>\n</li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Hadoop EcoSystem Sub Project","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/data-hadoopeco/"}},"site":{"siteMetadata":{"siteUrl":"https://nasa1515.com","comments":{"utterances":{"repo":"nasa1515/nasablog"}}}}},"pageContext":{"slug":"/data-hadoop/","nextSlug":"/date-spark/","prevSlug":"/data-hadoopeco/"}},"staticQueryHashes":["1073350324","2938748437"]}