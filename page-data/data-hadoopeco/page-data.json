{"componentChunkName":"component---src-templates-blog-template-js","path":"/data-hadoopeco/","result":{"data":{"cur":{"id":"3b573dbf-a917-56a5-9a76-6736d98f7ec3","html":"<p>머리말  </p>\n<p>이전 포스트에서 Hadoop EcoSystem 중 Core Project에 대해서 다뤘었습니다.<br>\n이번 포스트에서는 데이터를 수집하거나 DB화 하는 오픈소스들의 모음인 SUB Project들에 대해서 다룹니다.<br>\n모든 프로젝트를 다루지는 않고 앞으로 사용하게 될 것 같은 프로젝트 위주로 정리했습니다.    </p>\n<hr>\n<h2 id=\"-hadoop-ecosystem-sub-project\" style=\"position:relative;\"><a href=\"#-hadoop-ecosystem-sub-project\" aria-label=\" hadoop ecosystem sub project permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Hadoop EcoSystem Sub Project</h2>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110749647-be9a2880-8284-11eb-81ba-ab6f7a2e6dc1.png\" alt=\"123123123\"></p>\n<p><a href=\"https://nasa1515.tech/data-hadoop/\">이전포스트</a>에서는 Hadoop EcoSystem의 Core Project 부분에 대해서 다뤘습니다.<br>\nCore Project는 다 설명했고 이제 Hadoop Sub Project의 차례 입니다. </p>\n<ul>\n<li>Hadoop Core Project : HDFS(분산 데이터 저장), MapReduce(분산 처리)</li>\n<li><code class=\"language-text\">Hadoop Sub Project : 나머지 프로젝트 -> 데이터 마이닝, 수집, 분석 등을 수행한다.</code></li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"zookeeper주키퍼---분산-코디네이터\" style=\"position:relative;\"><a href=\"#zookeeper%EC%A3%BC%ED%82%A4%ED%8D%BC---%EB%B6%84%EC%82%B0-%EC%BD%94%EB%94%94%EB%84%A4%EC%9D%B4%ED%84%B0\" aria-label=\"zookeeper주키퍼   분산 코디네이터 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Zookeeper(주키퍼) - 분산 코디네이터</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111092196-b984f400-8578-11eb-9c77-727e7c82d5ae.jpg\" alt=\"111231\"></p>\n<p>위의 Hadoop EcoSystem을 보면 Hadoop(코끼리)부터 꿀벌 등 배부분 동물들의 이름을 딴 것들이 많습니다.<br>\n각 동물은 하나의 FramWork으로 이루어져있는데 Zookeeper는 이름으로도 그 역할이 짐작이 가능합니다.<br>\nZookeeper는 분산 시스템 간의 <code class=\"language-text\">정보 공유</code> 및 <code class=\"language-text\">상태 체크</code>, <code class=\"language-text\">동기화</code>를 처리하는 프레임워크입니다.<br>\n이러한 시스템을 코디네이션 서비스 시스템이라고 부르는데.<br>\nZookeeper를 많이 사용하는 이유는 기능에 비해 시스템이 단순하기 때문입니다.<br>\n분산 큐, 락, 피어 그룹 대표 산출 등의 기능을 가지는데 몇 개의 기본 기능만으로도 사용이 가능합니다.<br>\n즉 간단하게 요약하면 분산 환경에서 서버들간 상호 조정이 필요한 서비스를 제공합니다.  </p>\n<ul>\n<li>하나의 서버에만 서비스가 집중되지 않도록 서비스를 분산하여 조정  </li>\n<li>하나의 서버에서 처리한 결과를 다른 서버와 동기화</li>\n<li>운영(Active)서버에서 문제가 발생하면 다른 서버로 바꿔 서비스 중지 없이 제공  </li>\n<li>분산 환경을 구성하는 서버들의 환경설정을 통합적으로 관리한다.  </li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"oozie우지\" style=\"position:relative;\"><a href=\"#oozie%EC%9A%B0%EC%A7%80\" aria-label=\"oozie우지 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Oozie(우지)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111094519-cf95b300-857e-11eb-8c6e-7c31ab91b513.png\" alt=\"1_uoVl2GcziNS1uEHIt9wlOg\"></p>\n<p>Hadoop ecosystem에서 사용하는 Workflow Scheduler(혹은 orchestration) 프레임워크입니단.</p>\n<p>즉 하둡의 워크플로우를 관리하며,<br>\n일정한 시간이 경과하거나 또는 주기적으로 반복해서 실행될 수 있는 잡들에 대하여 관리하고,<br>\nMapReduce job, pig 잡 등의 시작과 완료 그리고 실행 중 에러등의 이벤트를 Call Back 할 수 있습니다.</p>\n<p>Oozie에서 제공하는 기능은 크게 아래의 3가지 입니다.</p>\n<p>Scheduling</p>\n<ul>\n<li>특정 시간에 액션 수행</li>\n<li>주기적인 간격 이후에 액션 수행</li>\n<li>이벤트가 발생하면 액션 수행</li>\n</ul>\n<p>Coordinating</p>\n<ul>\n<li>이전 액션이 성공적으로 끝나면 다음 액션 시작</li>\n</ul>\n<p>Managing</p>\n<ul>\n<li>액션이 성공하거나 실패했을 때 이메일 발송</li>\n<li>액션 수행시간이나 액션의 단계를 저장</li>\n</ul>\n<br/>\n<hr>\n<h3 id=\"pig-피그\" style=\"position:relative;\"><a href=\"#pig-%ED%94%BC%EA%B7%B8\" aria-label=\"pig 피그 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pig (피그)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111102796-4c7d5880-8590-11eb-8283-6c0f34676d58.png\" alt=\"Apache-Pig-Architecture-24\"></p>\n<p>하둡에 저장된 데이터를 MapReduce 코딩을 하지 않고 SQL과 유사한 스크립트를 이용해서<br>\n데이터를 처리하고, API를 단순화한 형태로 사용할 수 있습니다.<br>\n간단히 Hadoop의 MapReduce API를 단순화 시킨 FrameWork으로 Join 기능등을 쉽게 처리 가능하다.  </p>\n<br/>\n<hr>\n<h3 id=\"hive-하이브\" style=\"position:relative;\"><a href=\"#hive-%ED%95%98%EC%9D%B4%EB%B8%8C\" aria-label=\"hive 하이브 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HIVE (하이브)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111102972-abdb6880-8590-11eb-8cb7-34bf542bf564.jpg\" alt=\"11123\"></p>\n<p>가장 Hive를 쉽게 설명할 수 있는 용어는 Hadoop의 SQL 이라 표현하는게 좋을 것 같다<br>\n즉 HIVE는 Hadoop에서 SQL로 편하게 질의하며 데이터를 가져올 수 있는 툴 정도? 이다<br>\nHIVEQL이라는 자체 쿼리는 제공해서 실행되면 Mapreduce의 Job으로 변환 된다.<br>\n그래서 SQL은 익숙하지만 JAVA에 익숙하지 않은 사람들이 많이 사용한다.</p>\n<br/>\n<hr>\n<h3 id=\"hbase\" style=\"position:relative;\"><a href=\"#hbase\" aria-label=\"hbase permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HBase</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111104978-34f49e80-8595-11eb-8446-93ecceb45fd6.jpg\" alt=\"Architecture-of-Apache-HBase\">\n출처: <a href=\"https://thirdeyedata.io/apache-hbase/\">thirdeyedata 사이트</a>)</p>\n<p>HDFS, MapReduce로 분산하여 처리한 데이터를 저장하는 컬럼기반 DB 역할을 담당한다.<br>\nHDFS위에서 Bigtable과 같은 기능을 제공하며 실시간 랜덤 조회, 업데이트가 가능하다.<br>\nNoSQL로 분류되어, 스키마 변경없이 자유롭게 저장이 가능합니다.  </p>\n<br/>\n<hr>\n<h3 id=\"yarn-yet-another-resource-negotiator\" style=\"position:relative;\"><a href=\"#yarn-yet-another-resource-negotiator\" aria-label=\"yarn yet another resource negotiator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Yarn (Yet Another Resource Negotiator)</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111107613-87848980-859a-11eb-945f-f635052488ce.png\" alt=\"111111123123\"></p>\n<p>모든 사이트에서 공통적으로 Yarn을 표현하는 단어는 <code class=\"language-text\">Resource Managemnet</code>이빈다.<br>\n제 개인적으로도 이게 Yarn의 <code class=\"language-text\">핵심기능</code>인 것 같습니다.  </p>\n<p>Yarn은 기존 Hadoop 1.X Version 에서의 문제점을 해결하기 위해서 등장했습니다.<br>\n이전에는 MapReduce의 JopTracker에 의해서 Resource가 관리가 되고 있었어서<br>\n속도 측면이나 여러 클러스터끼리 연동하기 어려운 문제가 있었습니다.<br>\n그러나 이후 Hadoop 2.X Version 에서부터는 MapReduce의 클러스터 구성 기능이 Yarn으로 정의되며<br>\nMapReduce는 컴퓨팅을 위한 프로그램만 제공하는 것으로 하고<br>\n클러스터의 Resourece 관리, 장애 관리등은 Yarn을 통해 진행됩니다.  </p>\n<p>Yarn의 핵심 구성 요소는 <code class=\"language-text\">ResourceManager</code>와 <code class=\"language-text\">NodeManager</code> 입니다. </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111108321-fadacb00-859b-11eb-9a3a-1e1ea1cabbe6.png\" alt=\"112112\"></p>\n<ul>\n<li>\n<h4 id=\"resource-manager\" style=\"position:relative;\"><a href=\"#resource-manager\" aria-label=\"resource manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resource Manager</h4>\n<ul>\n<li>Yarn 클러스터의 Master 1개나 이중화 용 두개의 서버에만 실행.   </li>\n<li>클러스터 전체의 리소스를 관리  </li>\n<li>Yarn 클러스터의 Resource를 사용하고자 하는 다른 요청을 받아 리소스 할당  </li>\n<li>MapReduce의 JopTraker의 기능을 물려받았다</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"node-manager\" style=\"position:relative;\"><a href=\"#node-manager\" aria-label=\"node manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Node Manager</h4>\n<ul>\n<li>Yarn 클러스터의 Worker 서버, ResourceManager를 제외한 모든 서버 실행  </li>\n<li>사용자가 요청한 프로그램을 실행하는 Container를 Fork 시키고 모니터링<br>\nContainer 장애상황이나 리소스 사용량을 모니터링 한다.  </li>\n<li>MapReduce의 TaskTraker의 기능을 물려받았다.  </li>\n</ul>\n</li>\n</ul>\n<br>\n<h3 id=\"yarn의-running-processapplicationmaster\" style=\"position:relative;\"><a href=\"#yarn%EC%9D%98-running-processapplicationmaster\" aria-label=\"yarn의 running processapplicationmaster permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Yarn의 Running Process/ApplicationMaster</h3>\n<p><a href=\"https://ggoals.tistory.com/76\">내용출처</a></p>\n<p>YARN 클러스터에 job 을 요청한 경우 어떠한 방식으로 실행이 되는지 정리해보자  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111110273-915cbb80-859f-11eb-9acf-297a865f8c39.png\" alt=\"다운로드 (3)\"></p>\n<ul>\n<li>RM(Resource Manager) : 글로벌 스케줄러  </li>\n<li>NM(Node Manager) : Task Tracker </li>\n<li>AM(Application Master) : 한 개의 app을 관리하는 Master </li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"1-client가-app을-실행하고-cluster의-rm에게-알려준다\" style=\"position:relative;\"><a href=\"#1-client%EA%B0%80-app%EC%9D%84-%EC%8B%A4%ED%96%89%ED%95%98%EA%B3%A0-cluster%EC%9D%98-rm%EC%97%90%EA%B2%8C-%EC%95%8C%EB%A0%A4%EC%A4%80%EB%8B%A4\" aria-label=\"1 client가 app을 실행하고 cluster의 rm에게 알려준다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Client가 App을 실행하고 Cluster의 RM에게 알려준다.</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111109067-5ce80000-859d-11eb-9ce6-3be34d99f6bd.png\" alt=\"다운로드\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"2-rm은-worker-중-하나에-container를-생성한다\" style=\"position:relative;\"><a href=\"#2-rm%EC%9D%80-worker-%EC%A4%91-%ED%95%98%EB%82%98%EC%97%90-container%EB%A5%BC-%EC%83%9D%EC%84%B1%ED%95%9C%EB%8B%A4\" aria-label=\"2 rm은 worker 중 하나에 container를 생성한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. RM은 Worker 중 하나에 Container를 생성한다</h4>\n<p>그 후 Container 안에서는 Application Master가 실행된다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111109363-f31c2600-859d-11eb-8333-6e0738df5952.png\" alt=\"다운로드 (1)\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"3-am은-task를-싱핸할-컨테이너를-rm에-요청한다\" style=\"position:relative;\"><a href=\"#3-am%EC%9D%80-task%EB%A5%BC-%EC%8B%B1%ED%95%B8%ED%95%A0-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88%EB%A5%BC-rm%EC%97%90-%EC%9A%94%EC%B2%AD%ED%95%9C%EB%8B%A4\" aria-label=\"3 am은 task를 싱핸할 컨테이너를 rm에 요청한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. AM은 Task를 싱핸할 컨테이너를 RM에 요청한다.</h4>\n<p>그럼 RM은 남은 자원을 소유한 Work 호스트의 Node Manager를 통해서<br>\nTask를 실행 할 Container를 생성하고 AM에게 알려준다. </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/111109497-34143a80-859e-11eb-8391-62af97606600.png\" alt=\"다운로드 (2)\"></p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"4-모든-task가-종료된다\" style=\"position:relative;\"><a href=\"#4-%EB%AA%A8%EB%93%A0-task%EA%B0%80-%EC%A2%85%EB%A3%8C%EB%90%9C%EB%8B%A4\" aria-label=\"4 모든 task가 종료된다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. 모든 task가 종료된다.</h4>\n<p>AM도 종료되고 클러스터에 할당된 컨테이너의 자원도 모두 de-allocated 된다.<br>\n그리고 Application client 도 종료된다</p>\n</li>\n</ul>\n<br/>\n<p>Yarn의 결론 </p>\n<p>결국 Yarn은 app의 job을 분산처리된 환경에서 처리할 수 있도록 도와주는 서비스 이다.<br>\n위에서 설명한 RM(Resource Manager),AM(Application Manager),NM(Node..)가<br>\n주요 컴포넌트이고 하나의 JOB을 처리하기 위해 여러 TASK를 나누고<br>\n이를 분산환경에서 처리하기 위해 Container라는 개념이 존재한다.<br>\n즉 기존 Hadoop 1.X Version에서의 분산처리 MapReduce의 문제를<br>\nYarn으로 프로세싱을 나누어 적합하게 처리하는 목적이다. </p>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>이번 포스트에서도 자세하게 EcoSystem에 대해서 설명하고 싶었지만<br>\n이론적인 내용들만 다루다보니 또 주제에서 약간 벗어난 것 같습니다<br>\n추후 Sub Project tools을 각각 사용해보면서 자세하게 다시 리뷰 해야 할 것 같습니다.  </p>\n<br/>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#-hadoop-ecosystem-sub-project\">✔ Hadoop EcoSystem Sub Project</a></p>\n<ul>\n<li><a href=\"#zookeeper%EC%A3%BC%ED%82%A4%ED%8D%BC---%EB%B6%84%EC%82%B0-%EC%BD%94%EB%94%94%EB%84%A4%EC%9D%B4%ED%84%B0\">Zookeeper(주키퍼) - 분산 코디네이터</a></li>\n<li><a href=\"#oozie%EC%9A%B0%EC%A7%80\">Oozie(우지)</a></li>\n<li><a href=\"#pig-%ED%94%BC%EA%B7%B8\">Pig (피그)</a></li>\n<li><a href=\"#hive-%ED%95%98%EC%9D%B4%EB%B8%8C\">HIVE (하이브)</a></li>\n<li><a href=\"#hbase\">HBase</a></li>\n<li><a href=\"#yarn-yet-another-resource-negotiator\">Yarn (Yet Another Resource Negotiator)</a></li>\n<li><a href=\"#yarn%EC%9D%98-running-processapplicationmaster\">Yarn의 Running Process/ApplicationMaster</a></li>\n</ul>\n</li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","excerpt":"머리말   이전 포스트에서 Hadoop EcoSystem 중 Core Project에 대해서 다뤘었습니다. 이번 포스트에서는 데이터를 수집하거나 DB화 하는 오픈소스들의 모음인 SUB Project들에 대해서 다룹니다. 모든 프로젝트를 다루지는 않고 앞으로 사용하게 될 것 같은 프로젝트 위주로 정리했습니다.     ✔ Hadoop EcoSystem Sub Project 123123123 이전포스트에서는 Hadoop EcoSystem의 Core Project 부분에 대해서 다뤘습니다. Core Project는 다 설명했고 이제 Hadoop Sub Project의 차례 입니다.  Hadoop Core Project : H…","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Hadoop EcoSystem Sub Project","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/data-hadoopeco/"}},"next":{"id":"e82d4a67-91b1-5218-9fc2-35c7377e5ffc","html":"<p>머리말  </p>\n<p>이번 내용은 이전에 Spark의 이론적인 설명을 이어서 더 대표적인 Hadoop에 대해서 이론적인 내용들을 정리해보는 포스트입니다.<br>\n저는 여러 포스트로 실제 Cluster를 구축하긴 했지만 HDFS가 데이터를 어떻게 저장하는지, ecosystem이 뭐지? 라는<br>\n의문이 많이 남았기에 궁금한 내용들을 정리할 필요를 느꼈습니다.  </p>\n<hr>\n<h2 id=\"-apache-hadoop\" style=\"position:relative;\"><a href=\"#-apache-hadoop\" aria-label=\" apache hadoop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Apache Hadoop?</h2>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110746690-8395f600-8280-11eb-867b-616f6c82b8fb.JPG\" alt=\"1111123123\"></p>\n<p>Hadoop : <em>하둡 소프트웨어 라이브러리는 간단한 프로그래밍 모델을 사용하여<br>\n여러대의 컴퓨터 클러스터에서 대규모 데이터 세트를 분산 처리 할 수있게 해주는 프레임워크 이다.</em></p>\n<p>라고 모든 글에서 설명을 하는데 나는 그냥 데이터를 분산 저장하는 파일시스템이라고 이해했다.<br>\n솔직히 아직 많이 다뤄보지 못해서 정확한 의미는 잘 모르겠고<br>\n가장 주력으로 두고 있는 HDFS와 MapReduce 방식을 이해하면 프레임 워크라는게 어떤 말인지 대충 이해는 가고<br>\n나아가서는 EcoSystem에 대해 이해를 한다면 어떤 느낌인지 감이 올 것같다.  </p>\n<p>하둡의 초기에 HDFS, MapReduce 프레임워크로 시작되었으나<br>\n현재에는 여러 데이터저장, 실행엔진, 프로그래밍 및 데이터처리 같이<br>\n하둡 생태계 (Hadoop Ecosystem)을 포함하는 의미로 확장 발전 되었다고 한다.</p>\n<br/>\n<ul>\n<li>\n<h3 id=\"hadoop-ecosystem\" style=\"position:relative;\"><a href=\"#hadoop-ecosystem\" aria-label=\"hadoop ecosystem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop Ecosystem</h3>\n<p>위에서 Hadoop을 분산 FrameWork이라고 설명했었는데<br>\nHadoop Ecosystem이 그 FrameWork을 이루는 프로젝트의 모임이라고 생각하면 된다.  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110749647-be9a2880-8284-11eb-81ba-ab6f7a2e6dc1.png\" alt=\"123123123\"></p>\n<br/>\n<p>이 많은 Service 들을 정리하면 다음과 같다. </p>\n<ul>\n<li>Hadoop Core Project : HDFS(분산 데이터 저장), MapReduce(분산 처리)</li>\n<li>Hadoop Sub Project : 나머지 프로젝트 -> 데이터 마이닝, 수집, 분석 등을 수행한다.</li>\n</ul>\n<p>너무 많은 서비스에 저도 이해가 잘 안되서 간단하게 정리를 해봤습니다.</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110750345-ad055080-8285-11eb-88f1-822e3be5c029.JPG\" alt=\"11111123233\"></p>\n<br/>\n<p>다른 분들이 각 프로젝트 들에 대해서 잘 정리해놓은 것도 있네요</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110750466-db832b80-8285-11eb-8361-c32461fc97b8.JPG\" alt=\"33333333\"></p>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"-hadoop-ecosystem-core-구성-요소\" style=\"position:relative;\"><a href=\"#-hadoop-ecosystem-core-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\" aria-label=\" hadoop ecosystem core 구성 요소 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✌ Hadoop EcoSystem Core 구성 요소</h2>\n<br/>\n<ul>\n<li>\n<h3 id=\"hdfs-hadoop-distributed-file-system\" style=\"position:relative;\"><a href=\"#hdfs-hadoop-distributed-file-system\" aria-label=\"hdfs hadoop distributed file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS (Hadoop Distributed File System)</h3>\n<p>Hadoop Ecosystem의 환경에서 데이터를 저장하는 분산형 파일 시스템<br>\nHDFS는 Hadoop Framework을 위해 JAVA로 작성된 분산 확장 파일 시스템입니다.<br>\nHDFS는 대용량 파일을 여러 서버에 나누고, 중복 저장함으로써 안정성을 높힙니다. </p>\n<br/>\n</li>\n<li>\n<h4 id=\"특징\" style=\"position:relative;\"><a href=\"#%ED%8A%B9%EC%A7%95\" aria-label=\"특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>특징</h4>\n<ol>\n<li>HDFS는 다수의 노드에 복제 데이터도 함께 저장해 데이터 유실을 방지한다.  </li>\n<li>HDFS에 저장된 파일을 조회하려면 스트리밍 방식으로 데이터에 접근해야한다  </li>\n<li>한번 저장한 데이터는 수정할 수 없고, 읽기만 가능해서 데이터 무결성을 유지한다.<br>\n4.데이터 수정은 불가능하지만 파일 이동, 삭제, 복사할 수 있는 인터페이스를 제공한다.</li>\n</ol>\n<br/>\n</li>\n<li>\n<h4 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110756535-aed31200-828d-11eb-8d1e-e2bd0843713f.JPG\" alt=\"222211312\"></p>\n<p>HDFS는 마스터/슬레이브(master/slave)구조를 가집니다. </p>\n<br/>\n</li>\n<li>\n<h4 id=\"hdfs의-특징\" style=\"position:relative;\"><a href=\"#hdfs%EC%9D%98-%ED%8A%B9%EC%A7%95\" aria-label=\"hdfs의 특징 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS의 특징</h4>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> Block 구조의 FileSystem<span class=\"token punctuation\">,</span> 저장파일은 특정 사이즈의 Block으로 나눠져 분산된 서버에 저장된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> 하나의 Block은 <span class=\"token number\">3</span>개<span class=\"token punctuation\">(</span>수정 가능<span class=\"token punctuation\">)</span>로 복제되며<span class=\"token punctuation\">,</span> 각각 다른 HDFS의 DataNode에 분산저장된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> HDFS에는 NameNode 서버 한 대<span class=\"token punctuation\">,</span> Slave 역할을 하는 DataNode 서버가 여러 대로 구성된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> NameNode는 HDFS의 모든 <span class=\"token function\">Metadata</span><span class=\"token punctuation\">(</span>블록들이 저장되는 디렉토리의 이름<span class=\"token punctuation\">,</span> 파일명등<span class=\"token range operator\">..</span><span class=\"token punctuation\">)</span>를 관리하고  \n   Client가 이를 이용하여 HDFS에 저장된 파일에 접근할 수 있다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> 하둡 어플리케이션은 HDFS에 파일을 저장하거나<span class=\"token punctuation\">,</span> 저장된 파일을 읽기 위해 HDFS Client를 사용하며 API형태로 사용자에게 제공된다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> DataNode는 주기적으로  HeartBeat 전송한다 \n   <span class=\"token punctuation\">(</span>NameNode에서 <span class=\"token class-name\">Block</span> Report <span class=\"token punctuation\">:</span> 노드에 저장되어 있는 블록의 정보 <span class=\"token operator\">=</span> Metadata<span class=\"token punctuation\">)</span>\n   이를 통해 NameNode는 DataNode가 정상 동작하는지 확인한다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">7</span><span class=\"token punctuation\">.</span> Clients는 NameNode에 접속해서 원하는 파일이 저장된 블록의 위치를 확인하고<span class=\"token punctuation\">,</span>  \n   해당 Block이 저장된 DataNode에서 직접 데이터를 조회한다<span class=\"token punctuation\">.</span>  </code></pre></div>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"hdfs-file-저장-flow\" style=\"position:relative;\"><a href=\"#hdfs-file-%EC%A0%80%EC%9E%A5-flow\" aria-label=\"hdfs file 저장 flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS File 저장 Flow</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110758607-0bcfc780-8290-11eb-91ad-1b1e234128d2.png\" alt=\"다운로드11\"></p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> APP이 Client에게 파일 저장을 요청  \n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> Client는 NameNode에게 Block이 저장될 경로 생성을 요청한다<span class=\"token punctuation\">.</span> \n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> NameNode는 해당 경로가 존재하지 않으면 생성한 뒤  \n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> NameNode는 그 경로에 수정하지 못하게 LOCKING을 걸어둡니다<span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> 그 후 Client에게 Block을 저장할 DataNode 목록을 반환하고  \n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> Client는 첫번째 DataNode에 Data Block을 전송 \n\n<span class=\"token number\">7</span><span class=\"token punctuation\">.</span> 첫번째 DataNode는 Local에 저장한 뒤 두번째 DataNode로 전송 \n\n<span class=\"token number\">8</span><span class=\"token punctuation\">.</span> 두번째 DataNode는 동일하게 저장한 뒤 세번째로 전송 \n\n<span class=\"token number\">9</span><span class=\"token punctuation\">.</span> 세번째 DataNode부터 Local에 저장완료 후 넘겨준 DataNode에게 완료 Return을 준다 \n\n<span class=\"token number\">10</span><span class=\"token punctuation\">.</span> 최종적으로는 첫번째 DataNode가 Client에게 저장완료를 Return</code></pre></div>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h4 id=\"hdfs-file-읽기-flow\" style=\"position:relative;\"><a href=\"#hdfs-file-%EC%9D%BD%EA%B8%B0-flow\" aria-label=\"hdfs file 읽기 flow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS File 읽기 Flow</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110759735-471ec600-8291-11eb-9e63-5e5164a004d1.png\" alt=\"64982211\"></p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token number\">1</span><span class=\"token punctuation\">.</span> APP이 Client에게 파일 읽기를 요청\n\n<span class=\"token number\">2</span><span class=\"token punctuation\">.</span> Client는 NameNode에게 파일이 어느 DataNode의 어떤 블록에 저장되어 있는지 정보를 요청\n\n<span class=\"token number\">3</span><span class=\"token punctuation\">.</span> MetaData를 통해 파일이 저장된 블록 리스트를 Client에게 반환\n\n<span class=\"token number\">4</span><span class=\"token punctuation\">.</span> Client는 해당 DataNode에 접근해 Block 조회 요청\n\n<span class=\"token number\">5</span><span class=\"token punctuation\">.</span> DataNode는 Client에게 요청된 Block을 전송\n\n<span class=\"token number\">6</span><span class=\"token punctuation\">.</span> Client는 App에 데이터를 전달</code></pre></div>\n<br/>\n</li>\n</ul>\n<hr>\n<ul>\n<li>\n<h3 id=\"mapreduce-a-namea4a\" style=\"position:relative;\"><a href=\"#mapreduce-a-namea4a\" aria-label=\"mapreduce a namea4a permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce <a name=\"a4\"></a></h3>\n<p>대용량의 데이터 처리를 위한 분산 프로그래밍 Model, 소프트웨어 FrameWork라고 불린다.<br>\n대규모 분산 컴퓨팅 환경에서 MapReduce를 이용해 대량의 데이터를 병렬로 분석이 가능하고<br>\n직접 작성하는 Map과 Reduce 라는 두 개의 메소드로 구성된다.<br>\n요새는 HIVE등 SQL과 유사한 구문으로 MapReduce Code를 만들어 사용한다.</p>\n<p>MapReduce는 Hadoop 클러스터의 데이터를 처리하기 위한 시스템으로,<br>\n총 2개 Map , Reduce의 phase로 구성되어 있다.</p>\n<p>Map과 Reduce사이에는 Shuffle과 Sort라는 스테이지가 존재한다.<br>\n각 Map Task는 전체 데이터 세트에 대한 별개의 부분에 대한 작업을 수행하게 되는데<br>\n기본적으로 하나의 HDFS Block을 대상으로 수행하게 된다.<br>\n모든 Map Task가 종료되면 MapReduce 시스템은 intermediate<br>\n데이터를 Reduce phase를 수행할 노드로 분산하여 전송한다.</p>\n<br/>\n</li>\n<li>\n<h4 id=\"map--reduce\" style=\"position:relative;\"><a href=\"#map--reduce\" aria-label=\"map  reduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MAP &#x26; REDUCE</h4>\n<p>똑똑한 1명이 다량의 일을 처리하는 것<br>\n평범한 100명이 다량의 일을 처리하는 것<br>\n상식적으로 둘 중에 100명 진행하는 것이 훨씬 더 빠를 것이다.<br>\n위의 예가 분산처리의 핵심이지만 100명 각각의 결과를 취합하고 정리하는 시간의 소모도 크다.<br>\n또한 탐색할 데이터가 비정형이라서 갯수가 101개라거나, 길이가 서로 다르다거나 하면<br>\n이를 동일한 업무크기로 나누는 일도 쉽지가 않다.</p>\n<h3 id=\"mapreduce는-이러한-처리를-도와주는-역할을-한다\" style=\"position:relative;\"><a href=\"#mapreduce%EB%8A%94-%EC%9D%B4%EB%9F%AC%ED%95%9C-%EC%B2%98%EB%A6%AC%EB%A5%BC-%EB%8F%84%EC%99%80%EC%A3%BC%EB%8A%94-%EC%97%AD%ED%95%A0%EC%9D%84-%ED%95%9C%EB%8B%A4\" aria-label=\"mapreduce는 이러한 처리를 도와주는 역할을 한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce는 이러한 처리를 도와주는 역할을 한다.</h3>\n<br>\n</li>\n<li>\n<h4 id=\"분산형-파일시스템에서는\" style=\"position:relative;\"><a href=\"#%EB%B6%84%EC%82%B0%ED%98%95-%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%97%90%EC%84%9C%EB%8A%94\" aria-label=\"분산형 파일시스템에서는 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>분산형 파일시스템에서는?</h4>\n<p>① MapReduce 작업이 끝나면 HDFS에 파일이 써지고(write)<br>\n② MapReduce 작업이 시작될 때는 HDFS로 부터 파일을 가져오는(Read) 작업이 수행된다.</p>\n<p>MapReduce는 명칭 그대로 Map단계 &#x26; Reduce단계로 이루어진다.</p>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h3 id=\"map\" style=\"position:relative;\"><a href=\"#map\" aria-label=\"map permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MAP</h3>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110880244-aa583900-8321-11eb-8a05-de07fbfd261d.png\" alt=\"111111\"></p>\n<ul>\n<li>위의 그림처럼 흩어져 있는 분산 클러스터에서 각각의 데이터를 <code class=\"language-text\">(key, value의 형태)</code>로 분류합니다.  </li>\n<li>MapReduce의 Job의 입력 크기를 <code class=\"language-text\">스플릿</code>이라고 합니다<br>\n-> 각 스플릿마다 하나의 Map Task를 생성하게되고<br>\n-> 만들어진 Map Task는 스플릿의 레코드를 Map 함수로 처리<br>\n-> (key, value) 구조를 가지는 중간 산출물이 생성!</li>\n</ul>\n</li>\n</ul>\n<br/>\n<ul>\n<li>\n<h3 id=\"reduce\" style=\"position:relative;\"><a href=\"#reduce\" aria-label=\"reduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reduce</h3>\n<br/>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110882149-d88b4800-8324-11eb-9370-ba6df69a549d.png\" alt=\"11123323\"></p>\n<p>위의 그림은 문자열 데이터를 포함된 단어의 빈도 별로 나눠 출력해주는 Reduce 과정입니다.<br>\nMapReduce는 다음과 같은 과정으로 데이터를 다룹니다.</p>\n<ul>\n<li>Splitting : 문자열 데이터를 라인별로 나누는 과정</li>\n<li>Mapping : 라인별로 문자열을 입력 -> (key, value) 형태로 출력</li>\n<li>Shuffling : 같은 key를 가지는 데이터끼리 분류</li>\n<li>Reducing : 각 key 별로 빈도수를 합산해서 출력</li>\n<li>Final Result : 리듀스 메소드의 출력 데이터를 합쳐서 하둡 파일시스템에 저장</li>\n</ul>\n<br/>\n</li>\n<li>\n<p>간단하게 Map, Reduce 영역을 분리한 그림 </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110893271-fa8ec580-8338-11eb-883a-a4b715313a3d.png\" alt=\"33333\"></p>\n</li>\n</ul>\n<br>\n<ul>\n<li>\n<h3 id=\"mapreduce-jop\" style=\"position:relative;\"><a href=\"#mapreduce-jop\" aria-label=\"mapreduce jop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce Jop</h3>\n<p>Job은 ‘Full Program’ 즉, 전체 프로그램을 의미합니다.<br>\n데이터 집합을 통해 Mapper와 Reducer를 전체 실행하고<br>\nTask는 데이터 Block을 통해 하나의 Mapper 또는 Reducer를 실행하게 됩니다.</p>\n<ul>\n<li>Client가 수행하려는 작업단위<br>\n입력데이터, 맵리듀스 프로그램, 설정 정보로 구성.</li>\n<li>Hadoop은 Job을 Map Task와 Reduce Task로 작업을 나누어서 실행</li>\n<li>Job이 실행되는 과정을 제어 해주는 노드</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"mapreduce-시스템-구성\" style=\"position:relative;\"><a href=\"#mapreduce-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EA%B5%AC%EC%84%B1\" aria-label=\"mapreduce 시스템 구성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce 시스템 구성</h3>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110894214-cfa57100-833a-11eb-9a91-388e8d72ce48.png\" alt=\"image44444\"></p>\n<p>MapReduce System은 Client, JobTracker, TaskTracker로 구성된다.</p>\n<ul>\n<li>JobTracker 는 NameNode(Master)에 위치</li>\n<li>TaskTracker 는 DataNode(Slave)에 위치</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"client\" style=\"position:relative;\"><a href=\"#client\" aria-label=\"client permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Client</h3>\n<p>분석하고자 하는 데이터를 Job의 형태로 JobTracker에게 전달한다.</p>\n<br/>\n</li>\n<li>\n<h3 id=\"jobtracker\" style=\"position:relative;\"><a href=\"#jobtracker\" aria-label=\"jobtracker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>JobTracker</h3>\n<ul>\n<li>NameNode에 위치  </li>\n<li>Hadoop Cluster의 전체 Job들을 스케줄링하고 모니터링</li>\n</ul>\n<p>맵 리듀스 Job들은 JobTracker라는 소프트웨어 데몬에 의해 제어된다.<br>\nJobTracker들은 다음과 같은 역할을 수행한다.</p>\n<ul>\n<li>\n<ol>\n<li>Client는 MapReduce의 Job을 JobTracker에게 보낸다  </li>\n</ol>\n</li>\n<li>\n<ol start=\"2\">\n<li>JobTracker는 Clsuter의 다른 노드들에게 맵과 리듀스 Task를 할당한다.  </li>\n</ol>\n</li>\n<li>\n<ol start=\"3\">\n<li>해당 노드들은 TaskTracker라는 데몬에 의해 각각 실행되고  </li>\n</ol>\n</li>\n<li>\n<ol start=\"4\">\n<li>TaskTracker는 Map,Reduce Task를 인스턴스화 한 뒤 진행 상황을 JobTracker에게 보고한다.</li>\n</ol>\n</li>\n</ul>\n<br/>\n</li>\n<li>\n<h3 id=\"tasktracker\" style=\"position:relative;\"><a href=\"#tasktracker\" aria-label=\"tasktracker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TaskTracker</h3>\n<ul>\n<li>DataNode에서 실행되는 데몬 (DataNode에 위치)</li>\n<li>사용자가 설정한 맵리듀스 프로그램을 실행해 JobTracker로부터 작업을 요청받은뒤  </li>\n<li>Map과 Reduce 요청 개수만큼 Map,Reduce Task를 생성한 뒤 JobTracker에게 보고한다.</li>\n</ul>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>이번 포스트에서는 Hadoop에 대한 간단한 설명들과 EcoSyetem의 Core Preeject 부분을 자세히 살펴봤습니다.<br>\n원래 Sub까지 한 포스트에서 다루려고 했지만 포스트가 너무 길어져서 다음포스트에서 이어서 설명하겠습니다.    </p>\n<br/>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#-apache-hadoop\">✔ Apache Hadoop?</a></li>\n<li><a href=\"#-hadoop-ecosystem-core-%EA%B5%AC%EC%84%B1-%EC%9A%94%EC%86%8C\">✌ Hadoop EcoSystem Core 구성 요소</a></li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","frontmatter":{"date":"August 13, 2021","title":"[DATA] - Apache Hadoop, HDFS, MapReduce","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/data-hadoop/"}},"prev":{"id":"55f2967c-b271-5121-9dc5-8bebc2e1c7a9","html":"<p>머리말  </p>\n<p>저번 포스트에서 Apache Spark가 어떤 식으로 동작하는지? 어떤 함수가 있는지? 간단하게 이론적으로만 알아봤습니다.<br>\n아직 Spark에 대한 내용이 제대로 이해가 되지 않아 일단 구성부터 해보고 실습을 하면서 다시 이해를 해보겠습니다.  </p>\n<hr>\n<h2 id=\"-azure-vm에-spark-standalone-구성\" style=\"position:relative;\"><a href=\"#-azure-vm%EC%97%90-spark-standalone-%EA%B5%AC%EC%84%B1\" aria-label=\" azure vm에 spark standalone 구성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>✔ Azure VM에 Spark StandAlone 구성</h2>\n<ul>\n<li>Spark StandAlone Cluster로 구성하는 포스트입니다. </li>\n</ul>\n<br/>\n<h3 id=\"환경구성\" style=\"position:relative;\"><a href=\"#%ED%99%98%EA%B2%BD%EA%B5%AC%EC%84%B1\" aria-label=\"환경구성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>환경구성</h3>\n<ul>\n<li>OS : CentOS Linux release 8.2.2004 (Core)  </li>\n<li>cpu : 4 core  </li>\n<li>RAM : 14GB  </li>\n<li>JDK : 1.8.0</li>\n<li>python : 3.8.8</li>\n<li>Spark 3.0.2</li>\n<li>zeppelin : 0.9.0</li>\n</ul>\n<br/> \n<hr>\n<h3 id=\"1-open-jdk-설치-root-계정-기반\" style=\"position:relative;\"><a href=\"#1-open-jdk-%EC%84%A4%EC%B9%98-root-%EA%B3%84%EC%A0%95-%EA%B8%B0%EB%B0%98\" aria-label=\"1 open jdk 설치 root 계정 기반 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Open JDK 설치 (root 계정 기반)</h3>\n<p>Spark는 JVM 기반이기 때문에 JDK를 미리 설치해주어야 합니다.  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span># yum install <span class=\"token operator\">-</span>y java<span class=\"token operator\">-</span><span class=\"token number\">1.8</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>openjdk<span class=\"token operator\">-</span>devel<span class=\"token punctuation\">.</span>x86_64\nLast metadata <span class=\"token class-name\">expiration</span> check<span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span><span class=\"token number\">28</span><span class=\"token punctuation\">:</span><span class=\"token number\">13</span> ago <span class=\"token keyword\">on</span> Thu <span class=\"token number\">04</span> Mar <span class=\"token number\">2021</span> <span class=\"token number\">07</span><span class=\"token punctuation\">:</span><span class=\"token number\">30</span><span class=\"token punctuation\">:</span><span class=\"token number\">20</span> AM UTC<span class=\"token punctuation\">.</span>\n<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span>\n<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span>\n<span class=\"token punctuation\">(</span>중략<span class=\"token punctuation\">)</span>\nComplete<span class=\"token operator\">!</span></code></pre></div>\n<br/>\n<p>java version을 확인해보죠  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span># java <span class=\"token operator\">-</span>version\nopenjdk version <span class=\"token string\">\"1.8.0_275\"</span>\nOpenJDK <span class=\"token return-type class-name\">Runtime</span> Environment <span class=\"token punctuation\">(</span>build <span class=\"token number\">1.8</span><span class=\"token number\">.0_275</span><span class=\"token operator\">-</span>b01<span class=\"token punctuation\">)</span>\nOpenJDK <span class=\"token number\">64</span><span class=\"token operator\">-</span>Bit <span class=\"token return-type class-name\">Server</span> VM <span class=\"token punctuation\">(</span>build <span class=\"token number\">25.275</span><span class=\"token operator\">-</span>b01<span class=\"token punctuation\">,</span> <span class=\"token class-name\">mixed</span> mode<span class=\"token punctuation\">)</span></code></pre></div>\n<br/>\n<hr>\n<h3 id=\"2-apache-spark-설치-root-계정-기반\" style=\"position:relative;\"><a href=\"#2-apache-spark-%EC%84%A4%EC%B9%98-root-%EA%B3%84%EC%A0%95-%EA%B8%B0%EB%B0%98\" aria-label=\"2 apache spark 설치 root 계정 기반 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Apache Spark 설치 (root 계정 기반)</h3>\n<br/> \n<p>Spark 3.0.2 다운로드  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span># <span class=\"token class-name\">wget</span> https<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>downloads<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>org<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span><span class=\"token number\">3.0</span><span class=\"token number\">.2</span><span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span><span class=\"token number\">3.0</span><span class=\"token number\">.2</span><span class=\"token operator\">-</span>bin<span class=\"token operator\">-</span>hadoop2<span class=\"token punctuation\">.</span><span class=\"token number\">7</span><span class=\"token punctuation\">.</span>tgz</code></pre></div>\n<br/>\n<p>압축해제 및 권한 설정  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> home<span class=\"token punctuation\">]</span># useradd spark\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> home<span class=\"token punctuation\">]</span># cd <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> spark<span class=\"token punctuation\">]</span># tar xvfz spark<span class=\"token operator\">-</span><span class=\"token number\">3.0</span><span class=\"token number\">.2</span><span class=\"token operator\">-</span>bin<span class=\"token operator\">-</span>hadoop2<span class=\"token punctuation\">.</span><span class=\"token number\">7</span><span class=\"token punctuation\">.</span>tgz\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> spark<span class=\"token punctuation\">]</span># mv spark<span class=\"token operator\">-</span><span class=\"token number\">3.0</span><span class=\"token number\">.2</span><span class=\"token operator\">-</span>bin<span class=\"token operator\">-</span>hadoop2<span class=\"token punctuation\">.</span><span class=\"token number\">7</span> spark\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> spark<span class=\"token punctuation\">]</span># chown <span class=\"token operator\">-</span><span class=\"token class-name\">R</span> spark<span class=\"token punctuation\">:</span>spark spark\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> spark<span class=\"token punctuation\">]</span># chmod <span class=\"token operator\">-</span>R <span class=\"token number\">777</span>  spark</code></pre></div>\n<br/>\n<p>Spark 환경변수 등록 (spark 계정으로 전환 후 진행)  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>spark@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span>$ echo <span class=\"token class-name\">export</span> PATH<span class=\"token operator\">=</span>'$PATH'<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>bin <span class=\"token operator\">></span> <span class=\"token operator\">~</span><span class=\"token operator\">/</span><span class=\"token punctuation\">.</span>bashrc\n<span class=\"token punctuation\">[</span>spark@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span>$ source <span class=\"token operator\">~</span><span class=\"token operator\">/</span><span class=\"token punctuation\">.</span>bashrc</code></pre></div>\n<br/>\n<p>Spark 설치 확인 </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>spark@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span>$ spark<span class=\"token operator\">-</span>shell\n<span class=\"token number\">21</span><span class=\"token operator\">/</span><span class=\"token number\">03</span><span class=\"token operator\">/</span><span class=\"token number\">04</span> <span class=\"token number\">08</span><span class=\"token punctuation\">:</span><span class=\"token number\">37</span><span class=\"token punctuation\">:</span><span class=\"token number\">37</span> <span class=\"token class-name\">WARN</span> NativeCodeLoader<span class=\"token punctuation\">:</span> Unable to load native<span class=\"token operator\">-</span>hadoop library <span class=\"token keyword\">for</span> your platform<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span> <span class=\"token keyword\">using</span> builtin<span class=\"token operator\">-</span>java classes <span class=\"token keyword\">where</span> <span class=\"token class-name\">applicable</span>\nUsing Spark's <span class=\"token keyword\">default</span> <span class=\"token class-name\">log4j</span> profile<span class=\"token punctuation\">:</span> org<span class=\"token operator\">/</span>apache<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>log4j<span class=\"token operator\">-</span>defaults<span class=\"token punctuation\">.</span>properties\nSetting <span class=\"token keyword\">default</span> log level to <span class=\"token string\">\"WARN\"</span><span class=\"token punctuation\">.</span>\nTo adjust logging level <span class=\"token return-type class-name\">use</span> sc<span class=\"token punctuation\">.</span><span class=\"token function\">setLogLevel</span><span class=\"token punctuation\">(</span>newLevel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span> <span class=\"token class-name\">For</span> SparkR<span class=\"token punctuation\">,</span> <span class=\"token return-type class-name\">use</span> <span class=\"token function\">setLogLevel</span><span class=\"token punctuation\">(</span>newLevel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>\nSpark context Web UI available <span class=\"token class-name\">at</span> http<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span>standalone<span class=\"token punctuation\">.</span><span class=\"token keyword\">internal</span><span class=\"token punctuation\">.</span>cloudapp<span class=\"token punctuation\">.</span>net<span class=\"token punctuation\">:</span><span class=\"token number\">4040</span>\nSpark context available <span class=\"token keyword\">as</span> 'sc' <span class=\"token punctuation\">(</span>master <span class=\"token operator\">=</span> local<span class=\"token punctuation\">[</span><span class=\"token operator\">*</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">app</span> id <span class=\"token operator\">=</span> local<span class=\"token operator\">-</span><span class=\"token number\">1614847063399</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>\nSpark session available <span class=\"token keyword\">as</span> 'spark'<span class=\"token punctuation\">.</span>\nWelcome to\n      ____              __\n     <span class=\"token operator\">/</span> __<span class=\"token operator\">/</span>__  ___ _____<span class=\"token operator\">/</span> <span class=\"token operator\">/</span>__\n    _\\ \\<span class=\"token operator\">/</span> _ \\<span class=\"token operator\">/</span> _ `<span class=\"token operator\">/</span> __<span class=\"token operator\">/</span>  '_<span class=\"token operator\">/</span>\n   <span class=\"token operator\">/</span>___<span class=\"token operator\">/</span> <span class=\"token punctuation\">.</span>__<span class=\"token operator\">/</span>\\_<span class=\"token punctuation\">,</span>_<span class=\"token operator\">/</span>_<span class=\"token operator\">/</span> <span class=\"token operator\">/</span>_<span class=\"token operator\">/</span>\\_\\   version <span class=\"token number\">3.0</span><span class=\"token number\">.2</span>\n      <span class=\"token operator\">/</span>_<span class=\"token operator\">/</span>\n\nUsing Scala version <span class=\"token number\">2.12</span><span class=\"token number\">.10</span> <span class=\"token punctuation\">(</span>OpenJDK <span class=\"token number\">64</span><span class=\"token operator\">-</span>Bit <span class=\"token class-name\">Server</span> VM<span class=\"token punctuation\">,</span> Java <span class=\"token number\">1.8</span><span class=\"token number\">.0_275</span><span class=\"token punctuation\">)</span>\nType <span class=\"token keyword\">in</span> expressions to have them evaluated<span class=\"token punctuation\">.</span>\nType <span class=\"token punctuation\">:</span>help <span class=\"token keyword\">for</span> more information<span class=\"token punctuation\">.</span>\n\nscala<span class=\"token operator\">></span></code></pre></div>\n<br/>\n<p>Spark Config 설정 </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token preprocessor property\">## Spark_HOME의 conf 디렉토리에서 수행</span>\n\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> conf<span class=\"token punctuation\">]</span># cp spark<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh<span class=\"token punctuation\">.</span>template spark<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> conf<span class=\"token punctuation\">]</span># vim spark<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh\n\n\n<span class=\"token preprocessor property\">## nasa setting</span>\n\n<span class=\"token class-name\">export</span> SPARK_WORKER_INSTANCES<span class=\"token operator\">=</span><span class=\"token number\">3</span> <span class=\"token punctuation\">[</span>worker node에 대한 설정<span class=\"token punctuation\">]</span></code></pre></div>\n<p>Spark Master 프로세스 실행</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> sbin<span class=\"token punctuation\">]</span># sh start<span class=\"token operator\">-</span>master<span class=\"token punctuation\">.</span>sh\nstarting org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>master<span class=\"token punctuation\">.</span>Master<span class=\"token punctuation\">,</span> logging to <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>logs<span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span>root<span class=\"token operator\">-</span>org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>master<span class=\"token punctuation\">.</span>Master<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>Standalone<span class=\"token punctuation\">.</span><span class=\"token keyword\">out</span></code></pre></div>\n<br/>\n<p>MASTER WEB 확인 (Cloud라면 Inbound 설정 필요)</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110070522-86df3c80-7dbd-11eb-82cd-85a45eb4eeb2.JPG\" alt=\"캡처3121\"></p>\n<ul>\n<li>Worker Node 설정에 필요한 url을 미리 복사<br>\nspark://Standalone.44p1qlnthrou1ezmysbcbmontc.syx.internal.cloudapp.net:7077</li>\n</ul>\n<br/>\n<p>Worker Node 프로세스 실행</p>\n<p>아까 env.sh 설정에 맞게 3개의 Worker 가 생성됩니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> sbin<span class=\"token punctuation\">]</span># sh start<span class=\"token operator\">-</span><span class=\"token class-name\">slave<span class=\"token punctuation\">.</span>sh</span> spark<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>Standalone<span class=\"token punctuation\">.</span>44p1qlnthrou1ezmysbcbmontc<span class=\"token punctuation\">.</span>syx<span class=\"token punctuation\">.</span><span class=\"token keyword\">internal</span><span class=\"token punctuation\">.</span>cloudapp<span class=\"token punctuation\">.</span>net<span class=\"token punctuation\">:</span><span class=\"token number\">7077</span> <span class=\"token operator\">-</span>m 2g <span class=\"token operator\">-</span>c <span class=\"token number\">1</span>\nstarting org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>worker<span class=\"token punctuation\">.</span>Worker<span class=\"token punctuation\">,</span> logging to <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>logs<span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span>root<span class=\"token operator\">-</span>org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>worker<span class=\"token punctuation\">.</span>Worker<span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>Standalone<span class=\"token punctuation\">.</span><span class=\"token keyword\">out</span>\nstarting org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>worker<span class=\"token punctuation\">.</span>Worker<span class=\"token punctuation\">,</span> logging to <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>logs<span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span>root<span class=\"token operator\">-</span>org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>worker<span class=\"token punctuation\">.</span>Worker<span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token operator\">-</span>Standalone<span class=\"token punctuation\">.</span><span class=\"token keyword\">out</span>\nstarting org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>worker<span class=\"token punctuation\">.</span>Worker<span class=\"token punctuation\">,</span> logging to <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>logs<span class=\"token operator\">/</span>spark<span class=\"token operator\">-</span>root<span class=\"token operator\">-</span>org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>deploy<span class=\"token punctuation\">.</span>worker<span class=\"token punctuation\">.</span>Worker<span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token operator\">-</span>Standalone<span class=\"token punctuation\">.</span><span class=\"token keyword\">out</span></code></pre></div>\n<br/>\n<p>Master WEB에서 Worker 등록 확인</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110070820-23a1da00-7dbe-11eb-8014-304fd2583ef8.JPG\" alt=\"44444\"></p>\n<br/>\n<hr>\n<h3 id=\"3-zeppelin-설치-root-계정-기반\" style=\"position:relative;\"><a href=\"#3-zeppelin-%EC%84%A4%EC%B9%98-root-%EA%B3%84%EC%A0%95-%EA%B8%B0%EB%B0%98\" aria-label=\"3 zeppelin 설치 root 계정 기반 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Zeppelin 설치 (root 계정 기반)</h3>\n<br/> \n<p>Zeppelin 다운로드  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> zeppelin<span class=\"token punctuation\">]</span># <span class=\"token class-name\">wget</span> https<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>downloads<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>org<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">-</span><span class=\"token number\">0.9</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>preview2<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">-</span><span class=\"token number\">0.9</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>preview2<span class=\"token operator\">-</span>bin<span class=\"token operator\">-</span>all<span class=\"token punctuation\">.</span>tgz</code></pre></div>\n<br/>\n<p>압축해제 및 권한 변경</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> home<span class=\"token punctuation\">]</span># useradd zeppelin\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> home<span class=\"token punctuation\">]</span># cd <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> zeppelin<span class=\"token punctuation\">]</span># tar xvfz zeppelin<span class=\"token operator\">-</span><span class=\"token number\">0.9</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>preview2<span class=\"token operator\">-</span>bin<span class=\"token operator\">-</span>all<span class=\"token punctuation\">.</span>tgz\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> zeppelin<span class=\"token punctuation\">]</span># mv zeppelin<span class=\"token operator\">-</span><span class=\"token number\">0.9</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>preview2<span class=\"token operator\">-</span>bin<span class=\"token operator\">-</span>all zeppelin\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> zeppelin<span class=\"token punctuation\">]</span># chown <span class=\"token operator\">-</span><span class=\"token class-name\">R</span> zeppelin<span class=\"token punctuation\">:</span>zeppelin <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> zeppelin<span class=\"token punctuation\">]</span># chmod <span class=\"token operator\">-</span>R <span class=\"token number\">777</span> <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin</code></pre></div>\n<br/>\n<p>환경 변수 등록 (zeppelin 계정으로 전환 후 진행)  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>zeppelin@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span>$ echo <span class=\"token class-name\">export</span> PATH<span class=\"token operator\">=</span>'$PATH'<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>bin <span class=\"token operator\">></span> <span class=\"token operator\">~</span><span class=\"token operator\">/</span><span class=\"token punctuation\">.</span>bashrc\n<span class=\"token punctuation\">[</span>zeppelin@Spark<span class=\"token operator\">-</span>Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span>$ source <span class=\"token operator\">~</span><span class=\"token operator\">/</span><span class=\"token punctuation\">.</span>bashrc</code></pre></div>\n<br/>\n<p>Zeppelin 환경 설정  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token preprocessor property\">### /home/zeppelin/zeppelin/conf 위치에서 Conf 파일 설정</span>\n\n<span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> conf<span class=\"token punctuation\">]</span># pwd\n<span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>conf\n<span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> conf<span class=\"token punctuation\">]</span># cp zeppelin<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh<span class=\"token punctuation\">.</span>template zeppelin<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh\n\n<span class=\"token preprocessor property\">### 설정 추가</span>\n\n<span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> conf<span class=\"token punctuation\">]</span># echo <span class=\"token class-name\">export</span> JAVA_HOME<span class=\"token operator\">=</span><span class=\"token operator\">/</span>usr<span class=\"token operator\">/</span>lib<span class=\"token operator\">/</span>jvm<span class=\"token operator\">/</span>java<span class=\"token operator\">-</span><span class=\"token number\">1.8</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>openjdk <span class=\"token operator\">></span> zeppelin<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh\n<span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> conf<span class=\"token punctuation\">]</span># echo <span class=\"token class-name\">export</span> SPARK_HOME<span class=\"token operator\">=</span><span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark <span class=\"token operator\">>></span> zeppelin<span class=\"token operator\">-</span>env<span class=\"token punctuation\">.</span>sh\n\n\n<span class=\"token preprocessor property\">### Web 접속을 위한 설정</span>\n\n<span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> conf<span class=\"token punctuation\">]</span># cp zeppelin<span class=\"token operator\">-</span>site<span class=\"token punctuation\">.</span>xml<span class=\"token punctuation\">.</span>template zeppelin<span class=\"token operator\">-</span>site<span class=\"token punctuation\">.</span>xml</code></pre></div>\n<br/>\n<h4 id=\"config-수정\" style=\"position:relative;\"><a href=\"#config-%EC%88%98%EC%A0%95\" aria-label=\"config 수정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Config 수정</h4>\n<p>zeppelin-site.xml</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span>\n<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span>\n<span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n  <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>zeppelin<span class=\"token punctuation\">.</span>server<span class=\"token punctuation\">.</span>addr<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>name<span class=\"token operator\">></span>\n  <span class=\"token operator\">&lt;</span><span class=\"token keyword\">value</span><span class=\"token operator\">></span><span class=\"token number\">127.0</span><span class=\"token number\">.0</span><span class=\"token number\">.1</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span><span class=\"token keyword\">value</span><span class=\"token operator\">></span> <span class=\"token operator\">-></span> Client IP로 변경\n  <span class=\"token operator\">&lt;</span>description<span class=\"token operator\">></span>Server binding address<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>description<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>property<span class=\"token operator\">></span>\n\n<span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n  <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>zeppelin<span class=\"token punctuation\">.</span>server<span class=\"token punctuation\">.</span>port<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>name<span class=\"token operator\">></span>\n  <span class=\"token operator\">&lt;</span><span class=\"token keyword\">value</span><span class=\"token operator\">></span><span class=\"token number\">7777</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span><span class=\"token keyword\">value</span><span class=\"token operator\">></span>  <span class=\"token operator\">-></span> <span class=\"token number\">8080</span>은 Spark가 쓰고있기에 <span class=\"token number\">7777</span>로 설정\n  <span class=\"token operator\">&lt;</span>description<span class=\"token operator\">></span>Server port<span class=\"token punctuation\">.</span><span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>description<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span><span class=\"token operator\">/</span>property<span class=\"token operator\">></span>\n\n<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span>\n<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span></code></pre></div>\n<br/>\n<p>zeppelin-env.sh</p>\n<p>아래 설정 추가  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token class-name\">export</span> JAVA_HOME<span class=\"token operator\">=</span><span class=\"token operator\">/</span>usr<span class=\"token operator\">/</span>lib<span class=\"token operator\">/</span>jvm<span class=\"token operator\">/</span>java<span class=\"token operator\">-</span><span class=\"token number\">1.8</span><span class=\"token number\">.0</span><span class=\"token operator\">-</span>openjdk\n<span class=\"token class-name\">export</span> SPARK_HOME<span class=\"token operator\">=</span><span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark\n<span class=\"token class-name\">export</span> PYSPARK_PYTHON<span class=\"token operator\">=</span><span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>python\n<span class=\"token class-name\">export</span> PYTHONPATH<span class=\"token operator\">=</span><span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>spark<span class=\"token operator\">/</span>python\n<span class=\"token class-name\">export</span> MASTER<span class=\"token operator\">=</span>spark<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>Standalone<span class=\"token punctuation\">.</span>44p1qlnthrou1ezmysbcbmontc<span class=\"token punctuation\">.</span>syx<span class=\"token punctuation\">.</span><span class=\"token keyword\">internal</span><span class=\"token punctuation\">.</span>cloudapp<span class=\"token punctuation\">.</span>net<span class=\"token punctuation\">:</span><span class=\"token number\">7077</span></code></pre></div>\n<br/>\n<p>Zeppelin Daemon 기동  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root@Spark<span class=\"token operator\">-</span><span class=\"token class-name\">Standalone</span> conf<span class=\"token punctuation\">]</span># <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>bin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">-</span>daemon<span class=\"token punctuation\">.</span>sh start\nLog dir doesn'<span class=\"token class-name\">t</span> exist<span class=\"token punctuation\">,</span> create <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>logs\nPid dir doesn'<span class=\"token class-name\">t</span> exist<span class=\"token punctuation\">,</span> create <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>run\nZeppelin start                                             <span class=\"token punctuation\">[</span>  OK  <span class=\"token punctuation\">]</span>\n\n\n<span class=\"token preprocessor property\">### 정상 기동 확인</span>\n\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> conf<span class=\"token punctuation\">]</span># <span class=\"token operator\">/</span>home<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">/</span>bin<span class=\"token operator\">/</span>zeppelin<span class=\"token operator\">-</span>daemon<span class=\"token punctuation\">.</span>sh start\nZeppelin start                                             <span class=\"token punctuation\">[</span>  OK  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> conf<span class=\"token punctuation\">]</span># jps\n<span class=\"token number\">3779</span> ZeppelinServer\n<span class=\"token number\">3575</span> Worker\n<span class=\"token number\">3512</span> Worker\n<span class=\"token number\">3449</span> Worker\n<span class=\"token number\">3295</span> Master\n<span class=\"token number\">3807</span> Jps</code></pre></div>\n<br/>\n<p>Zeppelin Web page 확인 [Port 7777]</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/109940335-47f5ac00-7d15-11eb-9c86-04ded7a40090.JPG\" alt=\"캡처3333\"></p>\n<br/>\n<p>Notebook을 하나 만들어서 연동 테스트를 진행합니다. </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110071856-24d40680-7dc0-11eb-9320-04d58c12ea12.JPG\" alt=\"캡처4444\"></p>\n<p>완료인줄 알았으나…  </p>\n<br/>\n<hr>\n<h4 id=\"error-발생\" style=\"position:relative;\"><a href=\"#error-%EB%B0%9C%EC%83%9D\" aria-label=\"error 발생 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ERROR 발생</h4>\n<p>python, pyspark를 사용하려는데 python interpreter를 못찾는다..  </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>InterpreterException<span class=\"token punctuation\">:</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>InterpreterException<span class=\"token punctuation\">:</span> Fail to open PythonInterpreter\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>LazyOpenInterpreter<span class=\"token punctuation\">.</span><span class=\"token function\">open</span><span class=\"token punctuation\">(</span>LazyOpenInterpreter<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">76</span><span class=\"token punctuation\">)</span>\n\tat org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>remote<span class=\"token punctuation\">.</span>RemoteInterpreterServer$InterpretJob<span class=\"token punctuation\">.</span><span class=\"token function\">jobRun</span><span class=\"token punctuation\">(</span>RemoteInterpreterServer<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">760</span><span class=\"token punctuation\">)</span>\n\tat org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>remote<span class=\"token punctuation\">.</span>RemoteInterpreterServer$InterpretJob<span class=\"token punctuation\">.</span><span class=\"token function\">jobRun</span><span class=\"token punctuation\">(</span>RemoteInterpreterServer<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">668</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>scheduler<span class=\"token punctuation\">.</span>Job<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>Job<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">172</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>scheduler<span class=\"token punctuation\">.</span>AbstractScheduler<span class=\"token punctuation\">.</span><span class=\"token function\">runJob</span><span class=\"token punctuation\">(</span>AbstractScheduler<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">130</span><span class=\"token punctuation\">)</span>\n\tat org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>scheduler<span class=\"token punctuation\">.</span>FIFOScheduler<span class=\"token punctuation\">.</span>lambda$runJobInScheduler$<span class=\"token function\">0</span><span class=\"token punctuation\">(</span>FIFOScheduler<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">39</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>ThreadPoolExecutor<span class=\"token punctuation\">.</span><span class=\"token function\">runWorker</span><span class=\"token punctuation\">(</span>ThreadPoolExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">1149</span><span class=\"token punctuation\">)</span>\n\tat java<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span>concurrent<span class=\"token punctuation\">.</span>ThreadPoolExecutor$Worker<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>ThreadPoolExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">624</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>Thread<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">748</span><span class=\"token punctuation\">)</span>\n<span class=\"token class-name\">Caused</span> <span class=\"token keyword\">by</span><span class=\"token punctuation\">:</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>InterpreterException<span class=\"token punctuation\">:</span> Fail to open PythonInterpreter\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>PythonInterpreter<span class=\"token punctuation\">.</span><span class=\"token function\">open</span><span class=\"token punctuation\">(</span>PythonInterpreter<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">115</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>interpreter<span class=\"token punctuation\">.</span>LazyOpenInterpreter<span class=\"token punctuation\">.</span><span class=\"token function\">open</span><span class=\"token punctuation\">(</span>LazyOpenInterpreter<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">70</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span> <span class=\"token number\">8</span> more\n<span class=\"token class-name\">Caused</span> <span class=\"token keyword\">by</span><span class=\"token punctuation\">:</span> java<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span>IOException<span class=\"token punctuation\">:</span> Fail to launch python process<span class=\"token punctuation\">.</span>\norg<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>ExecuteException<span class=\"token punctuation\">:</span> <span class=\"token return-type class-name\">Execution</span> failed <span class=\"token punctuation\">(</span><span class=\"token class-name\">Exit</span> <span class=\"token keyword\">value</span><span class=\"token punctuation\">:</span> <span class=\"token operator\">-</span><span class=\"token number\">559038737</span><span class=\"token punctuation\">.</span> Caused <span class=\"token keyword\">by</span> java<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span>IOException<span class=\"token punctuation\">:</span> Cannot run program <span class=\"token string\">\"python\"</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">in</span> directory <span class=\"token string\">\".\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> error<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> No such file <span class=\"token keyword\">or</span> directory<span class=\"token punctuation\">)</span>\n\tat org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>DefaultExecutor$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>DefaultExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">205</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>Thread<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">748</span><span class=\"token punctuation\">)</span>\n<span class=\"token class-name\">Caused</span> <span class=\"token keyword\">by</span><span class=\"token punctuation\">:</span> java<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span>IOException<span class=\"token punctuation\">:</span> Cannot run program <span class=\"token string\">\"python\"</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">in</span> directory <span class=\"token string\">\".\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> error<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> No such file <span class=\"token keyword\">or</span> directory\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>ProcessBuilder<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span>ProcessBuilder<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">1048</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>Runtime<span class=\"token punctuation\">.</span><span class=\"token function\">exec</span><span class=\"token punctuation\">(</span>Runtime<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">621</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>launcher<span class=\"token punctuation\">.</span>Java13CommandLauncher<span class=\"token punctuation\">.</span><span class=\"token function\">exec</span><span class=\"token punctuation\">(</span>Java13CommandLauncher<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">61</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>DefaultExecutor<span class=\"token punctuation\">.</span><span class=\"token function\">launch</span><span class=\"token punctuation\">(</span>DefaultExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">279</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>DefaultExecutor<span class=\"token punctuation\">.</span><span class=\"token function\">executeInternal</span><span class=\"token punctuation\">(</span>DefaultExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">336</span><span class=\"token punctuation\">)</span>\n\tat org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>DefaultExecutor<span class=\"token punctuation\">.</span>access$<span class=\"token function\">200</span><span class=\"token punctuation\">(</span>DefaultExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">48</span><span class=\"token punctuation\">)</span>\n\tat org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>commons<span class=\"token punctuation\">.</span>exec<span class=\"token punctuation\">.</span>DefaultExecutor$<span class=\"token number\">1</span><span class=\"token punctuation\">.</span><span class=\"token function\">run</span><span class=\"token punctuation\">(</span>DefaultExecutor<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">200</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span> <span class=\"token number\">1</span> more\n<span class=\"token class-name\">Caused</span> <span class=\"token keyword\">by</span><span class=\"token punctuation\">:</span> java<span class=\"token punctuation\">.</span>io<span class=\"token punctuation\">.</span>IOException<span class=\"token punctuation\">:</span> error<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> No such file <span class=\"token keyword\">or</span> directory\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>UNIXProcess<span class=\"token punctuation\">.</span><span class=\"token function\">forkAndExec</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Native</span> Method<span class=\"token punctuation\">)</span>\n\tat java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>UNIXProcess<span class=\"token punctuation\">.</span><span class=\"token operator\">&lt;</span>init<span class=\"token operator\">></span><span class=\"token punctuation\">(</span>UNIXProcess<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">247</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>ProcessImpl<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span>ProcessImpl<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">134</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> java<span class=\"token punctuation\">.</span>lang<span class=\"token punctuation\">.</span>ProcessBuilder<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span>ProcessBuilder<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">1029</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span> <span class=\"token number\">7</span> more\n\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>PythonInterpreter<span class=\"token punctuation\">.</span><span class=\"token function\">createGatewayServerAndStartScript</span><span class=\"token punctuation\">(</span>PythonInterpreter<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">160</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token return-type class-name\">at</span> org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>zeppelin<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>PythonInterpreter<span class=\"token punctuation\">.</span><span class=\"token function\">open</span><span class=\"token punctuation\">(</span>PythonInterpreter<span class=\"token punctuation\">.</span>java<span class=\"token punctuation\">:</span><span class=\"token number\">112</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token range operator\">..</span><span class=\"token punctuation\">.</span> <span class=\"token number\">9</span> more</code></pre></div>\n<br/>\n<p>혹시 몰라 python 3.8.8 버전으로 새로 설치해봅시다.</p>\n<p>사전 파일 설치</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> conf<span class=\"token punctuation\">]</span># yum <span class=\"token operator\">-</span>y install gcc openssl<span class=\"token operator\">-</span>devel bzip2<span class=\"token operator\">-</span>devel libffi<span class=\"token operator\">-</span>devel</code></pre></div>\n<br/> \n<p>파이썬 설치</p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> nasa1515<span class=\"token punctuation\">]</span># <span class=\"token class-name\">wget</span> https<span class=\"token punctuation\">:</span><span class=\"token operator\">/</span><span class=\"token operator\">/</span>www<span class=\"token punctuation\">.</span>python<span class=\"token punctuation\">.</span>org<span class=\"token operator\">/</span>ftp<span class=\"token operator\">/</span>python<span class=\"token operator\">/</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token operator\">/</span>Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">.</span>tgz\n\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> nasa1515<span class=\"token punctuation\">]</span># tar xvfz Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">.</span>tgz\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> nasa1515<span class=\"token punctuation\">]</span># chmod <span class=\"token operator\">-</span>R <span class=\"token number\">777</span> Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span>\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> nasa1515<span class=\"token punctuation\">]</span>#\n<span class=\"token punctuation\">[</span>root<span class=\"token class-name\">@Standalone</span> nasa1515<span class=\"token punctuation\">]</span># cd Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span>\n<span class=\"token punctuation\">[</span>root@Standalone Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">]</span># <span class=\"token punctuation\">.</span><span class=\"token operator\">/</span>configure <span class=\"token operator\">--</span>enable<span class=\"token operator\">-</span>optimizations\n<span class=\"token punctuation\">[</span>root@Standalone Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">]</span># make altinstall\n<span class=\"token punctuation\">[</span>root@Standalone Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">]</span># echo <span class=\"token keyword\">alias</span> python<span class=\"token operator\">=</span><span class=\"token string\">\"/usr/local/bin/python3.8\"</span> <span class=\"token operator\">>></span> <span class=\"token operator\">/</span>root<span class=\"token operator\">/</span><span class=\"token punctuation\">.</span>bashrc\n<span class=\"token punctuation\">[</span>root@Standalone Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">]</span># source <span class=\"token operator\">/</span>root<span class=\"token operator\">/</span><span class=\"token punctuation\">.</span>bashrc\n<span class=\"token punctuation\">[</span>root@Standalone Python<span class=\"token operator\">-</span><span class=\"token number\">3.8</span><span class=\"token number\">.8</span><span class=\"token punctuation\">]</span># python <span class=\"token operator\">-</span>V\nPython <span class=\"token number\">3.8</span><span class=\"token number\">.8</span></code></pre></div>\n<p>결론 : 파이썬을 깔고 뭐 해봐도 안된다…  </p>\n<br/>\n<p>약 4시간동안 StackOverFlow를 찾아다닌 결과..아래 글을 발견했다..</p>\n<ul>\n<li><a href=\"https://stackoverflow.com/questions/32959723/set-python-path-for-spark-worker\">STACK OverFlow</a></li>\n</ul>\n<br/>\n<h4 id=\"문제-해결\" style=\"position:relative;\"><a href=\"#%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0\" aria-label=\"문제 해결 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>문제 해결</h4>\n<p>spark - pyspark가 python의 경로를 못읽고 있다!!<br>\n강제로 env 파일에 환경변수로 python의 경로를 넣어주자! </p>\n<div class=\"gatsby-highlight\" data-language=\"cs\"><pre class=\"language-cs\"><code class=\"language-cs\"><span class=\"token preprocessor property\">### 파이썬 경로 확인</span>\n\n<span class=\"token punctuation\">[</span>root@Standalone <span class=\"token operator\">~</span><span class=\"token punctuation\">]</span># which python3\n<span class=\"token operator\">/</span>usr<span class=\"token operator\">/</span>bin<span class=\"token operator\">/</span>python3\n\n\n<span class=\"token preprocessor property\">### env.sh 파일에 환경변수 설정</span>\n\n<span class=\"token class-name\">export</span> PYSPARK_PYTHON<span class=\"token operator\">=</span><span class=\"token string\">\"/usr/bin/python3\"</span></code></pre></div>\n<br/>\n<p>정상적으로 연결!!  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110093218-cddd2a00-7ddd-11eb-8259-aa1bdfd93880.JPG\" alt=\"캡처331212\"></p>\n<br/>\n<p>Zeppelin에서도 정상적으로 구동되네요…</p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110093881-8c994a00-7dde-11eb-8e41-81568de26954.JPG\" alt=\"123123\"></p>\n<br/>\n<hr>\n<h4 id=\"blob-storage에-csv-파일-upload\" style=\"position:relative;\"><a href=\"#blob-storage%EC%97%90-csv-%ED%8C%8C%EC%9D%BC-upload\" aria-label=\"blob storage에 csv 파일 upload permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Blob Storage에 csv 파일 Upload</h4>\n<p>기본적으로 Azure에서 Storage는 Storage Account로 관리됩니다.<br>\n때문에 우선적으로 Storage Account를 생성하고 blob container를 생성해야 합니다.  </p>\n<ul>\n<li>Storage Account 및 blob의 생성은 <a href=\"https://nasa1515.github.io/azure/2021/02/08/AZURE-Storageservice.html#a2\">이전포스트</a>를 확인하시면 됩니다.  </li>\n</ul>\n<br/>\n<h4 id=\"저는-다음과-같이-testdatacsv-파일을-blob에-upload-했습니다\" style=\"position:relative;\"><a href=\"#%EC%A0%80%EB%8A%94-%EB%8B%A4%EC%9D%8C%EA%B3%BC-%EA%B0%99%EC%9D%B4-testdatacsv-%ED%8C%8C%EC%9D%BC%EC%9D%84-blob%EC%97%90-upload-%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4\" aria-label=\"저는 다음과 같이 testdatacsv 파일을 blob에 upload 했습니다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>저는 다음과 같이 TESTDATA.csv 파일을 blob에 upload 했습니다.</h4>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110274941-64466100-8013-11eb-8357-ca245d5c6d2f.JPG\" alt=\"13123123\"></p>\n<br/>\n<h4 id=\"error-발생-1\" style=\"position:relative;\"><a href=\"#error-%EB%B0%9C%EC%83%9D-1\" aria-label=\"error 발생 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ERROR 발생!</h4>\n<ul>\n<li>\n<h4 id=\"원래의-목표--hadoopyarn---cluster-manager-없이-standalone-구성에-blob-storage-data-read\" style=\"position:relative;\"><a href=\"#%EC%9B%90%EB%9E%98%EC%9D%98-%EB%AA%A9%ED%91%9C--hadoopyarn---cluster-manager-%EC%97%86%EC%9D%B4-standalone-%EA%B5%AC%EC%84%B1%EC%97%90-blob-storage-data-read\" aria-label=\"원래의 목표  hadoopyarn   cluster manager 없이 standalone 구성에 blob storage data read permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>원래의 목표 : hadoop(yarn) - Cluster Manager 없이 Standalone 구성에 blob storage data read.</h4>\n</li>\n<li>\n<p>해당 구성을 테스트 해보려고 했으나 다음과 같은 ERROR 발생  </p>\n<p><img src=\"https://user-images.githubusercontent.com/69498804/110295613-a8962900-8034-11eb-8639-d665dc057275.JPG\" alt=\"1232313\"></p>\n<p>해당 이슈는 blob(data lake gen2)에서 wasb[s] 형식으로 파일을 받아오려 했으나<br>\nSpark 가 설치되어있는 VM에는 Hadoop이 설치 및 연동이 되어있지 않기에 DF에 넣을 수 없는 이슈 였습니다.<br>\n사실 pyspark를 기반으로 작동해서 Azure blob api를 직접 선언해서 https 연동을 할 수는 있지만<br>\n그렇게 사용하는 로직은 실습이나 실무에서도 적합하지 않다고 생각해서 Hadoop을 깔기로 했습니다.  </p>\n</li>\n</ul>\n<br/>\n<hr>\n<h2 id=\"마치며\" style=\"position:relative;\"><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\" aria-label=\"마치며 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>마치며…</h2>\n<p>마지막 pyspark 문제로 거의 4시간, hdhfs 문제로 4시간 거의 하루를 날렸습니다.<br>\n시간이 조금 지나니 Spark에 대한 로직을 제대로 이해 못한 부분이 큰 것 같습니다.<br>\n그래서 다음 포스트에서 hadoop을 설치하고 재도전해봅시다..  </p>\n<hr>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#-azure-vm%EC%97%90-spark-standalone-%EA%B5%AC%EC%84%B1\">✔ Azure VM에 Spark StandAlone 구성</a></p>\n<ul>\n<li><a href=\"#%ED%99%98%EA%B2%BD%EA%B5%AC%EC%84%B1\">환경구성</a></li>\n<li><a href=\"#1-open-jdk-%EC%84%A4%EC%B9%98-root-%EA%B3%84%EC%A0%95-%EA%B8%B0%EB%B0%98\">1. Open JDK 설치 (root 계정 기반)</a></li>\n<li><a href=\"#2-apache-spark-%EC%84%A4%EC%B9%98-root-%EA%B3%84%EC%A0%95-%EA%B8%B0%EB%B0%98\">2. Apache Spark 설치 (root 계정 기반)</a></li>\n<li>\n<p><a href=\"#3-zeppelin-%EC%84%A4%EC%B9%98-root-%EA%B3%84%EC%A0%95-%EA%B8%B0%EB%B0%98\">3. Zeppelin 설치 (root 계정 기반)</a></p>\n<ul>\n<li><a href=\"#config-%EC%88%98%EC%A0%95\">Config 수정</a></li>\n<li><a href=\"#error-%EB%B0%9C%EC%83%9D\">ERROR 발생</a></li>\n<li><a href=\"#%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0\">문제 해결</a></li>\n<li><a href=\"#blob-storage%EC%97%90-csv-%ED%8C%8C%EC%9D%BC-upload\">Blob Storage에 csv 파일 Upload</a></li>\n<li><a href=\"#%EC%A0%80%EB%8A%94-%EB%8B%A4%EC%9D%8C%EA%B3%BC-%EA%B0%99%EC%9D%B4-testdatacsv-%ED%8C%8C%EC%9D%BC%EC%9D%84-blob%EC%97%90-upload-%ED%96%88%EC%8A%B5%EB%8B%88%EB%8B%A4\">저는 다음과 같이 TESTDATA.csv 파일을 blob에 upload 했습니다.</a></li>\n<li><a href=\"#error-%EB%B0%9C%EC%83%9D-1\">ERROR 발생!</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><a href=\"#%EB%A7%88%EC%B9%98%EB%A9%B0\">마치며…</a></li>\n</ul>\n</div>","frontmatter":{"date":"August 14, 2021","title":"[DATA] - Azure VM에 Apache Spark v3.0 Standalone 설치 With Zeppelin","categories":"DATA","author":"nasa1515","emoji":"🤦‍♂️"},"fields":{"slug":"/data-sparkinstall/"}},"site":{"siteMetadata":{"siteUrl":"https://nasa1515.com","comments":{"utterances":{"repo":"nasa1515/nasablog"}}}}},"pageContext":{"slug":"/data-hadoopeco/","nextSlug":"/data-hadoop/","prevSlug":"/data-sparkinstall/"}},"staticQueryHashes":["1073350324","2938748437"]}